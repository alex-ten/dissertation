\chapter{Progress-based exploration in humans}\label{CH4}

\section{Introduction}\label{CH4_S_introduction}
As explained extensively in \cref{CH2}, curiosity is a fundamental drive in human behavior and a topic of great interest in neuroscience and cognitive psychology. The vast majority of recent research on curiosity has operationalized it as intrinsically motivated information demand, using tasks in which participants can request information about future events but do not have the opportunity to exploit (act on) the information. The studies have shown that humans and other animals seek to obtain information as a good in itself and this preference is encoded in neural systems of reward and motivation, suggesting that information is rewarding independently of material gains \parencite{duan2020effect,lau2020shared,kang_wick_2009,bromberg-martin_midbrain_2009}.

While these findings tap into the intrinsic motivation behind curiosity, they are yet to capture the full scope of curiosity-driven investigations \parencite{gottlieb_towards_2018}. Specifically, in natural settings, humans investigate questions on much longer time scales relative to those tested in the laboratory. In contrast with  tasks of information demand in which participants request information about brief unrelated events – e.g., a forthcoming reward or a trivia question – in natural behavior, learners maintain sustained focus on specific activities such as reading an article, conducting an online search, or taking a course. Operating from early infant development \parencite{bazhydai_curiosity_2020}, this ability for sustained investigations may underlie the most important ecological role of curiosity, as it allows people to develop individual interests and skills and, ultimately, discover explanatory models and latent structures of the world \parencite{hidi_interest_2019,schwartenbeck_computational_2019,dubey_reconciling_2020}.

% Figure 1
\begin{figure}[tbh]
    \centering
    \includegraphics[width=\textwidth]{Figures/c4/figure1.pdf}
    \caption[(\textbf{a}) Free-exploration paradigm; (\textbf{b}) Problem difficulty and initial performance]{Task design and difficulty manipulation. \textbf{a}, Trial structure during free play. The panels show 3 example free-choice trials consisting of 3 steps each. Each trial began with a choice among 4 "monster families" depicted as visual icons (1). This was followed by the presentation of a randomly drawn individual from that family and a prompt to guess which of two possible foods the individual liked to eat (2). After guessing (2), the participant received immediate feedback (3) and the next trial began. Participants were free to repeat the previously sampled activity (e.g., trial $t+2$ in this figure) or switch to any other monster family (e.g., trial $t+1$) as they wished. \textbf{b}, Performance during the forced-choice familiarization stage. Each box plot shows the \acf{PC} during the 15 familiarization trials in which participants had to play each activity for the \ac{IG} (blue; $N=186$) and \ac{EG} (red; $N=196$) groups. Horizontal bars inside boxes show the median values across all participants in a group; box boundaries show the 1st and the 3rd quartiles; whiskers show sample minima and maxima. Image credits (Fig. 1, \textbf{a}): monster character designs by macrovector/Freepik; food-item designs by brgfx/Freepik.}
    \label{fig:CH4_1}
\end{figure}

Very little is known about how people self-organize investigations to achieve  learning on longer time scales. Natural environments afford a practically infinite number of activities that a curious learner can in principle investigate. However, given the limited time and resources available for investigation, the learner  must carefully select which activity to engage with to enable discovery. Formal treatment of this “strategic student” problem prescribe how learners should allocate study time to maximize learning across a set of the activities \parencite{son_metacognitive_2006,lopes_strategic_2012} but show that the optimal allocation is very sensitive to the shape of the expected learning trajectory, which is not available to learners in practice \parencite{son_metacognitive_2006}. 
 
A common proposal for how people resolve this conundrum is that they prioritize study items based on their perceived difficulty, i.e., their perceived level of knowledge or competence on a task, but the precise form of this prioritization is under debate. Several studies have shown  that people prioritize tasks with high difficulty or high uncertainty \parencite{loewenstein_psychology_1994,schulz_structured_2019}. In contrast, an expanding literature proposes that people prefer intermediate difficulty \parencite{berlyne1960conflict} in a range of conditions including curiosity about trivia questions \parencite{kang_wick_2009,baranes_eye_2015}, choices among sensorimotor activities \parencite{baranes_effects_2014}, infant attention \parencite{kidd_goldilocks_2012} and aesthetic appreciation \parencite{tsutsui_complexity_2011,gold_predictability_2019}.
 
Strategies that prioritize high versus intermediate difficulty activities may have different computational bases and ecological roles. A preference for high difficulty tasks may emerge from computational architectures that assign intrinsic utility to prediction errors or uncertainty, thus motivating agents to venture beyond familiar activities  \parencite{dayan1996exploration,bellemare_unifying_2016,pathak_curiosity-driven_2017,schulz_structured_2019}. In contrast, a strategy prioritizing activities with intermediate difficulty may emerge from control architectures based on learning progress \parencite[\ac{LP};][]{kaplan_search_2007,schmidhuber2010formal,graves_automated_2017,twomey_curiosity-based_2018,colas_curious_2019,kim_active_2020} that monitor the temporal derivative of performance - e.g., \acf{PC} - and generate intrinsic rewards for activities in which the agent's performance changes with practice.  

\ac{LP}-based algorithms are particularly important in naturalistic environments because they allow agents to avoid not only highly familiar tasks but also unlearnable tasks – i.e., activities that are intrinsically random or cannot be mastered with the learners’ current knowledge or skills \parencite{oudeyer_intrinsic_2007,forestier_intrinsically_2020,kim_active_2020}. Unlike \ac{PC}-based algorithms that steer agents toward tasks of maximum difficulty, \ac{LP}-based algorithms help to avoid random or too-difficult  activities. Moreover, these algorithms provide realistic solutions for optimizing study time allocation - by maximizing the progress that an agent experiences in practice without precise knowledge of one’s future learning curve \parencite{son_metacognitive_2006,lopes_strategic_2012} - and have been applied to automate curriculum learning in difficult machine learning problems \parencite{graves_automated_2017, matiisen2019teacher,portelas2020automatic} and personalize sequences of learning activities in educational technologies \parencite{clement:hal-00913669,oudeyer2016intrinsic,mu2018combining}.

Despite the potential importance of \ac{LP}-based control strategies, there is no empirical evidence of whether, and how, people use such strategies. In the studies conducted so far, people were asked to estimate the difficulty of study materials based on their familiarity with the topic \parencite[e.g., biographical text or foreign vocabulary;][]{son_metacognitive_2000}. However, no study has tested whether participants can  dynamically monitor their performance on an arbitrary activity and use dynamic estimates of \ac{PC} or its temporal derivative (\ac{LP}) as predicted by computational algorithms. 

Here, we examined this question using computational modeling and a behavioral task in which people self-organized their study curricula based on trial-by-trial feedback about their performance on a set of novel activities. We provide direct evidence that humans show bona fide sensitivity to \ac{LP} – the change in performance on novel activities – which coexists with a sensitivity to \ac{PC} and steers people away from unlearnable tasks consistent with computational theories. 

\section{Results}\label{CH4_S_results}
    
% Figure 2
\begin{figure}[tbh]
    \center
    \includegraphics[width=.6\columnwidth]{Figures/c4/figure2.pdf}
    \caption[short description]{Free play behavior. \textbf{a}, The fraction of participants selecting each learning activity in the \ac{EG} ($N=196$) and \ac{IG} ($N=186$) groups (respectively, top and bottom panels) as a function of trial number during the free play stage (no smoothing) demonstrate that group differences in choice patterns persisted throughout the task. \textbf{b}, Histograms of \acf{dwfPC} for each instruction group. The \ac{EG} group ($N=196$) achieved better \ac{dwfPC} scores than the \ac{IG} group ($N=186$), but the distributions were broad and overlapping, highlighting important individual variability. The difference between groups was significant with both \ac{dwfPC} and unweighted average \ac{PC} scores.}
    \label{fig:CH4_2}
\end{figure}

We analyzed data from 382 participants who performed an online task in which they could freely engage with a set of learning activities (\cref{fig:CH4_1}, \textbf{a}). Each trial started with a free-choice panel prompting the participant to choose one of 4 activities depicted as families of “monsters” (\cref{fig:CH4_1}, \textbf{a}, (1)). After making a choice, the participant received a randomly drawn member from the chosen family, made a binary guess about which food that member liked to eat (\cref{fig:CH4_1}, \textbf{a}, (2)), and received immediate feedback regarding their guess (\cref{fig:CH4_1}, \textbf{a}, (3)). To understand how participants self-organized their learning curriculum, we required them to complete 250 trials but did not impose any other constraint on their choice of activity.

Our key questions were (1) how people self-organize their exploration over a set of activities of variable difficulty, and (2) whether they spontaneously adopt learning maximization objectives when they do not receive explicit instructions. To examine these questions, we manipulated the difficulty of the available activities as a within-participant variable, and the instructions that participants received as an across-participant variable. Difficulty was controlled by the complexity of the categorization rule governing the food preferences.  In the easiest activity (A1), individual monster-family members differed in only one feature and that feature governed their food preference (e.g., a red monster with big flame liked fries and a red monster with small flame liked salad; 1-dimensional categorization). In the next easiest level (A2), family members varied along two features, but only one feature determined preference (1-dimensional with an irrelevant feature). In the most difficult learnable activity (A3)  food preferences were determined by a conjunction of 2 variable features (2-dimensional categorization). Finally, the 4\textsuperscript{th} activity (A4) was random and unlearnable: individual monsters had two variable features, but their food preferences were assigned randomly each time a new monster was sampled, and were thus unpredictable with either a rule-based or rote memorization strategy.

Learning objectives were manipulated across two randomly selected  participant groups. Participants assigned to the “external goal” group (\ac{EG}; $\text{N} = 196$) were asked to maximize learning across all the activities and were told that they will be tested at the end of the session. In contrast, participants in the “internal goal” group (\ac{IG}, $\text{N} = 186$) were told to choose any activity they wished with no constraint except for completing 250 trials. Except for this difference in instructions (and the fact that the \ac{EG} group received the announced test), the two groups received identical treatments. Each group started with 15 forced-choice familiarization trials on each activity, followed by a 250-trial free-play stage, and gave several subjective ratings of the activities before and after the free play stage (see Appendix \labelcref{CH4A_S_self_reported_ratings}, \textsc{Self-reported Ratings}).

Performance on the forced-choice familiarization stage verified that these manipulations worked as intended. The \ac{EG} and \ac{IG} groups had equivalent  performance during this stage (\cref{fig:CH4_1}, \textbf{b}; mixed-design ANOVA on percent correct (\ac{PC}) with group and difficulty as factors; \ac{EG} vs \ac{IG}, $F(1, 380) = 1.829,\ p = .177$; group $\times$ difficulty interaction, $F(3,1140) = 0.820,\ p = .483$). For both \ac{EG} and \ac{IG} participants, performance on each activity was significantly different from all others, suggesting that both groups could use performance feedback as an index of activity difficulty (\cref{fig:CH4_1}, \textbf{b}; mixed-design ANOVA, main effect of activity, $F(3,1140) = 158.400,\ p < .001$; post-hoc pairwise Tukey's HSD tests between all activity levels within each group were significant with  all p-values smaller than $p = .01$). Additional evidence from the ratings obtained at the end of the task showed that the \ac{EG} and \ac{IG} groups provided similar retrospective ratings of time spent, progress made and interest in learning activities (Appendix \labelcref{fig:CH4A_2_self_reported_ratings}), suggesting that they had equivalent engagement and self-monitoring while performing the task.

\subsection{Self-challenge} \label{CH4_SS_self_challenge}
% \label{subCH4_S_results/heterogeneity}

Despite their equivalent learning ability, \ac{EG} and \ac{IG} participants showed different choice patterns and substantial individual variability in the extent to which they challenged themselves and mastered the available tasks. 

Analysis of group-level activity choices showed that, while the \ac{EG} group focused strongly on the most difficult activity (the unlearnable activity that had the lowest \ac{PC}), the \ac{IG} group showed a more uniform preference with only a slight bias toward the easiest activity (\cref{fig:CH4_2}, \textbf{a}). Across the entire session, the \ac{EG} group had significant below-chance time allocation to the two easiest activities and above-chance allocation to the random (lowest-PC) activity (relative to $25\%$; linear model with sum contrasts: A1: $20.61\%,\ t(1520) = -3.002,\ p = .003$; A2: $19.29\%;\ t(1520) = -3.910,\ p = .048$; A4: $36.92\%;\ t(1520) = 8.156,\ p < .001$). In contrast, the \ac{IG} group had a significant above-chance allocation for the easiest (A1) activity (A1: $33.00\%,\ t(1520) = 5.330,\ p < .001$) while spending less time on other activities (A2: $21.42\%;\ t(1520) = -2.387,\ p = .017$; A3: $22.16\%; p > .05$; A4: $23.43\%; p > .05$; \cref{fig:CH4_2}, \textbf{a}). According to a significant interaction between instruction-group $\times$ activity-type interaction, revealed by a 2-way mixed design ANOVA of time allocation, these differences were reliable ($F(3, 1140) = 14.578,\ p < .001$).

Consistent with their higher self-challenge, average learning achieved by the end of the free-play stage was greater in the \ac{EG} relative to the \ac{IG} group (\cref{fig:CH4_2}, \textbf{b}). A measure of difficulty-weighted final \ac{PC} (\ac{dwfPC}: the average \ac{PC} in the last 15 trials spent on each activity scaled by its difficulty rank (see \cref{CH4_SSS_difficulty_weighted_final_performance}, \textsc{Methods}/\textit{Difficulty-weighted final performance}) was significantly higher for the \ac{EG} group ($\text{M} = 0.756,\ \text{SD} = 0.127$) relative to the \ac{IG} group (\cref{fig:CH4_2}, \textbf{b}; $\text{M} = 0.721,\ \text{SD} = 0.126;\ t(379.4) = 2.679,\ p = 0.008$, Welch two-sample $t$-test), and the same result held if we used unweighted average PC (\ac{EG}: $\text{M}=0.787,\ \text{SD}=.118$; \ac{IG} $\text{M}=0.756,\ \text{SD}=0.120;\ t(378.1) = 2.539,\ p = .011$, Welch two-sample $t$-test). 

% Figure 3
\begin{figure}[tbh!]
    \centering
    \includegraphics[width=.75\columnwidth]{Figures/c4/figure3.pdf}
    \caption[short description]{Individual variability within groups. \textbf{a}, Final performance was the same across instruction groups when accounting for the number of activities mastered (\ac{NAM}). As expected, the \ac{NAM} designation captured well the learning achievement of our participants. In light of \textbf{b}, this demonstrates that many participants achieved a high performance across learning activities, even without an explicit instruction to learn. \textbf{b}, Distributions of participants mastering 1, 2, or 3 activities in each instruction group. Whereas half of the participants in the \ac{EG} group achieved high performance across learnable tasks, a sizable portion of the \ac{IG} participants (almost 1/3) were motivated enough to self-challenge and learn without being asked to do so. Only 8 participants in the \ac{EG} and 9 participants in the \ac{IG} group failed to master even one activity. Thus, 99 participants mastered only 1 activity ($N_{\mathrm{EG}}=42$; $N_{\mathrm{IG}}=57$), 126 mastered two ($N_{\mathrm{EG}}=58$; $N_{\mathrm{IG}}=68$), and 140 mastered all three ($N_{\mathrm{EG}}=88$; $N_{\mathrm{IG}}=52$) \textbf{c}, Time allocation patterns differed by instruction and level of achievement. The three panels show the average time allocation patterns in \ac{IG} ($N=177$) and \ac{EG} ($N=188$) groups observed over the free-play trials separately for each level of \ac{NAM} (from left to right, \ac{NAM}1, \ac{NAM}2, and \ac{NAM}3). Circle (\ac{EG}) and square (\ac{IG}) symbols represent the average percentage of time spent on an activity in the respective \ac{NAM}-instruction group; error bars indicate the standard error; the horizontal dashed lines show random time allocation (25\%). Time allocation was consistent across the levels of \ac{NAM} towards harder activities in the \ac{EG} group. In contrast, only the best learners in the \ac{IG} group displayed a similar preference, whereas \ac{NAM}1\&2 participants tended towards easier activities.}
    \label{fig:CH4_3}
\end{figure}

Notwithstanding these group-level differences, participants showed substantial individual variability and, importantly, a subset of those in the \ac{IG} group adopted levels of self-challenge similar to the \ac{EG} group. To investigate this variability we categorized each participant based on the number of activities they mastered to a learning criterion - i.e., whether they mastered 1, 2 or all 3 learnable activities (\ac{NAM}1, \ac{NAM}2 or \ac{NAM}3; see \cref{CH4_SSS_nam_designation}, \textsc{Methods}/\textit{\ac{NAM} designation}). The \ac{dwfPC} score within each \ac{NAM} group was not affected by instructions, showing that the \ac{NAM} designation effectively captured the variability in learning achievement (\cref{fig:CH4_3}, a; pairwise contrasts \ac{IG} vs. \ac{EG} conditioned on \ac{NAM} were nonsignificant, $p>.05$, at all levels of \ac{NAM}).

Importantly, despite not being instructed to study for a test, $64.52\%$ of \ac{IG} participants mastered more than one activity (\ac{NAM}2 and \ac{NAM}3) and $29.59\%$ mastered all 3 activities (\cref{fig:CH4_3}, b). These percentages were comparable to learning achievements in the \ac{EG} group, where $74.49\%$ mastered at least 2 activities, and $36.56\%$ mastered all three. The relative proportions of participants at each achievement level were comparable between the two groups across a range of mastery criteria (see Appendix \labelcref{CH4A_S_mastery_points}, for a detailed analysis). Thus, while changing the criterion modified the number of participants who achieved mastery, it left intact the relative fractions of \ac{NAM} subgroups in the \ac{IG} and \ac{EG} groups. This shows that our conclusions are independent of a specific definition of mastery.

While \ac{NAM}1 and \ac{NAM}2 participants in the \ac{IG} group showed choices consistent with the group average -- favoring the easiest activity -- \ac{NAM}3 participants showed a distinct preference for A3 and A4 activities that more closely resembled the \ac{EG} group (\cref{fig:CH4_3}, \textbf{c}). A two-way mixed ANOVAs of time allocation in the \ac{IG} group showed a marginally significant main effect of activity ($F(3,525) = 8.847, p < .001$) and a highly significant interaction between activity and \ac{NAM} ($F(3,525)=14.791, p < .001$). In the \ac{EG} group there was also a significant main effect of activity ($F(3,525) = 19.407,\ p<.001$) and a significant interaction with \ac{NAM} ($F(3,525) = 7.197,\ p<.001$). As \cref{fig:CH4_3} (\textbf{c}) shows, while participants in \ac{NAM}1 and \ac{NAM}2 groups differed in activity selection across the instruction conditions, those who mastered all 3 learnable activities allocated their time similarly. Importantly, a sizeable fraction of the \ac{IG} group behaved in the same way as people who were instructed to learn and prepare for a test.

To further examine the relationship between learning achievement and activity choices, we created an index of \acf{SC} measuring the extent to which each participant tended to challenge themselves. This index was defined as the recent \ac{PC} of the activity selected on each trial, normalized to the entire range of \ac{PC} levels the participant experienced so far (see \cref{CH4_SSS_self_challenge_index}, \textsc{Methods}/\textit{Self-challenge index}). Thus, \ac{SC} values close to 0 denote participants who tended to choose the easiest of the activities they experienced; \ac{SC} close to 1 denote participants who tended to choose the most difficult activities; and \ac{SC} near 0.5 denote participants who preferred activities of intermediate difficulty. Supplementary analyses verified that the \ac{SC} index is a more efficient measure of the tendency to choose challenging activities compared to simple contrasts between pairs of activities (Appendix \labelcref{CH4A_S_self_challenge_index}).

% Figure 4
\begin{figure}[tbh!]
    \centering
    \includegraphics[width=.75\columnwidth]{Figures/c4/figure4.pdf}
    \caption[short description]{Relationship between activity choices and final performance. The scatter plot shows the difficulty-weighted final score (\ac{dwfPC}; $y$-axis) as a function of the self-challenge index (SC; $x$-axis). Each point is one participant. Colors indicate the number of activities mastered: \ac{NAM}1, $N=99$ ($N_{\mathrm{EG}}=42$; $N_{\mathrm{IG}}=57$); \ac{NAM}2, $N=126$ ($N_{\mathrm{EG}}=58$; $N_{\mathrm{IG}}=68$); and \ac{NAM}3, $N=140$ ($N_{\mathrm{EG}}=88$; $N_{\mathrm{IG}}=52$); filled and unfilled circles indicate, respectively, \ac{EG} ($N=188$) and \ac{IG} ($N=177$) groups. The black curve shows the line of best fit from a linear-quadratic regression model, with $95\%$ confidence intervals represented by the strip surrounded by black dashed lines. The marginal histograms on the top show the distributions of \ac{SC} scores for each \ac{NAM} (color) and group (solid and dashed traces). \ac{SC} was higher for \ac{EG} relative to \ac{IG} groups in participants who mastered only 1 or 2 activities (\ac{NAM}1 and \ac{NAM}2), and was equivalent, with intermediate values, for participants who mastered all 3 activities (\ac{NAM}3; top histogram).}
    \label{fig:CH4_4}
\end{figure}

Plotting \ac{dwfPC} versus \ac{SC} (\cref{fig:CH4_4}) reveals two important insights. First, \ac{dwfPC} has a strong inverted-U relationship with \ac{SC}, suggesting that the best learning outcomes were associated with intermediate \ac{SC}. An additive model of \ac{dwfPC} that included both linear and quadratic \ac{SC}-index terms (as well as control variables of initial performance and instruction) was superior to its counterpart with only a linear term, $\Delta_{\text{AIC}} = 11.775$). The linear-quadratic model accounted for a significant fraction of variance ($R_{\text{adjusted}}^2 = .159,\ F(4,360) = 18.238,\ p < .001$) and produced a significant negative coefficient for the quadratic term ($-0.016,\ t(360) = -1.966,\ p < .001$). We replicated this finding when we repeated the analysis using unweighted final \ac{PC} scores  ($R_{\text{adjusted}}^2 = .191,\ F(4,360) = 13.642,\ p < .001$, with the coefficient for the quadratic term $=-0.017,\ t(360) = -3.561,\ p = .007$) and when replacing \ac{SC} with pairwise contrast of activity choices (Appendix \labelcref{fig:CH4A_4_self_challenge_index}, \textbf{b}). This shows that the finding was not an artifact of the specific ways we measured \ac{PC} or \ac{SC}.

Second, participants with different instructions and learning achievement fell on different portions of the inverted-U curve. Participants who did not master all 3 activities  (\ac{NAM}1 and \ac{NAM}2) fell on the rising and falling arms of the inverted-U curve if they were in, respectively, the \ac{IG} or the \ac{EG} group (\cref{fig:CH4_4}). These participants had equivalent \ac{dwfPC} but higher \ac{SC} in the \ac{EG} relative to the \ac{IG} group (multiplicative linear model;  \ac{NAM}1, $t(359) = 2.856,\ p = .005$; \ac{NAM}2 ($t(359) = 4.377,\ p < .001$; Tukey's HSD; see the marginal histograms in \cref{fig:CH4_4}). Thus, \ac{EG} participants who failed to master all 3 tasks did so because they over-challenged themselves and those in the \ac{IG} group did so because they under-challenged themselves. In contrast, participants who mastered all 3 activities were at the top of the inverted-U curve and had equivalent (intermediate) \ac{SC} in the \ac{IG} and \ac{EG} groups (\cref{fig:CH4_3}, c; no significant pairwise contrasts between \ac{EG} and \ac{IG} for \ac{NAM}3, $t(359) = 1.236,\ p = .217$; see the top marginal histogram). Thus, consistent with the activity preferences (\cref{fig:CH4_3}, \textbf{c}): a subset of participants spontaneously adopted intermediate self-challenge strategies and maximized learning regardless of external instructions. 

\subsection{Computational modeling and sensitivity to LP}\label{CH4_SSS_computational_modeling}
While empirical studies demonstrate preferences for activities of intermediate complexity, they have yet to report specific sensitivity to \ac{LP}. One study \parencite{son_metacognitive_2000} reports that people choose study words that are judged to have intermediate difficulty, but did not measure dynamic sensitivity to \ac{LP} - the change in performance over time - either alone or in combination with \ac{PC}.

To examine this question, we fit the participants' activity choices by leveraging the formalism of intrinsically motivated reinforcement learning models \parencite{lopes_strategic_2012,graves_automated_2017,linke_adapting_2020,colas_curious_2019}. Such models typically include three major components: (1) a space of learning activities, (2) an intrinsic utility function for each activity, associated with a decision-making mechanism, modeling how they are sampled, and (3) a model of learning mechanisms that improve skills after practicing an activity. Here, we already know the space of learning activities and we can observe the evolution of performance as learners engage in the activities. Thus, we can ask which intrinsic utility function could best explain the participants' choices. To do so, we consider a standard softmax model (in a bandit setting \parencite{linke_adapting_2020}, in which the utility of an activity is a linear combination of \ac{PC} and \ac{LP}:
\begin{equation}
    U_{i,t} = w_{\mathrm{PC}} \times \mathrm{PC}_{i,t} +  w_{\mathrm{LP}} \times \mathrm{LP}_{i,t}
    \label{eq:utility}
\end{equation}
\ac{PC} and \ac{LP} were dynamically evaluated for each activity $i$ at each trial $t$ based on the recent feedback history. \ac{PC} was defined as the number of correct guesses over the last 15 trials of activity $i$, and \ac{LP} was defined as the difference in \ac{PC} between first versus second parts of the same interval. We fitted each participants’ data (excluding 8 \ac{EG} and 9 \ac{IG} participants who did not master even a single activity) as a probabilistic (softmax) choice over 4 discrete classes, using maximum likelihood estimation with 3 free parameters - the softmax temperature (capturing choice stochasticity) and weights $w_{\mathrm{PC}}$, $w_{\mathrm{LP}}$ indicating the extent to which each participant was sensitive to, respectively, \ac{PC} and \ac{LP} (\cref{CH4_SSS_computational_modeling}, \textsc{Methods}/\textit{Computational modeling}). Appendix \labelcref{fig:CH4A_5_individual_model_fit} illustrates the model fitting procedure for an example participant's data.

The bivariate form of the model that included both \ac{LP} and \ac{PC} (\cref{eq:utility}) provided a superior fit to the data in both \ac{EG} and \ac{IG} groups. The bivariate model average AIC score ($\text{M}=491.992,\ \text{SD}=200.389)$) was lower than that of an alternative model based on random selection ($\text{M} = 693.147$; SD = 0; the baseline model yields the same likelihood regardless of participants' choices; see \cref{eq:likelihood}) and, importantly, also outperformed univariate models that included only \ac{LP} or only \ac{PC} terms (\cref{fig:CH4_5}, \textbf{a}). A 2-way ANOVA of AIC scores showed a significant effect of model form ($F(2, 1089) = 43.992, \ p < .001$), a marginal effect of instruction ($p = .054$), but no interaction between model form and \ac{EG}/\ac{IG} groups ($p = .716$). The bivariate model had the lowest AIC scores in a large majority of participants in both groups (\ac{EG}: $70.74\%$; \ac{IG}: $74.01\%$). Finally, in each group, the bivariate model had a significantly lower AIC relative to each participant's next-best model (Wilcoxon signed-rank test, \ac{EG}: mean difference $=21.503,\ \text{SD} = 41.433;\ Z(188) = 55,\ p < .001$; \ac{IG}: mean difference $=21.882,\ \text{SD} = 45.383;\ Z(177) = 46,\ p < .001$) and was at least 2 AIC points away from the next-best model in a majority of participants (\ac{EG}: $58.51\%$; \ac{IG}: $62.71\%$).   

The fact that the bivariate model fits free-choice data better than univariate models provides direct evidence that participants are sensitive to \ac{LP} – a heuristic for the temporal derivative of \ac{PC} – above and beyond overall error rates. Importantly, the lack of interaction between model form and instruction shows that participants do not need to be explicitly instructed to maximize learning to demonstrate sensitivity to \ac{LP}. Additional analyses showed that the \ac{PC} and \ac{LP} coefficients remained important even after including a term representing task familiarity (the reciprocal of novelty) in the utility function. As discussed in Appendix \labelcref{CH4A_S_familiarity_component}, (\textsc{Familiarity component}), we focus on models without the familiarity term because in our task, novelty/familiarity is defined only by past choices and is thus circular if used to model choices. Modeling familiarity accounts for choice autocorrelation, but does not explain it. We note, however, that in computational \ac{RL} studies \parencite{pathak_curiosity-driven_2017,bougie2020fast}, measures of competence (like our \ac{PC} measure) are used as a proxy for novelty preference that guides agents towards unfamiliar states.

As a final validation of our models, we conducted model simulations of time-allocation using the coefficients fitted by the bivariate models. We simulated activity choices over 250 trials in each \ac{NAM} and \ac{EG}/\ac{IG} group using the observed success rates in conjunction with the fitted coefficients (randomly sampled with replacement over 500 iterations). As shown in \cref{fig:CH4_5} (\textbf{b}), the simulations reproduced the main patterns of  time allocation, including the preference for activity A4 in the \ac{EG} and \ac{IG} \ac{NAM}3 groups, and the preference for activity A1 in the \ac{NAM}1 and \ac{NAM}2 \ac{IG} groups (see \cref{fig:CH4_3}, \textbf{c}, for comparison), confirming that the bivariate models captured the main features of the empirical data.

% Figure 5
\begin{figure}[tbh!]
    \centering
    \includegraphics[width=\textwidth]{Figures/c4/figure5.pdf}
    \caption[short description]{Computational modeling results. \textbf{a}, The bivariate models had better AIC scores both across and within groups ($N_\mathrm{EG}=188$; $N_\mathrm{IG}=177$), compared to random-choice and univariate baselines univariate models. Box boundaries represent the 1st and the 3rd quartiles, and the lines inside show median scores; whiskers represent the full sample range. The dotted red line shows the AIC of the random-choice model. \textbf{b}, Fitted coefficients reproduce choice patterns across instruction and \ac{NAM} groups. The panels show the average time allocation patterns obtained by simulating activity choices over 250 trials using $N=500$ randomly sampled coefficients from the pool of all fitted bivariate models. \textbf{c}, Models of two distinct activity-selection strategies. The top row shows the joint distributions of normalized bivariate-utility coefficients. Subsets of these distributions whose data is presented below are highlighted with solid colors. These subsets were formed by first grouping all fitted models into three segments along $\hat w_{\mathrm{PC}}$ and $\hat w_{\mathrm{LP}}$, and then selecting groups corresponding to \ac{PC}-driven and \ac{LP}-driven profiles. Sample sizes of each subset are shown their respective subpanels. The bottom row shows mean relative frequencies of selecting each activity in the corresponding subset of participants depicted immediately above. LP-driven participants sampled the unlearnable activity (A4) in relative moderation compared the \ac{PC}-driven group. \textbf{d}, \ac{LP}-driven participants selected allocated time more efficiently for learning and had better learning outcomes. The top row shows fractions of participants in the two groups that reached an objective criterion of 13/15 trials on the hardest learnable activity (A3) at least once in the experiment. The middle row shows the relative preference for activity A4 over A3, defined as the difference between fractions of participants (that still have not mastered A3) who selected A4 minus the fraction selecting A3. The bottom row shows average \ac{SC} scores in the two groups (shaded regions indicate the standard error). Source data are provided as a Source Data file.}
    \label{fig:CH4_5}
\end{figure}

Computational theories suggest that sensitivities to \ac{PC} and \ac{LP} will have distinct contributions to activity choices and learning. While a sensitivity to \ac{PC} can motivate people to learn by steering them away from overly easy activities, a sensitivity to \ac{LP} may protect them from focusing on overly difficult or impossible activities. Several aspects of the $w_{\mathrm{PC}}$ and $w_{\mathrm{LP}}$ coefficients in our task support these hypotheses.

First, $w_{\mathrm{PC}}$ and $w_{\mathrm{LP}}$ coefficients were uncorrelated and showed different effects of instructions, suggesting that they capture different influences on choice strategies. We found no correlation between the $w_{\mathrm{PC}}$ and $w_{\mathrm{LP}}$ coefficients in the \ac{IG} group (Pearson correlation of normalized coefficients, \ac{IG} group: $r(186) = -.077,\ p = .298$); \ac{EG} group: $r(175) = .062,\ p = .399$; the normalization procedure is described in \cref{CH4_SSS_computational_modeling}, \textsc{Methods}/\textit{Computational modeling}). Moreover, the \ac{PC} coefficients were on average positive in the \ac{IG} group and negative in the \ac{EG} group (consistent with the groups' relative preferences for easier versus harder activities) while the \ac{LP} coefficients showed no effects of instructions (mean normalized \ac{PC} coefficient in \ac{IG}: $\text{M}_{\text{norm}} = 0.255,\ \text{SD} = 0.724$; in \ac{EG}: $\text{M}_{\text{norm}} = -0.232,\ \text{SD} = 0.741$; 1-way ANOVA, $F(1, 363) = 40.240,\ p < .001$; mean normalized \ac{LP} coefficient in \ac{IG}: $\text{M}_{\text{norm}} = 0.079, \text{SD} = 0.640$; in \ac{EG}: $\text{M}_{\text{norm}} = 0.062,\ \text{SD} = 0.631$; 1-way ANOVA, $F(1, 363) = 0.065,\ p = .799$).

Additional analyses supported the view that while both \ac{PC} and \ac{LP} coefficients correlate with higher self-challenge (Appendix \labelcref{fig:CH4A_4_self_challenge_index}, \textbf{c}), a sensitivity to \ac{LP} can steer people away from unlearnable activities. We first conducted a group-level analysis of the correlation between the coefficients and two model-free measures of task choices: the difference between the time devoted to A3 versus easier activities (indexing the tendency to choose more challenging learnable activities) and the difference between the time devoted to activity A4 relative to the other activities (indexing the tendency to choose the unlearnable activity). Across all participants, lower \ac{PC} coefficients coincided with a preference for choosing both A3 and A4, but $\hat w_{\mathrm{LP}}$ coefficients correlated only with a preference for the learnable, A3 activity (Appendix \labelcref{fig:CH4A_7_model_coefficients}).

To more closely examine the specific contribution of \ac{LP} sensitivity we focused on two subsets of participants whose choices were driven predominantly by, respectively, \ac{PC} or \ac{LP}. As shown in \cref{fig:CH4_5} (\textbf{c}, top), \ac{PC}-driven participants had negative \ac{PC} coefficients but near-zero \ac{LP} coefficients and \ac{LP}-driven participants had positive \ac{LP} coefficients but near-zero \ac{PC} coefficients (see \cref{CH4_SSS_computational_modeling}, \textsc{Methods}/\textit{Computational modeling}, for more details on the grouping procedure). While both groups preferred more difficult activities, the preference for A4 was lower in \ac{LP}-driven relative to \ac{PC}-driven participants. Linear regression models of time allocation as a function of activity (A3 or A4) and type of drive showed that \ac{PC}-driven people engaged in activity A4 more often relative to A3 in both the \ac{EG} and \ac{IG} groups (\ac{EG}: $\text{slope} = 76.485,\ t(104) = 7.019,\ p < .001$; \ac{IG}: $\text{slope} = 83.941,\ t(72) = 5.199,\ p < .001$) but this preference was lower or absent in \ac{LP}-driven participants as shown by its negative interaction with the type of drive (\ac{EG}: $\text{interaction slope} = -47.628,\ t(104) = -2.726,\ p < .001$; \ac{IG}: $\text{interaction slope} = -125.179,\ t(72) = -5.764,\ p < .001$).

Importantly, the lower preference for A4 enhanced learning outcomes in the \ac{LP}-driven relative to the \ac{PC}-driven group. As shown in \cref{fig:CH4_5} (\textbf{d}), after approximately trial 80, \ac{PC}-driven participants showed a prominent increase in choices of A4 in favor of A3 but this was not seen in the \ac{LP}-driven participants (\cref{fig:CH4_5}, \textbf{d}, middle row, captured as a decline in \ac{SC} in the latter group (\cref{fig:CH4_5}, \textbf{d}, bottom row). At around the same time, the fraction of participants mastering A3 in the \ac{LP}-driven group exceeded that in the \ac{PC}-driven group (\cref{fig:CH4_5}, \textbf{d}, top row). By the end of the free-play stage, the probability of mastering at least 2 activities was $90.48\%$ in the \ac{LP}-driven group versus $70.59\%$ the \ac{PC}-driven group, and the  probability of mastering all 3 tasks was, respectively, $64.29\%$ versus $34.98\%$. Thus, consistent with theoretical predictions, \ac{LP}-driven choices increase the efficiency of active learning by steering participants away from unlearnable activities.

\section{Discussion}
While the ability to self-organize study time is critical for learning success, finding an efficient organization poses a daunting computational challenge. Prominent theories such as the free energy principle postulate that animals are intrinsically motivated to optimize their explanatory models of the environment \parencite{collins2014human,schwartenbeck_computational_2019}. However, the strategies for optimal exploration that are proposed by these theories are limited to highly simplified laboratory conditions while being typically too complex to be computed in real-world situations \parencite{cohen_should_2007}. Similarly, mathematical models prescribing how students should allocate study time across competing activities show that optimal allocation is strongly sensitive to the precise shape of the learning trajectory, but this shape is typically unknown to the learner in advance \parencite{son_metacognitive_2006}. 

\ac{LP}-based algorithms solve this conundrum by generating intrinsic rewards for activities in which  learning recently occurred in practice, and thus provide a uniquely powerful means to optimize choices of study activity using a biologically plausible  mechanism. And yet, it is unknown whether or how such choice strategies influence human behavior. Here we use a free-choice paradigm in which participants allocate study time based on dynamic feedback history and provide direct empirical evidence that humans are sensitive to \ac{LP}.

Converging evidence suggests that humans tend to choose activities of intermediate complexity in a range of disparate settings - e.g., when spontaneously allocating visual attention in infancy \parencite{kidd_goldilocks_2012} or declaring aesthetic preference \parencite{tsutsui_complexity_2011,gold_predictability_2019,sauve2019information}. Our present results show that the preference for intermediate complexity extends to choices of learning activities \parencite[see also][]{baranes_effects_2014} and, most importantly, that it may be a manifestation of an underlying \ac{LP}-based mechanism. Thus, the ubiquitous preference for intermediate complexity reported in different settings may reflect an underlying mechanism that steers organisms toward activities that provide learning maximization.

Two major ideas in the literature postulate that exploration is structured based on the learner’s competence (prediction errors or error rates) or, alternatively, based on changes in competence over time (learning progress). However, whereas these strategies are typically framed as mutually exclusive alternatives, \parencite{kaplan2003motivational,kaplan_search_2007,mirolli_functions_2013,santucci_which_2013} our findings suggest that these two factors are uncorrelated and can jointly shape activity choices and contribute to different aspects of an investigative policy. A sensitivity to \ac{PC} -- with a preference for higher error rates -- motivates people to explore more difficult unfamiliar activities, while a sensitivity to \ac{LP} - the temporal derivative of \ac{PC}  - allows people to avoid unlearnable activities. 

The properties of \ac{PC}- and \ac{LP}-based control mechanisms in our data suggests that the relative influence of each type of control may depend on the set of available learning activities. Here we used a relatively simple setting in which the available activities can be quickly mastered, and found that a \ac{PC}-based strategy strongly contributed to the drive to choose challenging activities rather than stick with already-mastered tasks. However, if the environment is replete with challenging and unlearnable tasks, e.g., during realistic scientific investigation, an \ac{LP}-based strategy may be more critical for steering learners toward tasks where progress is made as proposed in artificial curiosity \parencite{kaplan_search_2007,schmidhuber2010formal,colas_curious_2019}.

Our results also pertain to the relation between extrinsic and intrinsic motivation - and specifically the debate whether extrinsic rewards bolster \parencite{duan2020effect} or suppress \parencite{murayama2019motivated} the intrinsic motivation to learn. Our findings suggest that the answer is more complex, as external objectives both enhanced and impaired different aspects of our learners' study strategy. On one hand, external objectives motivated participants to greater self-challenge, as people who were told to study for a test showed a greater tolerance for errors and better learning outcomes than those who did not. On the other hand, external instructions dampened learning achievement by inducing some participants to labor in vain on a random activity rather than learnable activity.

It is important to note that, while previous studies pitted intrinsic motivation against extrinsic monetary incentives \parencite[e.g.,][]{murayama2019motivated}, the extrinsic motivation for the \ac{EG} group in our task came from the specification of a learning objective. In addition, rather than rewarding participants for individual correct answers, our external instruction specified the end-goal but not the local strategy for achieving the goal; this allowed people to choose their activities and commit errors in the short term, in the interest of maximizing learning in the long term. This greater autonomy, we believe, contributed to the synergism we observed, whereby externally imposed goals enhanced the eventual learning outcomes, rather than hindering them. Our findings support two key postulates of self-determination theory stating that intrinsic and extrinsic motivations are not dichotomous but fall on a continuum, and that a sense of agency is a strong factor that motivates people to internalize and meet externally imposed goals \parencite{ryan_intrinsic_2020}. Thus, the most critical question may not be whether external objectives have beneficial or detrimental effects - but how to balance these objectives to support the investigative strategy that is most efficient in a particular context.

Last but not least, by examining investigations on longer time-scales, our results bear on the increasingly recognized distinction between momentary curiosity and sustained learning and interest \parencite{hidi_interest_2019,murayama_process_2019}. Beyond the brief satisfaction offered by fleeting (diversive) curiosity, long-term sustained interest, and the willingness to exert sustained effort in pursuit of such interests, can have profound influence on the lifelong acquisition of competence and skills \parencite{hidi_interest_2019,hidi_four-phase_2006}. Hidi and Renninger \citeyearpar{hidi_interest_2019,hidi_four-phase_2006} proposed a four-stage model of interest development, whereby situational interests is initially triggered and sustained (or dampened) by the environment but with time gives way to well-developed interest in which people spontaneously generate new questions and initiate investigations \parencite{son_metacognitive_2000}. The fact that many people in our \ac{IG} group mastered two or more tasks and reported subjective interest proportional to their time allocation (Appendix \labelcref{fig:CH4A_2_self_reported_ratings}), suggests that the activities we provided may have triggered their situational interest regardless of explicit instructions. The fact that higher achievements were more common in the \ac{EG} group suggests that external instructions help support that fledgling interest. Thus, important questions for future research concern the relation between the mechanisms by which people self-organize their activities, their subjective feelings of interest and the impact of both factors on the development of lifelong interests and skills.

Finally, the experimental setup implemented in our study allows researchers to fit and evaluate a larger scope of models. In this study we focused exclusively on modeling activity choices while eschewing assumptions about the learning process itself and the potentially complex factors that modulate it (including, e.g., forgetting, switching costs, effort, and preferences for uncertainty). However, follow-up work can easily extend the task design to allow for proper examination of these factors, for example by collecting subjective probability ratings to track participants' evolving inferences regarding each task. Moreover, while our task takes a step towards a more naturalistic lab setting by giving people the freedom to choose their own learning activities, it supplies a very limited set of learning activities. Future studies can benefit from the straightforward parametrization of the learning environment  (e.g., number of learning activities, difficulty levels, number of response categories, time horizon, etc.) to study how different drives self-organized learning according to context.

\section{Methods}\label{CH4_S_methods}

\subsection{Participants and Procedure}\label{CH4_SS_participants_and_procedure}

Four-hundred participants (including 208 female, 187 male, and 5 participants of undisclosed gender) were recruited for the study on the online platform Amazon Mechanical Turk. Participants were between 19 and 71 years of age, with an average age of $36.15$ years, $\text{SD} = 10.54$). All participants provided informed consent. All the procedures were approved by the Institutional Review Board of the University of Rochester.

All participants were told that the experiment will last 45 min to 1 hour and, upon completion, they will be compensated \$1 regardless of performance. This scheme was consistent with prevailing rates on Amazon MTurk and with our goals of minimizing the role of monetary incentives and avoiding biasing participants toward activities with consistently high performance. All participants were asked to complete the task on their own in a quiet environment and eliminate external distractions (e.g., turn off cell phones, TV sets, music players, etc.). After receiving detailed written instructions, each participant completed 4 task modules in sequence: (1) 15 forced-choice familiarization trials with each activity; (2) rating of prospective learnability for each task (see below); (3) a free-play stage with 250 trials of free-choice of activity; (4) 6 additional subjective ratings (see below).

Before delivery of the instruction, participants were randomly assigned to either \ac{EG} or \ac{IG} group The groups received identical treatments except for the initial instruction. The \ac{IG} participants received a task description that did not communicate any expectations or objectives on the part of the experimenters: “In each family there are several individuals, and the appearance of an individual might predict what food they like to eat. When you interact with a monster family, different individuals will be presented to you. For each individual, two food items will be displayed, and you can click on the one you think it prefers. You will receive feedback whether your guess was correct or not”, which was followed by brief descriptions of familiarization, free-choice, and questionnaire stages. The \ac{EG} participants’ instructions were identical, except for two additional sentences that included an explicit prescription of a learning goal: “In the main section of the task, we ask you to play for 250 trials and try to maximize your learning \textit{about all the 4 families}” followed by information on the post-session testing module re-emphasizing their objective: “We will briefly test how well you learned to predict the food preferences within each family”. After the free-play stage, participants in the \ac{EG} group received the announced test (between steps 3 and 4) consisting of 15 forced-choice trials on each activity. (However, in our analyses we used the last 15 trials on the free-play stage rather than the test data, as the latter were not available for the \ac{IG} group). Participants in both groups also provided several ratings of the activities, described in detail in Appendix \labelcref{CH4A_S_self_reported_ratings}.

\subsection{Data analyses}\label{CH4_SSS_computational_modeling}
All the $t$-tests reported throughout this chapter (including the Appendix) are two-tailed. We excluded a total of 18 participants -- 5 in the \ac{EG} and 13 in the \ac{IG} group -- who did not appear to be sufficiently engaged in the task based on a response bias criterion (see supplementary Appendix \labelcref{fig:CH4A_1_exclusion_criteria} for more details). This criterion measured the participants' tendency to choose a single response category in each activity (i.e., always guessing the same food item, regardless of the stimulus).
     
\subsubsection{Difficulty-weighted final performance}\label{CH4_SSS_difficulty_weighted_final_performance}
Difficulty weighted final \ac{PC} (\ac{dwfPC}) is a weighted average of each participant’s final \ac{PC} (fPC) on the learnable activities over the last 15 trials played on the activity. The weights are equal to the activity rank (1, 2 and 3) divided by the sum of the ranks (6). Thus, \ac{dwfPC} for participant $i$ is $\text{dwfPC}_i = \frac{1}{6}\text{fPC}_{i,A1} + \frac{1}{3}\text{fPC}_{i,A2} + \frac{1}{2}\text{fPC}_{i,A3}$. (Here and in all subsequent analyses we chose a 15-trial time window that was equal to the number of familiarization trials each participant played).
 
\subsubsection{\ac{NAM} designation}\label{CH4_SSS_nam_designation}
We divided participants into discrete groups based on the number of activities on which they reached a mastery criterion. The data presented in this article are based on a criterion of 13/15 correct trials ($86.7\%$ correct), which, in a binomial distribution with discrete outcomes, corresponds to $p = .0037$ of arising by chance. Additional analyses verified that the conclusions are robust over a range of criteria (see Appendix \labelcref{fig:CH4A_3_mastery_points}). Ten participants (5/154 in the \ac{IG} group and 5/176 in the \ac{EG} group) did not master any activity and were excluded from \ac{NAM}-related analyses and computational modeling.
 
\subsubsection{Self-challenge index}\label{CH4_SSS_self_challenge_index}
For each participant, we defined a self-challenge (SC) index for each trial $t$ and activity $i$ as: 
\begin{equation}\label{eq:sc}
    \text{SC}_{t,i} = 1-\frac{\text{PC}_{t,i}-\min\limits_{\forall k \in K}\text{PC}_{:t,k}}{\max\limits_{\forall k \in K}\text{PC}_{:t,k}-\min\limits_{\forall k \in K}\text{PC}_{:t,k}}
\end{equation}
where $\text{PC}_{t,i}$ is the recent \ac{PC} of the selected activity the participant selected on trial $t$ (measured over the last 15 trials on that activity, including familiarization trials) and where $\min\nolimits_{\forall k \in K}\text{PC}_{:t,k}$ and $\max\nolimits_{\forall k \in K}\text{PC}_{:t,k}$ are the minimum and maximum \ac{PC} experienced by the participant over the entire set of trials (including both free- and forced choice) prior to trial $t$ and over the entire set of activities $K$. Thus, \ac{SC} values close to 1 indicate a tendency to select activities that yield the minimum \ac{PC} (“over-challenging”) and values closer to 0 indicate a tendency to select activities with the highest \ac{PC} (“under-challenging”). To get a single \ac{SC} index for each participant, we averaged each participants' the trial-wise \ac{SC} scores across the entire free-play stage. Supplementary analyses verified that the \ac{SC} index was a better, more concise measure of the preference for challenging tasks relative to the pairwise preferences between different combinations of activities (see Appendix \labelcref{fig:CH4A_4_self_challenge_index}). 

\subsubsection{Computational modeling}\label{CH4_SSS_computational_modeling} 

To understand which intrinsic utility function could best explain the task sampling behavior, we consider a model in the bandit setting (\parencite{linke_adapting_2020}), where an intrinsic utility function for each task, measuring its value, is used to decide which task to sample probabilistically. The sampling mechanism used here is the softmax function, following prior models of human decision-making in \parencite{nussenbaum_reinforcement_2019}. This softmax function simultaneously translates the underlying choice utilities into selection probabilities and scales the correspondence between utility and probability: 
\begin{equation}\label{eq:softmax}
    p_t(\text{choice}_i) = \frac{e^{U_{i,t}\times\tau}}{\sum_{\forall k \in K}e^{U_{k,t}\times\tau}}
\end{equation}
$U_i$ is the subjective value of choice $i$, and $k$ indexes the utilities of all items in the set of available activities $K$ (including $i$); the parameter $\tau$, known as temperature, controls how strongly the item values determine the probability of their selection. $U$ was defined for each trial as described in the Results section (Computational modeling and sensitivity to LP), as a linear combination of two quantities that represent two aspects of learning: competence and change in competence. Both signals were defined for a retrospective time window of the last 15 trials played on the activity chosen at trial $i$  (including familiarization trials early in the free-play epoch): 
\begin{equation}\label{eq:pc}
    \text{PC}_{i,t} = \frac{1}{15}\sum_{t'=t-15}^{t} y_{t'}
\end{equation}
\begin{equation}\label{eq:lp}
    \text{LP}_{i,t} = \bigg|\Big(\frac{1}{10}\sum_{t'=t-15}^{t-5} y_{t'}\Big) - \Big(\frac{1}{9}\sum_{t'=t-9}^{t} y_{t'}\Big)\bigg|
\end{equation}
where $y_{t’}$ equals 1 or 0 if the participant guessed, respectively, correctly or in error at time $t’$. Hence, \ac{PC} was defined as the proportion of correct guesses over the last 15 trials, while \ac{LP} was defined as the absolute value of the difference in \ac{PC} over the first 10 and the last 9 of the same stretch of 15 trials. This implementation of  \ac{PC} and \ac{LP} signals is similar to machine learning models in \parencite{oudeyer_intrinsic_2007,colas_curious_2019,linke_adapting_2020}. In particular, one follows these computational approaches in using the absolute value of \ac{LP}, which was shown to enable learners to detect tasks where performances decrease, e.g., due to forgetting, and re-gain interest to re-focus on them \parencite{colas_curious_2019}.
 
An individual set of parameters was estimated  for each participant  by minimizing the negative sum of log likelihood values over the free play trials (see \parencite{daw2011trial}). Assuming that choice probabilities on a trial come from a categorical probability distribution, the likelihood of a model equals the probability (provided by the model) of the observed choice. The categorical distribution is a special case of the multinomial probability distribution, which provides the probabilities of $K$ discrete outcomes in a single sample. Thus, the likelihood of a model that predicts choices with probabilities $p_t$ is:
\begin{equation}\label{eq:likelihood}
    L(\textbf{p}_t \vert \text{choice}_i) = f(\text{choice}_i \vert \textbf{p}_t) = \prod_{j=1}^{K} p_t(\text{choice}_j)^{[i=j]}
\end{equation}
Where $\textbf{p}_t$ is a vector of probabilities at time $t$ associated with $K$ items indexed by $j$, and the term $[j = i]$ evaluates to 1 when $i$ is the activity that was chosen and to 0 otherwise. Thus, at the level of a single trial, higher likelihood is attributed to the model that assigns higher utility to the option chosen on the subsequent trial. For two and more trials, the likelihood of a model increases with the utility of the observed choices across trials. Therefore, in a maximum-likelihood model, a highly positive coefficient for a given learning signal reflects a tendency to choose options with higher values along that signal. Conversely, a highly negative coefficient for a feature indicates a tendency to choose options that have lower values along that feature, while coefficients close to zero reflect the indifference to the feature. The total likelihood of observing all choices from a participant is given by the product of likelihoods from individual trials, $\prod_t^T L(\textbf{p}_t \vert \text{choice})$. We take a logarithm of each individual trial's likelihood value in order to compute the overall model likelihood per individual as the sum of single-trial log likelihoods, $\sum_t^T \log L(\textbf{p}_t \vert \text{choice})$, rather than their product. Finally, we maximized this summed likelihood by minimizing its negative value using the L-BFGS-B nonlinear numerical optimization method \parencite{byrd1995limited}.
 
Values of the estimated parameters vary not only due to different choice data between participants, but also as a function of initialization of starting values in the parameter space. Because of this variability, we estimated a model multiple times for each participant using different parameter initializations for every fit, until a convergence criterion was reached. The utility parameters were initialized from a random uniform distribution between -1 and 1, and softmax temperature was randomly sampled from [0, 100]. Convergence was reached by repeatedly fitting a model with different random initializations until 50 maximum likelihood models were found. Concretely, the algorithm updated the current "best model" each time a model better the current best was found, and stopped when it found a model just as good as the current best 50 times.

For analyses of the relation between the coefficients, instructions and choices, we normalized each coefficient pair [$w_{\mathrm{PC}}$, $w_{\mathrm{LP}}$] by their Euclidean norm, allowing us to interpret the coefficients as relative preferences for \ac{PC} and \ac{LP}, respectively. 

To select participants driven predominantly by \ac{PC} or \ac{LP} (\cref{fig:CH4_5}, \textbf{c} and \textbf{d}), we categorized all participants into equally-spaced bins ($\text{bin}_1 = [-1.00, -0.33);\ \text{bin}_2 = [-0.33, 0.33);\ \text{bin}_3 = [0.33, 1.00]$) along each (normalized) coefficient. The \ac{PC}-driven group (\cref{fig:CH4_5}, \textbf{c}, left) had negative PC coefficients but near-zero influence of LP (intersection of $\text{bin}_1$ along \ac{PC} and $\text{bin}_2$ along \ac{LP} i.e., $\hat w_\text{LP} \approx 0,\ \hat w_\text{PC} \approx -1$), while the \ac{LP}-driven group (\cref{fig:CH4_5}, \textbf{c}, right) had a high preference for \ac{LP} but little preference to \ac{PC} ($\hat w_\text{LP} \approx 1,\ \hat w_\text{PC} \approx 0$). 