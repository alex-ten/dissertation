
@inproceedings{abdullahGeneratingUniversityCourse2008,
  title = {Generating {{University Course Timetable Using Genetic Algorithms}} and {{Local Search}}},
  booktitle = {2008 {{Third International Conference}} on {{Convergence}} and {{Hybrid Information Technology}}},
  author = {Abdullah, Salwani and Turabieh, Hamza},
  date = {2008-11},
  pages = {254--260},
  publisher = {{IEEE}},
  location = {{Busan, Korea}},
  doi = {10.1109/ICCIT.2008.379},
  url = {http://ieeexplore.ieee.org/document/4682035/},
  urldate = {2021-01-22},
  abstract = {In this paper we establish a new algorithm based on Genetic Algorithms (GA) and sequential local search to solve course timetabling problem. Universities are challenged to arise in number of complexity, their resources and events are becoming harder to schedule. Timetabling is a kind of problem in which events (classes, exams, courses, etc) have to be arranged into a number of timeslots such that conflicts in using a given set of resources are avoided. We perform preliminary experiments on standard benchmark course timetable problems and able to produce promising results.},
  eventtitle = {2008 {{Third International Conference}} on {{Convergence}} and {{Hybrid Information Technology}} ({{ICCIT}})},
  isbn = {978-0-7695-3407-7},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/72D9CMJ2/Abdullah and Turabieh - 2008 - Generating University Course Timetable Using Genet.pdf}
}

@article{adolphHowYouLearn2012,
  title = {How {{Do You Learn}} to {{Walk}}? {{Thousands}} of {{Steps}} and {{Dozens}} of {{Falls}} per {{Day}}},
  shorttitle = {How {{Do You Learn}} to {{Walk}}?},
  author = {Adolph, Karen E. and Cole, Whitney G. and Komati, Meghana and Garciaguirre, Jessie S. and Badaly, Daryaneh and Lingeman, Jesse M. and Chan, Gladys L. Y. and Sotsky, Rachel B.},
  date = {2012-11},
  journaltitle = {Psychological Science},
  shortjournal = {Psychol Sci},
  volume = {23},
  number = {11},
  pages = {1387--1394},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797612446346},
  url = {http://journals.sagepub.com/doi/10.1177/0956797612446346},
  urldate = {2021-01-22},
  abstract = {A century of research on the development of walking has examined periodic gait over a straight, uniform path. The current study provides the first corpus of natural infant locomotion derived from spontaneous activity during free play. Locomotor experience was immense: Twelve- to 19-month-olds averaged 2,368 steps and 17 falls per hour. Novice walkers traveled farther faster than expert crawlers, but had comparable fall rates, which suggests that increased efficiency without increased cost motivates expert crawlers to transition to walking. After walking onset, natural locomotion improved dramatically: Infants took more steps, traveled farther distances, and fell less. Walking was distributed in short bouts with variable paths—frequently too short or irregular to qualify as periodic gait. Nonetheless, measures of periodic gait and of natural locomotion were correlated, which indicates that better walkers spontaneously walk more and fall less. Immense amounts of time-distributed, variable practice constitute the natural practice regimen for learning to walk.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/S8J6VG2Q/Adolph et al. - 2012 - How Do You Learn to Walk Thousands of Steps and D.pdf}
}

@article{ahmadPropertiesSparseDistributed,
  title = {Properties of {{Sparse Distributed Representations}} and Their {{Application}} to {{Hierarchical Temporal Memory}}},
  author = {Ahmad, Subutai and Hawkins, Jeff},
  pages = {18},
  abstract = {Empirical evidence demonstrates that every region of the neocortex represents information using sparse activity patterns. This paper examines Sparse Distributed Representations (SDRs), the primary information representation strategy in Hierarchical Temporal Memory (HTM) systems and the neocortex. We derive a number of properties that are core to scaling, robustness, and generalization. We use the theory to provide practical guidelines and illustrate the power of SDRs as the basis of HTM. Our goal is to help create a unified mathematical and practical framework for SDRs as it relates to cortical function.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4IY794N3/Ahmad and Hawkins - Properties of Sparse Distributed Representations a.pdf}
}

@article{ahmadPropertiesSparseDistributeda,
  title = {Properties of {{Sparse Distributed Representations}} and Their {{Application}} to {{Hierarchical Temporal Memory}}},
  author = {Ahmad, Subutai and Hawkins, Jeff},
  pages = {18},
  abstract = {Empirical evidence demonstrates that every region of the neocortex represents information using sparse activity patterns. This paper examines Sparse Distributed Representations (SDRs), the primary information representation strategy in Hierarchical Temporal Memory (HTM) systems and the neocortex. We derive a number of properties that are core to scaling, robustness, and generalization. We use the theory to provide practical guidelines and illustrate the power of SDRs as the basis of HTM. Our goal is to help create a unified mathematical and practical framework for SDRs as it relates to cortical function.},
  langid = {english}
}

@article{aisIndividualConsistencyAccuracy2016,
  title = {Individual Consistency in the Accuracy and Distribution of Confidence Judgments},
  author = {Ais, Joaquín and Zylberberg, Ariel and Barttfeld, Pablo and Sigman, Mariano},
  date = {2016-01},
  journaltitle = {Cognition},
  shortjournal = {Cognition},
  volume = {146},
  pages = {377--386},
  issn = {00100277},
  doi = {10.1016/j.cognition.2015.10.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027715300846},
  urldate = {2021-01-22},
  abstract = {We examine which aspects of the confidence distributions – its shape, its bias toward higher or lower values, and its ability to distinguish correct from erred trials – are idiosyncratic of the who (individual specificity), the when (variability across days) and the what (task specificity). Measuring confidence across different sessions of four different perceptual tasks we show that: (1) Confidence distributions are virtually identical when measured in different days for the same subject and the same task, constituting a subjective fingerprint, (2) The capacity of confidence reports to distinguish correct from incorrect responses is only modestly (but significantly) correlated when compared across tasks, (3) Confidence distributions are very similar for tasks that involve different sensory modalities but have similar structure, (4) Confidence accuracy is independent of the mean and width of the confidence distribution, (5) The mean of the confidence distribution (an individual’s confidence bias) constitutes the most efficient indicator to infer a subject’s identity from confidence reports and (6) Confidence bias measured in simple perceptual decisions correlates with an individual’s optimism bias measured with standard questionnaire. Ó 2015 Elsevier B.V. All rights reserved.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KM46ILYD/Ais et al. - 2016 - Individual consistency in the accuracy and distrib.pdf}
}

@article{alterUnitingTribesFluency,
  title = {Uniting the {{Tribes}} of {{Fluency}} to {{Form}} a {{Metacognitive Nation}}},
  author = {Alter, Adam L},
  pages = {17},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NH8JWEPB/Alter - Uniting the Tribes of Fluency to Form a Metacognit.pdf}
}

@article{alterUnitingTribesFluencya,
  title = {Uniting the {{Tribes}} of {{Fluency}} to {{Form}} a {{Metacognitive Nation}}},
  author = {Alter, Adam L},
  pages = {17},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KD3UYUNI/Alter - Uniting the Tribes of Fluency to Form a Metacognit.pdf}
}

@article{andersonNullHypothesisTesting2000,
  title = {Null {{Hypothesis Testing}}: {{Problems}}, {{Prevalence}}, and an {{Alternative}}},
  author = {Anderson, David R. and Burnham, Kenneth P. and Thompson, William L.},
  date = {2000},
  journaltitle = {The Journal of Wildlife Management},
  volume = {64},
  number = {4},
  eprint = {3803199},
  eprinttype = {jstor},
  pages = {912--923},
  file = {/Users/alexten/Zotero/storage/39D32VE6/Anderson et al. - 2000 - Null Hypothesis Testing Problems, Prevalence, and.pdf}
}

@article{andersonNullHypothesisTesting2000a,
  title = {Null {{Hypothesis Testing}}: {{Problems}}, {{Prevalence}}, and an {{Alternative}}},
  shorttitle = {Null {{Hypothesis Testing}}},
  author = {Anderson, David R. and Burnham, Kenneth P. and Thompson, William L.},
  date = {2000-10},
  journaltitle = {The Journal of Wildlife Management},
  shortjournal = {The Journal of Wildlife Management},
  volume = {64},
  number = {4},
  eprint = {3803199},
  eprinttype = {jstor},
  pages = {912},
  issn = {0022541X},
  doi = {10.2307/3803199},
  file = {/Users/alexten/Zotero/storage/YCXGMKGU/Anderson et al. - 2000 - Null Hypothesis Testing Problems, Prevalence, and.pdf}
}

@article{andersonThereNoSucha,
  title = {There Is No Such Thing as Attention},
  author = {Anderson, Britt},
  journaltitle = {Frontiers in Psychology},
  pages = {8},
  abstract = {Given that the core issues of attention research have been recognized for millenia, we do not know as much about attention as we should. I argue that the reasons for this failure are (1) we create spurious dichotomies, (2) we reify attention, treating it as a cause, when it is an effect, and (3) we equate a collection of facts with a theory. In order to correct these errors, we need a new technical vocabulary that allows for attentional effects to be continuously distributed, rather than merely present or absent, and that provides a basis for quantitative behavioral predictions that map onto neural substrates. The terminology of the Bayesian decision process has already proved useful for structuring conceptual discussions in other psychological domains, such as perception and decision making under uncertainty, and it had demonstrated early success in the domain of attention. By rejecting a reified, causal conception of attention, in favor of theories that produce attentional effects as consequences, psychologists will be able to conduct more definitive experiments. Such conceptual advances will then enhance the productivity of neuroscientists by allowing them to concentrate their data collection efforts on the richest soil.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/G428TLSY/Anderson - There is no such thing as attention.pdf}
}

@article{andrewsFreeEnergyPrinciple,
  title = {The {{Free Energy Principle}}: {{An Accessible Introduction}} to Its {{Derivations}}, {{Applications}}, \& {{Implications}}},
  author = {Andrews, Mel},
  pages = {17},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8EWIEJ7W/Andrews - The Free Energy Principle An Accessible Introduct.pdf}
}

@article{andrewsFreeEnergyPrinciplea,
  title = {The {{Free Energy Principle}}: {{An Accessible Introduction}} to Its {{Derivations}}, {{Applications}}, \& {{Implications}}},
  author = {Andrews, Mel},
  pages = {17},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2TML5YKZ/Andrews - The Free Energy Principle An Accessible Introduct.pdf}
}

@article{anwyl-irvineGorillaOurMidst2020,
  title = {Gorilla in Our Midst: {{An}} Online Behavioral Experiment Builder},
  shorttitle = {Gorilla in Our Midst},
  author = {Anwyl-Irvine, Alexander L. and Massonnié, Jessica and Flitton, Adam and Kirkham, Natasha and Evershed, Jo K.},
  date = {2020-02},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {52},
  number = {1},
  pages = {388--407},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01237-x},
  url = {http://link.springer.com/10.3758/s13428-019-01237-x},
  urldate = {2021-06-23},
  abstract = {Behavioral researchers are increasingly conducting their studies online, to gain access to large and diverse samples that would be difficult to get in a laboratory environment. However, there are technical access barriers to building experiments online, and web browsers can present problems for consistent timing—an important issue with reaction-time-sensitive measures. For example, to ensure accuracy and test–retest reliability in presentation and response recording, experimenters need a working knowledge of programming languages such as JavaScript. We review some of the previous and current tools for online behavioral research, as well as how well they address the issues of usability and timing. We then present the Gorilla Experiment Builder (gorilla.sc), a fully tooled experiment authoring and deployment platform, designed to resolve many timing issues and make reliable online experimentation open and accessible to a wider range of technical abilities. To demonstrate the platform’s aptitude for accessible, reliable, and scalable research, we administered a task with a range of participant groups (primary school children and adults), settings (without supervision, at home, and under supervision, in both schools and public engagement events), equipment (participant’s own computer, computer supplied by the researcher), and connection types (personal internet connection, mobile phone 3G/4G). We used a simplified flanker task taken from the attentional network task (Rueda, Posner, \& Rothbart, 2004). We replicated the Bconflict network\^ effect in all these populations, demonstrating the platform’s capability to run reaction-time-sensitive experiments. Unresolved limitations of running experiments online are then discussed, along with potential solutions and some future features of the platform.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/L55XSGQK/Anwyl-Irvine et al. - 2020 - Gorilla in our midst An online behavioral experim.pdf}
}

@article{aston-jonesINTEGRATIVETHEORYLOCUS2005,
  title = {{{AN INTEGRATIVE THEORY OF LOCUS COERULEUS}}-{{NOREPINEPHRINE FUNCTION}}: {{Adaptive Gain}} and {{Optimal Performance}}},
  author = {Aston-Jones, Gary and Cohen, Jonathan D},
  date = {2005},
  pages = {50},
  abstract = {Historically, the locus coeruleus-norepinephrine (LC-NE) system has been implicated in arousal, but recent findings suggest that this system plays a more complex and specific role in the control of behavior than investigators previously thought. We review neurophysiological and modeling studies in monkey that support a new theory of LC-NE function. LC neurons exhibit two modes of activity, phasic and tonic. Phasic LC activation is driven by the outcome of task-related decision processes and is proposed to facilitate ensuing behaviors and to help optimize task performance (exploitation). When utility in the task wanes, LC neurons exhibit a tonic activity mode, associated with disengagement from the current task and a search for alternative behaviors (exploration). Monkey LC receives prominent, direct inputs from the anterior cingulate (ACC) and orbitofrontal cortices (OFC), both of which are thought to monitor task-related utility. We propose that these frontal areas produce the above patterns of LC activity to optimize utility on both short and long timescales.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Y9247ETH/Aston-Jones and Cohen - 2005 - AN INTEGRATIVE THEORY OF LOCUS COERULEUS-NOREPINEP.pdf}
}

@article{averbeckMotivationalNeuralCircuits2017,
  title = {Motivational Neural Circuits Underlying Reinforcement Learning},
  author = {Averbeck, Bruno B and Costa, Vincent D},
  date = {2017},
  journaltitle = {nature neuroscience},
  volume = {20},
  number = {4},
  pages = {9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CIZL6FGK/Averbeck and Costa - 2017 - Motivational neural circuits underlying reinforcem.pdf}
}

@article{balcetisSeeWhatYoua,
  title = {See {{What You Want}} to {{See}}: {{Motivational Influences}} on {{Visual Perception}}},
  author = {Balcetis, Emily and Dunning, David},
  pages = {14},
  abstract = {People’s motivational states—their wishes and preferences—influence their processing of visual stimuli. In 5 studies, participants shown an ambiguous figure (e.g., one that could be seen either as the letter B or the number 13) tended to report seeing the interpretation that assigned them to outcomes they favored. This finding was affirmed by unobtrusive and implicit measures of perception (e.g., eye tracking, lexical decision tasks) and by experimental procedures demonstrating that participants were aware only of the single (usually favored) interpretation they saw at the time they viewed the stimulus. These studies suggest that the impact of motivation on information processing extends down into preconscious processing of stimuli in the visual environment and thus guides what the visual system presents to conscious awareness.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KCA4UHFP/Balcetis and Dunning - See What You Want to See Motivational Influences .pdf}
}

@article{baldassarreIntrinsicMotivationsOpenended,
  title = {Intrinsic Motivations and Open-Ended Development in Animals, Humans, and Robots: An Overview},
  author = {Baldassarre, Gianluca},
  journaltitle = {Frontiers in Psychology},
  pages = {5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/28QV2UWA/Baldassarre - Intrinsic motivations and open-ended development i.pdf}
}

@article{baranesActiveLearningInverse2013,
  title = {Active Learning of Inverse Models with Intrinsically Motivated Goal Exploration in Robots},
  author = {Baranes, Adrien},
  date = {2013},
  journaltitle = {Robotics and Autonomous Systems},
  pages = {25},
  abstract = {We introduce the Self-Adaptive Goal Generation Robust Intelligent Adaptive Curiosity (SAGG-RIAC) architecture as an intrinsically motivated goal exploration mechanism which allows active learning of inverse models in high-dimensional redundant robots. This allows a robot to efficiently and actively learn distributions of parameterized motor skills/policies that solve a corresponding distribution of parameterized tasks/goals. The architecture makes the robot sample actively novel parameterized tasks in the task space, based on a measure of competence progress, each of which triggers low-level goal-directed learning of the motor policy parameters that allow to solve it. For both learning and generalization, the system leverages regression techniques which allow to infer the motor policy parameters corresponding to a given novel parameterized task, and based on the previously learnt correspondences between policy and task parameters.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/E99VEHEP/Baranes - 2013 - Active learning of inverse models with intrinsical.pdf}
}

@article{baranesEffectsTaskDifficulty,
  title = {The Effects of Task Difficulty, Novelty and the Size of the Search Space on Intrinsically Motivated Exploration},
  author = {Baranes, Adrien F and Oudeyer, Pierre-Yves and Gottlieb, Jacqueline},
  journaltitle = {Frontiers in Neuroscience},
  pages = {10},
  abstract = {Devising efficient strategies for exploration in large open-ended spaces is one of the most difficult computational problems of intelligent organisms. Because the available rewards are ambiguous or unknown during the exploratory phase, subjects must act in intrinsically motivated fashion. However, a vast majority of behavioral and neural studies to date have focused on decision making in reward-based tasks, and the rules guiding intrinsically motivated exploration remain largely unknown. To examine this question we developed a paradigm for systematically testing the choices of human observers in a free play context. Adult subjects played a series of short computer games of variable difficulty, and freely choose which game they wished to sample without external guidance or physical rewards. Subjects performed the task in three distinct conditions where they sampled from a small or a large choice set (7 vs. 64 possible levels of difficulty), and where they did or did not have the possibility to sample new games at a constant level of difficulty. We show that despite the absence of external constraints, the subjects spontaneously adopted a structured exploration strategy whereby they (1) started with easier games and progressed to more difficult games, (2) sampled the entire choice set including extremely difficult games that could not be learnt, (3) repeated moderately and high difficulty games much more frequently than was predicted by chance, and (4) had higher repetition rates and chose higher speeds if they could generate new sequences at a constant level of difficulty. The results suggest that intrinsically motivated exploration is shaped by several factors including task difficulty, novelty and the size of the choice set, and these come into play to serve two internal goals—maximize the subjects’ knowledge of the available tasks (exploring the limits of the task set), and maximize their competence (performance and skills) across the task set.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PD9ERK69/Baranes et al. - The effects of task difﬁculty, novelty and the siz.pdf}
}

@article{baranesEyeMovementsReveal2015,
  title = {Eye Movements Reveal Epistemic Curiosity in Human Observers},
  author = {Baranes, Adrien and Oudeyer, Pierre-Yves and Gottlieb, Jacqueline},
  date = {2015-12},
  journaltitle = {Vision Research},
  shortjournal = {Vision Research},
  volume = {117},
  pages = {81--90},
  issn = {00426989},
  doi = {10.1016/j.visres.2015.10.009},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0042698915003430},
  urldate = {2021-01-22},
  abstract = {Saccadic (rapid) eye movements are primary means by which humans and non-human primates sample visual information. However, while saccadic decisions are intensively investigated in instrumental contexts where saccades guide subsequent actions, it is largely unknown how they may be influenced by curiosity – the intrinsic desire to learn. While saccades are sensitive to visual novelty and visual surprise, no study has examined their relation to epistemic curiosity – interest in symbolic, semantic information. To investigate this question, we tracked the eye movements of human observers while they read trivia questions and, after a brief delay, were visually given the answer. We show that higher curiosity was associated with earlier anticipatory orienting of gaze toward the answer location without changes in other metrics of saccades or fixations, and that these influences were distinct from those produced by variations in confidence and surprise. Across subjects, the enhancement of anticipatory gaze was correlated with measures of trait curiosity from personality questionnaires. Finally, a machine learning algorithm could predict curiosity in a cross-subject manner, relying primarily on statistical features of the gaze position before the answer onset and independently of covariations in confidence or surprise, suggesting potential practical applications for educational technologies, recommender systems and research in cognitive sciences. With this article, we provide full access to the annotated database allowing readers to reproduce the results. Epistemic curiosity produces specific effects on oculomotor anticipation that can be used to read out curiosity states.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4KBMJVIZ/Baranes - 2015 - Eye movements reveal epistemic curiosity in human .pdf;/Users/alexten/Zotero/storage/ATKY3QGP/Baranes et al. - 2015 - Eye movements reveal epistemic curiosity in human .pdf}
}

@article{baronModeratorMediatorVariableDistinction,
  title = {The {{Moderator}}-{{Mediator Variable Distinction}} in {{Social Psychological Research}}: {{Conceptual}}, {{Strategic}}, and {{Statistical Considerations}}},
  author = {Baron, Reuben M and Kenny, David A},
  pages = {10},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JSJ2V5KB/Baron and Kenny - The Moderator-Mediator Variable Distinction in Soc.pdf}
}

@article{barrettMeasuresMetacognitionSignaldetectiona,
  title = {Measures of Metacognition on Signal-Detection Theoretic Models},
  author = {Barrett, Adam B and Dienes, Zoltan and Seth, Anil K},
  pages = {63},
  abstract = {Analysing metacognition, specifically knowledge of accuracy of internal perceptual, memorial or other knowledge states, is vital for many strands of psychology, including determining the accuracy of feelings of knowing, and discriminating conscious from unconscious cognition. Quantifying metacognitive sensitivity is however more challenging than quantifying basic stimulus sensitivity. Under popular signal detection theory (SDT) models for stimulus classification tasks, approaches based on type II receiver-operator characteristic (ROC) curves or type II d-prime risk confounding metacognition with response biases in either the type I (classification) or type II (metacognitive) tasks. A new approach introduces meta-d′: the type I d-prime that would have led to the observed type II data had the subject used all the type I information. Here we (i) further establish the inconsistency of the type II d-prime and ROC approaches with new explicit analyses of the standard SDT model, and (ii) analyse, for the first time, the behaviour of meta-d′ under non-trivial scenarios, such as when metacognitive judgments utilize enhanced or degraded versions of the type I evidence. Analytically, meta-d′ values typically reflect the underlying model well, and are stable under changes in decision criteria; however, in relatively extreme cases meta-d′ can become unstable. We explore bias and variance of in-sample measurements of meta-d′ and supply MATLAB code for estimation in general cases. Our results support meta-d′ as a useful measure of metacognition, and provide rigorous methodology for its application. Our recommendations are useful for any researchers interested in assessing metacognitive accuracy.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/X4K9FYM8/Barrett et al. - Measures of metacognition on signal-detection theo.pdf}
}

@article{barronEmbracingMultipleDefinitions,
  title = {Embracing Multiple Definitions of Learning},
  author = {Barron, Andrew B and Hebets, Eileen A and Cleland, Thomas A and Fitzpatrick, Courtney L and Hauber, Mark E},
  pages = {13},
  abstract = {Definitions of learning vary widely across disciplines, driven largely by different approaches used to assess its occurrence. These definitions can be better reconciled with each other if each is recognized as coherent with a common conceptualization of learning, while appreciating the practical utility of different learning definitions in different contexts.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7JUFYNI3/Barron et al. - Embracing multiple definitions of learning.pdf;/Users/alexten/Zotero/storage/WTFZND85/Barron et al. - Embracing multiple definitions of learning.pdf}
}

@article{bartoAdaptiveCriticsBasal,
  title = {Adaptive {{Critics}} and the {{Basal Ganglia}}},
  author = {Barto, Andrew G},
  pages = {20},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KY5BM5JA/Barto - Adaptive Critics and the Basal Ganglia.pdf}
}

@article{bartoNoveltySurprise,
  title = {Novelty or {{Surprise}}?},
  author = {Barto, Andrew},
  journaltitle = {Frontiers in Psychology},
  pages = {15},
  abstract = {Novelty and surprise play significant roles in animal behavior and in attempts to understand the neural mechanisms underlying it. They also play important roles in technology, where detecting observations that are novel or surprising is central to many applications, such as medical diagnosis, text processing, surveillance, and security. Theories of motivation, particularly of intrinsic motivation, place novelty and surprise among the primary factors that arouse interest, motivate exploratory or avoidance behavior, and drive learning. In many of these studies, novelty and surprise are not distinguished from one another: the words are used more-or-less interchangeably. However, while undeniably closely related, novelty and surprise are very different. The purpose of this article is first to highlight the differences between novelty and surprise and to discuss how they are related by presenting an extensive review of mathematical and computational proposals related to them, and then to explore the implications of this for understanding behavioral and neuroscience data. We argue that opportunities for improved understanding of behavior and its neural basis are likely being missed by failing to distinguish between novelty and surprise.},
  langid = {english}
}

@article{bartoNoveltySurprisea,
  title = {Novelty or {{Surprise}}?},
  author = {Barto, Andrew},
  journaltitle = {Frontiers in Psychology},
  pages = {15},
  abstract = {Novelty and surprise play significant roles in animal behavior and in attempts to understand the neural mechanisms underlying it. They also play important roles in technology, where detecting observations that are novel or surprising is central to many applications, such as medical diagnosis, text processing, surveillance, and security. Theories of motivation, particularly of intrinsic motivation, place novelty and surprise among the primary factors that arouse interest, motivate exploratory or avoidance behavior, and drive learning. In many of these studies, novelty and surprise are not distinguished from one another: the words are used more-or-less interchangeably. However, while undeniably closely related, novelty and surprise are very different. The purpose of this article is first to highlight the differences between novelty and surprise and to discuss how they are related by presenting an extensive review of mathematical and computational proposals related to them, and then to explore the implications of this for understanding behavioral and neuroscience data. We argue that opportunities for improved understanding of behavior and its neural basis are likely being missed by failing to distinguish between novelty and surprise.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CPDLWYF5/Barto - Novelty or Surprise.pdf}
}

@article{bartoRecentAdvancesHierarchical,
  title = {Recent {{Advances}} in {{Hierarchical Reinforcement Learning}}},
  author = {Barto, Andrew G and Mahadevan, Sridhar},
  journaltitle = {Discrete Event Dynamic Systems},
  pages = {37},
  abstract = {Reinforcement learning is bedeviled by the curse of dimensionality: the number of parameters to be learned grows exponentially with the size of any compact encoding of a state. Recent attempts to combat the curse of dimensionality have turned to principled ways of exploiting temporal abstraction, where decisions are not required at each step, but rather invoke the execution of temporally-extended activities which follow their own policies until termination. This leads naturally to hierarchical control architectures and associated learning algorithms. We review several approaches to temporal abstraction and hierarchical organization that machine learning researchers have recently developed. Common to these approaches is a reliance on the theory of semiMarkov decision processes, which we emphasize in our review. We then discuss extensions of these ideas to concurrent activities, multiagent coordination, and hierarchical memory for addressing partial observability. Concluding remarks address open challenges facing the further development of reinforcement learning in a hierarchical setting.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/A5AWQX39/Barto and Mahadevan - Recent Advances in Hierarchical Reinforcement Lear.pdf}
}

@article{bartoRecentAdvancesHierarchicala,
  title = {Recent {{Advances}} in {{Hierarchical Reinforcement Learning}}},
  author = {Barto, Andrew G and Mahadevan, Sridhar},
  journaltitle = {Discrete Event Dynamic Systems},
  pages = {37},
  abstract = {Reinforcement learning is bedeviled by the curse of dimensionality: the number of parameters to be learned grows exponentially with the size of any compact encoding of a state. Recent attempts to combat the curse of dimensionality have turned to principled ways of exploiting temporal abstraction, where decisions are not required at each step, but rather invoke the execution of temporally-extended activities which follow their own policies until termination. This leads naturally to hierarchical control architectures and associated learning algorithms. We review several approaches to temporal abstraction and hierarchical organization that machine learning researchers have recently developed. Common to these approaches is a reliance on the theory of semiMarkov decision processes, which we emphasize in our review. We then discuss extensions of these ideas to concurrent activities, multiagent coordination, and hierarchical memory for addressing partial observability. Concluding remarks address open challenges facing the further development of reinforcement learning in a hierarchical setting.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UD2I3FH9/Barto and Mahadevan - Recent Advances in Hierarchical Reinforcement Lear.pdf}
}

@article{batesFittingLinearMixedEffects,
  title = {Fitting {{Linear Mixed}}-{{Effects Models}} Using Lme4},
  author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
  journaltitle = {Journal of Statistical Software},
  pages = {48},
  abstract = {Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/VHVHIUK4/Bates et al. - Fitting Linear Mixed-Effects Models using lme4.pdf}
}

@article{batesFittingLinearMixedEffects2015,
  title = {Fitting {{Linear Mixed}}-{{Effects Models Using}} {\textbf{Lme4}}},
  author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
  date = {2015},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {67},
  number = {1},
  issn = {1548-7660},
  doi = {10.18637/jss.v067.i01},
  url = {http://www.jstatsoft.org/v67/i01/},
  urldate = {2021-01-22},
  abstract = {Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Z7ERLAV5/Bates et al. - 2015 - Fitting Linear Mixed-Effects Models Using lme4.pdf}
}

@article{batesFittingLinearMixedEffects2015a,
  title = {Fitting {{Linear Mixed}}-{{Effects Models Using}} {\textbf{Lme4}}},
  author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
  date = {2015},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {67},
  number = {1},
  issn = {1548-7660},
  doi = {10.18637/jss.v067.i01},
  url = {http://www.jstatsoft.org/v67/i01/},
  urldate = {2021-06-23},
  abstract = {Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FG72K7PP/Bates et al. - 2015 - Fitting Linear Mixed-Effects Models Using lme4.pdf}
}

@online{battagliaRelationalInductiveBiases2018,
  title = {Relational Inductive Biases, Deep Learning, and Graph Networks},
  author = {Battaglia, Peter W. and Hamrick, Jessica B. and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and Gulcehre, Caglar and Song, Francis and Ballard, Andrew and Gilmer, Justin and Dahl, George and Vaswani, Ashish and Allen, Kelsey and Nash, Charles and Langston, Victoria and Dyer, Chris and Heess, Nicolas and Wierstra, Daan and Kohli, Pushmeet and Botvinick, Matt and Vinyals, Oriol and Li, Yujia and Pascanu, Razvan},
  date = {2018-10-17},
  eprint = {1806.01261},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1806.01261},
  urldate = {2021-01-22},
  abstract = {Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one’s experiences—a hallmark of human intelligence from infancy—remains a formidable challenge for modern AI.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/DIHJU2YL/Battaglia et al. - 2018 - Relational inductive biases, deep learning, and gr.pdf}
}

@online{battagliaRelationalInductiveBiases2018a,
  title = {Relational Inductive Biases, Deep Learning, and Graph Networks},
  author = {Battaglia, Peter W. and Hamrick, Jessica B. and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and Gulcehre, Caglar and Song, Francis and Ballard, Andrew and Gilmer, Justin and Dahl, George and Vaswani, Ashish and Allen, Kelsey and Nash, Charles and Langston, Victoria and Dyer, Chris and Heess, Nicolas and Wierstra, Daan and Kohli, Pushmeet and Botvinick, Matt and Vinyals, Oriol and Li, Yujia and Pascanu, Razvan},
  date = {2018-10-17},
  eprint = {1806.01261},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1806.01261},
  urldate = {2021-01-22},
  abstract = {Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one’s experiences—a hallmark of human intelligence from infancy—remains a formidable challenge for modern AI.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/D2UK5E4X/Battaglia et al. - 2018 - Relational inductive biases, deep learning, and gr.pdf}
}

@article{baumMolecularMolarParadigm2002,
  title = {From Molecular to Molar: {{A}} Paradigm Shift in Behavior Analysis},
  shorttitle = {{{FROM MOLECULAR TO MOLAR}}},
  author = {Baum, William M.},
  date = {2002-07},
  journaltitle = {Journal of the Experimental Analysis of Behavior},
  volume = {78},
  number = {1},
  pages = {95--116},
  issn = {00225002},
  doi = {10.1901/jeab.2002.78-95},
  url = {http://doi.wiley.com/10.1901/jeab.2002.78-95},
  urldate = {2021-07-04},
  abstract = {A paradigm clash is occurring within behavior analysis. In the older paradigm, the molecular view, behavior consists of momentary or discrete responses that constitute instances of classes. Variation in response rate reflects variation in the strength or probability of the response class. The newer paradigm, the molar view, sees behavior as composed of activities that take up varying amounts of time. Whereas the molecular view takes response rate and choice to be ‘‘derived’’ measures and hence abstractions, the molar view takes response rate and choice to be concrete temporally extended behavioral allocations and regards momentary ‘‘responses’’ as abstractions. Research findings that point to variation in tempo, asymmetry in concurrent performance, and paradoxical resistance to change are readily interpretable when seen in the light of reinforcement and stimulus control of extended behavioral allocations or activities. Seen in the light of the ontological distinction between classes and individuals, extended behavioral allocations, like species in evolutionary taxonomy, constitute individuals, entities that change without changing their identity. Seeing allocations as individuals implies that less extended activities constitute parts of larger wholes rather than instances of classes. Both laboratory research and everyday behavior are explained plausibly in the light of concrete extended activities and their nesting. The molecular view, because it requires discrete responses and contiguous events, relies on hypothetical stimuli and consequences to account for the same phenomena. One may prefer the molar view on grounds of elegance, integrative power, and plausibility.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/P2X568Q5/Baum - 2002 - FROM MOLECULAR TO MOLAR A PARADIGM SHIFT IN BEHAV.pdf}
}

@article{beerDynamicalSystemsPerspective,
  title = {A Dynamical Systems Perspective on Agent-Environment Interaction},
  author = {Beer, Randall D},
  pages = {43},
  abstract = {Using the language of dynamical systems theory, a general theoretical framework for the synthesis and analysis of autonomous agents is sketched. In this framework, an agent and its environment are modeled as two coupled dynamical systems whose mutual interaction is in general jointly responsible for the agent’s behavior. In addition, the adaptive fit between an agent and its environment is characterized in terms of the satisfaction of a given constraint on the trajectories of the coupled agent-environment system. The utility of this framework is demonstrated by using it to first synthesize and then analyze a walking behavior for a legged agent.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JQM8NXWC/Beer - A dynamical systems perspective on agent-environme.pdf}
}

@article{behrensLearningValueInformation2007,
  title = {Learning the Value of Information in an Uncertain World},
  author = {Behrens, Timothy E J and Woolrich, Mark W and Walton, Mark E and Rushworth, Matthew F S},
  date = {2007},
  journaltitle = {NATURE NEUROSCIENCE},
  volume = {10},
  number = {9},
  pages = {8},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UZ6CW2LC/Behrens et al. - 2007 - Learning the value of information in an uncertain .pdf}
}

@article{behrensLearningValueInformation2007a,
  title = {Learning the Value of Information in an Uncertain World},
  author = {Behrens, Timothy E J and Woolrich, Mark W and Walton, Mark E and Rushworth, Matthew F S},
  date = {2007-09},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {10},
  number = {9},
  pages = {1214--1221},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn1954},
  url = {http://www.nature.com/articles/nn1954},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FGRBNPVX/Behrens et al. - 2007 - Learning the value of information in an uncertain .pdf}
}

@article{behrensWhatCognitiveMap,
  title = {What {{Is}} a {{Cognitive Map}}? {{Organizing Knowledge}} for {{Flexible Behavior}}},
  author = {Behrens, Timothy E J},
  pages = {20},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GQLA2RIV/Behrens - What Is a Cognitive Map Organizing Knowledge for .pdf;/Users/alexten/Zotero/storage/J4WAHHMR/Behrens - What Is a Cognitive Map Organizing Knowledge for .pdf}
}

@article{bennettIntrinsicValuationInformation2016,
  title = {Intrinsic {{Valuation}} of {{Information}} in {{Decision Making}} under {{Uncertainty}}},
  author = {Bennett, Daniel and Bode, Stefan and Brydevall, Maja and Warren, Hayley and Murawski, Carsten},
  date = {2016},
  journaltitle = {PLOS Computational Biology},
  pages = {21},
  abstract = {In a dynamic world, an accurate model of the environment is vital for survival, and agents ought regularly to seek out new information with which to update their world models. This aspect of behaviour is not captured well by classical theories of decision making, and the cognitive mechanisms of information seeking are poorly understood. In particular, it is not known whether information is valued only for its instrumental use, or whether humans also assign it a non-instrumental intrinsic value. To address this question, the present study assessed preference for non-instrumental information among 80 healthy participants in two experiments. Participants performed a novel information preference task in which they could choose to pay a monetary cost to receive advance information about the outcome of a monetary lottery. Importantly, acquiring information did not alter lottery outcome probabilities. We found that participants were willing to incur considerable monetary costs to acquire payoff-irrelevant information about the lottery outcome. This behaviour was well explained by a computational cognitive model in which information preference resulted from aversion to temporally prolonged uncertainty. These results strongly suggest that humans assign an intrinsic value to information in a manner inconsistent with normative accounts of decision making under uncertainty. This intrinsic value may be associated with adaptive behaviour in real-world environments by producing a bias towards exploratory and information-seeking behaviour.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CW7QJMYK/Bennett et al. - 2016 - Intrinsic Valuation of Information in Decision Mak.pdf;/Users/alexten/Zotero/storage/QWGYW82P/Bennett et al. - 2016 - Intrinsic Valuation of Information in Decision Mak.pdf}
}

@article{berridgeAffectiveNeurosciencePleasure,
  title = {Affective Neuroscience of Pleasure: Reward in Humans and Animals},
  author = {Berridge, Kent C and Kringelbach, Morten L},
  pages = {24},
  abstract = {Introduction Pleasure and reward are generated by brain circuits that are largely shared between humans and other animals.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/23MDGYI5/Berridge and Kringelbach - Affective neuroscience of pleasure reward in huma.pdf;/Users/alexten/Zotero/storage/M7Y2VUTK/Berridge and Kringelbach - Affective neuroscience of pleasure reward in huma.pdf}
}

@article{berridgePleasureSystemsBrain,
  title = {Pleasure {{Systems}} in the {{Brain}}},
  author = {Berridge, Kent C},
  pages = {19},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/LUQ3PR9T/Berridge - Pleasure Systems in the Brain.pdf}
}

@article{berridgePleasureSystemsBrain2015,
  title = {Pleasure {{Systems}} in the {{Brain}}},
  author = {Berridge, Kent C. and Kringelbach, Morten L.},
  date = {2015-05},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {86},
  number = {3},
  pages = {646--664},
  issn = {08966273},
  doi = {10.1016/j.neuron.2015.02.018},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315001336},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5XH3GL8U/Berridge and Kringelbach - 2015 - Pleasure Systems in the Brain.pdf}
}

@article{bezerianosGeneaQuiltsSystemExploring,
  title = {{{GeneaQuilts}}: {{A System}} for {{Exploring Large Genealogies}}},
  author = {Bezerianos, Anastasia and Dragicevic, Pierre and Fekete, Jean-Daniel and Bae, Juhee and Watson, Ben},
  pages = {10},
  abstract = {GeneaQuilts is a new visualization technique for representing large genealogies of up to several thousand individuals. The visualization takes the form of a diagonally-filled matrix, where rows are individuals and columns are nuclear families. After identifying the major tasks performed in genealogical research and the limits of current software, we present an interactive genealogy exploration system based on GeneaQuilts. The system includes an overview, a timeline, search and filtering components, and a new interaction technique called Bring \& Slide that allows fluid navigation in very large genealogies. We report on preliminary feedback from domain experts and show how our system supports a number of their tasks.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/K396MEIW/Bezerianos et al. - 2010 - GeneaQuilts A System for Exploring Large Genealog.pdf;/Users/alexten/Zotero/storage/Q8A4ECZV/Bezerianos et al. - GeneaQuilts A System for Exploring Large Genealog.pdf}
}

@article{binksTestingEnhancesLearning2018,
  title = {Testing Enhances Learning: {{A}} Review of the Literature},
  shorttitle = {Testing Enhances Learning},
  author = {Binks, Sally},
  date = {2018-05},
  journaltitle = {Journal of Professional Nursing},
  shortjournal = {Journal of Professional Nursing},
  volume = {34},
  number = {3},
  pages = {205--210},
  issn = {87557223},
  doi = {10.1016/j.profnurs.2017.08.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S8755722317301047},
  urldate = {2021-01-22},
  abstract = {The retrieval of information from memory through testing produces learning advantages that are superior to studying alone; a phenomenon called the testing effect. Despite strong and consistent evidence that testing improves retention and recall of information, and superior organization of information within memory, testing continues to be under-utilized as a pedagogical strategy by teachers and as a self-regulatory strategy by learners. Testing that promotes recall rather than recognition of information, that is repeated at intervals over time, and that is accompanied by feedback is optimal for promoting learning. In addition to using testing as a powerful teaching tool, educators should promote the use of self-testing by learners to support the life-long learning that is essential to professional practice.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/HWCCHZLF/Binks - 2018 - Testing enhances learning A review of the literat.pdf}
}

@article{binksTestingEnhancesLearning2018a,
  title = {Testing Enhances Learning: {{A}} Review of the Literature},
  shorttitle = {Testing Enhances Learning},
  author = {Binks, Sally},
  date = {2018-05},
  journaltitle = {Journal of Professional Nursing},
  shortjournal = {Journal of Professional Nursing},
  volume = {34},
  number = {3},
  pages = {205--210},
  issn = {87557223},
  doi = {10.1016/j.profnurs.2017.08.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S8755722317301047},
  urldate = {2021-01-22},
  abstract = {The retrieval of information from memory through testing produces learning advantages that are superior to studying alone; a phenomenon called the testing effect. Despite strong and consistent evidence that testing improves retention and recall of information, and superior organization of information within memory, testing continues to be under-utilized as a pedagogical strategy by teachers and as a self-regulatory strategy by learners. Testing that promotes recall rather than recognition of information, that is repeated at intervals over time, and that is accompanied by feedback is optimal for promoting learning. In addition to using testing as a powerful teaching tool, educators should promote the use of self-testing by learners to support the life-long learning that is essential to professional practice.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/HEC45SCS/Binks - 2018 - Testing enhances learning A review of the literat.pdf}
}

@online{blakemanComplementaryLearningSystems2019,
  title = {A {{Complementary Learning Systems Approach}} to {{Temporal Difference Learning}}},
  author = {Blakeman, Sam and Mareschal, Denis},
  date = {2019-05-07},
  eprint = {1905.02636},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio},
  url = {http://arxiv.org/abs/1905.02636},
  urldate = {2021-01-22},
  abstract = {Complementary Learning Systems (CLS) theory suggests that the brain uses a ’neocortical’ and a ’hippocampal’ learning system to achieve complex behavior. These two systems are complementary in that the ’neocortical’ system relies on slow learning of distributed representations while the ’hippocampal’ system relies on fast learning of pattern-separated representations. Both of these systems project to the striatum, which is a key neural structure in the brain’s implementation of Reinforcement Learning (RL). Current deep RL approaches share similarities with a ’neocortical’ system because they slowly learn distributed representations through backpropagation in Deep Neural Networks (DNNs). An ongoing criticism of such approaches is that they are data inefficient and lack flexibility. CLS theory suggests that the addition of a ’hippocampal’ system could address these criticisms. In the present study we propose a novel algorithm known as Complementary Temporal Difference Learning (CTDL), which combines a DNN with a Self-Organising Map (SOM) to obtain the benefits of both a ’neocortical’ and a ’hippocampal’ system. Key features of CTDL include the use of Temporal Difference (TD) error to update a SOM and the combination of a SOM and DNN to calculate action values. We evaluate CTDL on grid worlds and the Cart-Pole environment, and show several benefits over the classic Deep Q-Network (DQN) approach. These results demonstrate (1) the utility of complementary learning systems for the evaluation of actions, (2) that the TD error signal is a useful form of communication between the two systems and (3) the biological plausibility of the proposed approach.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {/Users/alexten/Zotero/storage/RVEKUJ7N/Blakeman and Mareschal - 2019 - A Complementary Learning Systems Approach to Tempo.pdf;/Users/alexten/Zotero/storage/YHU8JAAG/Blakeman and Mareschal - 2020 - A complementary learning systems approach to tempo.pdf}
}

@article{blakemorePredictingConsequencesOur,
  title = {Predicting the {{Consequences}} of {{Our Own Actions}}: {{The Role}} of {{Sensorimotor Context Estimation}}},
  author = {Blakemore, Sarah J and Goodbody, Susan J and Wolpert, Daniel M},
  pages = {8},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/RNQ42H83/Blakemore et al. - Predicting the Consequences of Our Own Actions Th.pdf}
}

@article{blakemorePredictingConsequencesOur1998,
  title = {Predicting the {{Consequences}} of {{Our Own Actions}}: {{The Role}} of {{Sensorimotor Context Estimation}}},
  shorttitle = {Predicting the {{Consequences}} of {{Our Own Actions}}},
  author = {Blakemore, Sarah J. and Goodbody, Susan J. and Wolpert, Daniel M.},
  date = {1998-09-15},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {18},
  number = {18},
  pages = {7511--7518},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.18-18-07511.1998},
  url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.18-18-07511.1998},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/TFUEUS9B/Blakemore et al. - 1998 - Predicting the Consequences of Our Own Actions Th.pdf}
}

@article{blanchardOrbitofrontalCortexUses,
  title = {Orbitofrontal {{Cortex Uses Distinct Codes}} for {{Different Choice Attributes}} in {{Decisions Motivated}} by {{Curiosity}}},
  author = {Blanchard, Tommy C},
  pages = {28},
  abstract = {Decision makers are curious and consequently value advance information about future events. We made use of this fact to test competing theories of value representation in area 13 of orbitofrontal cortex (OFC). In a new task, we found that monkeys reliably sacrificed primary reward (water) to view advance information about gamble outcomes. While monkeys integrated information value with primary reward value to make their decisions, OFC neurons had no systematic tendency to integrate these variables, instead encoding them in orthogonal manners. These results suggest that the predominant role of the OFC is to encode variables relevant for learning, attention, and decision making, rather than integrating them into a single scale of value. They also suggest that OFC may be placed at a relatively early stage in the hierarchy of information-seeking decisions, before evaluation is complete. Thus, our results delineate a circuit for information-seeking decisions and suggest a neural basis for curiosity.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8RQE58BW/Blanchard - Orbitofrontal Cortex Uses Distinct Codes for Diffe.pdf}
}

@article{blanchardOrbitofrontalCortexUsesa,
  title = {Orbitofrontal {{Cortex Uses Distinct Codes}} for {{Different Choice Attributes}} in {{Decisions Motivated}} by {{Curiosity}}},
  author = {Blanchard, Tommy C},
  pages = {28},
  abstract = {Decision makers are curious and consequently value advance information about future events. We made use of this fact to test competing theories of value representation in area 13 of orbitofrontal cortex (OFC). In a new task, we found that monkeys reliably sacrificed primary reward (water) to view advance information about gamble outcomes. While monkeys integrated information value with primary reward value to make their decisions, OFC neurons had no systematic tendency to integrate these variables, instead encoding them in orthogonal manners. These results suggest that the predominant role of the OFC is to encode variables relevant for learning, attention, and decision making, rather than integrating them into a single scale of value. They also suggest that OFC may be placed at a relatively early stage in the hierarchy of information-seeking decisions, before evaluation is complete. Thus, our results delineate a circuit for information-seeking decisions and suggest a neural basis for curiosity.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JE32IWNA/Blanchard - Orbitofrontal Cortex Uses Distinct Codes for Diffe.pdf}
}

@article{bleiVariationalInferenceReview2017,
  title = {Variational {{Inference}}: {{A Review}} for {{Statisticians}}},
  shorttitle = {Variational {{Inference}}},
  author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
  date = {2017-04-03},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {112},
  number = {518},
  eprint = {1601.00670},
  eprinttype = {arxiv},
  pages = {859--877},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2017.1285773},
  url = {http://arxiv.org/abs/1601.00670},
  urldate = {2021-01-22},
  abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/FWJJCT2Y/Blei et al. - 2017 - Variational Inference A Review for Statisticians.pdf}
}

@online{bleiVariationalInferenceReview2018,
  title = {Variational {{Inference}}: {{A Review}} for {{Statisticians}}},
  shorttitle = {Variational {{Inference}}},
  author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
  date = {2018-05-09},
  eprint = {1601.00670},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  doi = {10.1080/01621459.2017.1285773},
  url = {http://arxiv.org/abs/1601.00670},
  urldate = {2021-01-22},
  abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/M2NHQ6UT/Blei et al. - 2018 - Variational Inference A Review for Statisticians.pdf}
}

@article{bogaczTutorialFreeenergyFramework2017,
  title = {A Tutorial on the Free-Energy Framework for Modelling Perception and Learning},
  author = {Bogacz, Rafal},
  date = {2017},
  journaltitle = {Journal of Mathematical Psychology},
  pages = {14},
  abstract = {This paper provides an easy to follow tutorial on the free-energy framework for modelling perception developed by Friston, which extends the predictive coding model of Rao and Ballard. These models assume that the sensory cortex infers the most likely values of attributes or features of sensory stimuli from the noisy inputs encoding the stimuli. Remarkably, these models describe how this inference could be implemented in a network of very simple computational elements, suggesting that this inference could be performed by biological networks of neurons. Furthermore, learning about the parameters describing the features and their uncertainty is implemented in these models by simple rules of synaptic plasticity based on Hebbian learning. This tutorial introduces the free-energy framework using very simple examples, and provides step-by-step derivations of the model. It also discusses in more detail how the model could be implemented in biological neural circuits. In particular, it presents an extended version of the model in which the neurons only sum their inputs, and synaptic plasticity only depends on activity of pre-synaptic and post-synaptic neurons.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5B6ATBRU/Bogacz - 2017 - A tutorial on the free-energy framework for modell.pdf;/Users/alexten/Zotero/storage/MJ6LUWFS/Bogacz - 2017 - A tutorial on the free-energy framework for modell.pdf}
}

@article{boldtImpactEvidenceReliability,
  title = {The Impact of Evidence Reliability on Sensitivity and Bias in Decision Confidence.},
  author = {Boldt, Annika},
  pages = {13},
  abstract = {People constantly face various types of decisions, which are commonly accompanied by an inherent feeling of (in)correctness: Just as realizing the tennis ball we played will most likely hit the net, we can feel more or less confident regarding our recent car purchase. People’s confidence judgments have been found to be surprisingly accurate. However, little is known about the underlying mechanisms that give rise to them. In this study, we suggest that variability in the information we receive from the outside world is of particular importance for how confident we feel in our decisions—more so than the extent to which evidence favors one over another choice option. Specifically, we find that this variability affects how people translate their internal feelings of certainty into the confidence judgments they express.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EMIGZCEI/Boldt - The impact of evidence reliability on sensitivity .pdf}
}

@article{boldtImpactEvidenceReliability2017,
  title = {The Impact of Evidence Reliability on Sensitivity and Bias in Decision Confidence.},
  author = {Boldt, Annika and de Gardelle, Vincent and Yeung, Nick},
  options = {useprefix=true},
  date = {2017-08},
  journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
  shortjournal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {43},
  number = {8},
  pages = {1520--1531},
  issn = {1939-1277, 0096-1523},
  doi = {10.1037/xhp0000404},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xhp0000404},
  urldate = {2021-01-22},
  abstract = {People constantly face various types of decisions, which are commonly accompanied by an inherent feeling of (in)correctness: Just as realizing the tennis ball we played will most likely hit the net, we can feel more or less confident regarding our recent car purchase. People’s confidence judgments have been found to be surprisingly accurate. However, little is known about the underlying mechanisms that give rise to them. In this study, we suggest that variability in the information we receive from the outside world is of particular importance for how confident we feel in our decisions—more so than the extent to which evidence favors one over another choice option. Specifically, we find that this variability affects how people translate their internal feelings of certainty into the confidence judgments they express.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/R6JCB9YD/Boldt et al. - 2017 - The impact of evidence reliability on sensitivity .pdf}
}

@article{bonattiInfantsAnticipateProbabilistic2016,
  title = {Infants Anticipate Probabilistic but Not Deterministic Outcomes},
  author = {Bonatti, Luca L},
  date = {2016},
  pages = {10},
  abstract = {Infants look at physically impossible events longer than at physically possible events, and at improbable events longer than at probable events. Such behaviors are generally interpreted as showing that infants have expectations about future events and are surprised to see them violated. It is unknown, however, whether and under what conditions infants form proactive expectations about the future, as opposed to realizing post hoc that outcomes do not comply with their previous knowledge or experience.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6GH46WMB/Bonatti - 2016 - Infants anticipate probabilistic but not determini.pdf;/Users/alexten/Zotero/storage/HQU792P7/Bonatti - 2016 - Infants anticipate probabilistic but not determini.pdf}
}

@article{botvinickReinforcementLearningFast1897,
  title = {Reinforcement {{Learning}}, {{Fast}} and {{Slow}}},
  author = {Botvinick, Matthew},
  date = {1897},
  pages = {15},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/VWWN3CJD/Botvinick - 1897 - Reinforcement Learning, Fast and Slow.pdf}
}

@article{botvinickReinforcementLearningFast2019,
  title = {Reinforcement {{Learning}}, {{Fast}} and {{Slow}}},
  author = {Botvinick, Matthew and Ritter, Sam and Wang, Jane X. and Kurth-Nelson, Zeb and Blundell, Charles and Hassabis, Demis},
  date = {2019-05},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {23},
  number = {5},
  pages = {408--422},
  issn = {13646613},
  doi = {10.1016/j.tics.2019.02.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661319300610},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/H9HMSN6Y/Botvinick et al. - 2019 - Reinforcement Learning, Fast and Slow.pdf}
}

@article{boureauDecidingHowDecide2015,
  title = {Deciding {{How To Decide}}: {{Self}}-{{Control}} and {{Meta}}-{{Decision Making}}},
  shorttitle = {Deciding {{How To Decide}}},
  author = {Boureau, Y-Lan and Sokol-Hessner, Peter and Daw, Nathaniel D.},
  date = {2015-11},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {19},
  number = {11},
  pages = {700--710},
  issn = {13646613},
  doi = {10.1016/j.tics.2015.08.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661315002041},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9B98X26J/Boureau et al. - 2015 - Deciding How To Decide Self-Control and Meta-Deci.pdf;/Users/alexten/Zotero/storage/KWS45QHF/Boureau - Deciding How To Decide Self-Control and Meta-Deci.pdf}
}

@article{boydEvolutionStoriesMimesis2018,
  title = {The Evolution of Stories: From Mimesis to Language, from Fact to Fiction: {{The}} Evolution of Stories},
  shorttitle = {The Evolution of Stories},
  author = {Boyd, Brian},
  date = {2018-01},
  journaltitle = {Wiley Interdisciplinary Reviews: Cognitive Science},
  shortjournal = {WIREs Cogn Sci},
  volume = {9},
  number = {1},
  pages = {e1444},
  issn = {19395078},
  doi = {10.1002/wcs.1444},
  url = {http://doi.wiley.com/10.1002/wcs.1444},
  urldate = {2021-03-09},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IGK8AKYG/Boyd - 2018 - The evolution of stories from mimesis to language.pdf}
}

@article{bozdoganModelSelectionAkaike,
  title = {Model Selection and {{Akaike}}'s {{Information Criterion}} ({{AIC}}): {{The}} General Theory and Its Analytical Extensions},
  author = {Bozdogan, Hamparsum},
  pages = {26},
  abstract = {During the last fifteen years, Akaike's entropy-based Information Criterion (AIC) has had a fundamental impact in statistical model evaluation problems. This paper studies the general theory of the AIC procedure and provides its analytical extensions in two ways without violating Akaike's main principles. These extensions make AIC asymptotically consistent and penalize overparameterization more stringently to pick only the simplest of the "true" models. These selection criteria are called CAIC and CAICF. Asymptotic properties of AIC and its extensions are investigated, and empirical performances of these criteria are studied in choosing the correct degree of a polynomial model in two different Monte Carlo experiments under different conditions.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/LAV3ZRG8/Bozdogan - Model selection and Akaike's Information Criterion.pdf}
}

@article{bozdoganModelSelectionAkaike1987,
  title = {Model Selection and {{Akaike}}'s {{Information Criterion}} ({{AIC}}): {{The}} General Theory and Its Analytical Extensions},
  shorttitle = {Model Selection and {{Akaike}}'s {{Information Criterion}} ({{AIC}})},
  author = {Bozdogan, Hamparsum},
  date = {1987-09},
  journaltitle = {Psychometrika},
  shortjournal = {Psychometrika},
  volume = {52},
  number = {3},
  pages = {345--370},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02294361},
  url = {http://link.springer.com/10.1007/BF02294361},
  urldate = {2021-01-22},
  abstract = {During the last fifteen years, Akaike's entropy-based Information Criterion (AIC) has had a fundamental impact in statistical model evaluation problems. This paper studies the general theory of the AIC procedure and provides its analytical extensions in two ways without violating Akaike's main principles. These extensions make AIC asymptotically consistent and penalize overparameterization more stringently to pick only the simplest of the "true" models. These selection criteria are called CAIC and CAICF. Asymptotic properties of AIC and its extensions are investigated, and empirical performances of these criteria are studied in choosing the correct degree of a polynomial model in two different Monte Carlo experiments under different conditions.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8XRMM28W/Bozdogan - 1987 - Model selection and Akaike's Information Criterion.pdf}
}

@article{brewerRelativePerformanceAIC2016,
  title = {The Relative Performance of {{AIC}}, {{AIC}} {{{\textsubscript{C}}}} and {{BIC}} in the Presence of Unobserved Heterogeneity},
  author = {Brewer, Mark J. and Butler, Adam and Cooksley, Susan L.},
  editor = {Freckleton, Robert},
  date = {2016-06},
  journaltitle = {Methods in Ecology and Evolution},
  shortjournal = {Methods Ecol Evol},
  volume = {7},
  number = {6},
  pages = {679--692},
  issn = {2041210X},
  doi = {10.1111/2041-210X.12541},
  url = {http://doi.wiley.com/10.1111/2041-210X.12541},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ZT6AFMAP/Brewer et al. - 2016 - The relative performance of AIC, AIC C .pdf}
}

@article{bromberg-martinDopamineMotivationalControl,
  title = {Dopamine in {{Motivational Control}}: {{Rewarding}}, {{Aversive}}, and {{Alerting}}},
  author = {Bromberg-Martin, Ethan S},
  pages = {20},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2JG4FDJI/Bromberg-Martin - Dopamine in Motivational Control Rewarding, Avers.pdf;/Users/alexten/Zotero/storage/LQJHQPMA/Bromberg-Martin - Dopamine in Motivational Control Rewarding, Avers.pdf}
}

@article{bromberg-martinLateralHabenulaNeurons2011,
  title = {Lateral Habenula Neurons Signal Errors in the Prediction of Reward Information},
  author = {Bromberg-Martin, Ethan S},
  date = {2011},
  journaltitle = {nature NEUROSCIENCE},
  volume = {14},
  number = {9},
  pages = {11},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3TS92FXH/Bromberg-Martin - 2011 - Lateral habenula neurons signal errors in the pred.pdf}
}

@article{bromberg-martinLateralHabenulaNeurons2011a,
  title = {Lateral Habenula Neurons Signal Errors in the Prediction of Reward Information},
  author = {Bromberg-Martin, Ethan S},
  date = {2011},
  journaltitle = {nature NEUROSCIENCE},
  volume = {14},
  number = {9},
  pages = {11},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CVGK9JKR/Bromberg-Martin - 2011 - Lateral habenula neurons signal errors in the pred.pdf}
}

@article{bromberg-martinMidbrainDopamineNeurons,
  title = {Midbrain {{Dopamine Neurons Signal Preference}} for {{Advance Information}} about {{Upcoming Rewards}}},
  author = {Bromberg-Martin, Ethan S and Hikosaka, Okihide},
  pages = {8},
  abstract = {The desire to know what the future holds is a powerful motivator in everyday life, but it is unknown how this desire is created by neurons in the brain. Here we show that when macaque monkeys are offered a water reward of variable magnitude, they seek advance information about its size. Furthermore, the same midbrain dopamine neurons that signal the expected amount of water also signal the expectation of information, in a manner that is correlated with the strength of the animal’s preference. Our data show that single dopamine neurons process both primitive and cognitive rewards, and suggest that current theories of reward-seeking must be revised to include information-seeking.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JT9THRQK/Bromberg-Martin and Hikosaka - Midbrain Dopamine Neurons Signal Preference for Ad.pdf}
}

@article{bromberg-martinMidbrainDopamineNeuronsa,
  title = {Midbrain {{Dopamine Neurons Signal Preference}} for {{Advance Information}} about {{Upcoming Rewards}}},
  author = {Bromberg-Martin, Ethan S and Hikosaka, Okihide},
  pages = {8},
  abstract = {The desire to know what the future holds is a powerful motivator in everyday life, but it is unknown how this desire is created by neurons in the brain. Here we show that when macaque monkeys are offered a water reward of variable magnitude, they seek advance information about its size. Furthermore, the same midbrain dopamine neurons that signal the expected amount of water also signal the expectation of information, in a manner that is correlated with the strength of the animal’s preference. Our data show that single dopamine neurons process both primitive and cognitive rewards, and suggest that current theories of reward-seeking must be revised to include information-seeking.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IUEM88MN/Bromberg-Martin and Hikosaka - Midbrain Dopamine Neurons Signal Preference for Ad.pdf}
}

@article{buckleyFreeEnergyPrinciple2017,
  title = {The Free Energy Principle for Action and Perception: {{A}} Mathematical Review},
  shorttitle = {The Free Energy Principle for Action and Perception},
  author = {Buckley, Christopher L. and Kim, Chang Sub and McGregor, Simon and Seth, Anil K.},
  date = {2017-12},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {81},
  pages = {55--79},
  issn = {00222496},
  doi = {10.1016/j.jmp.2017.09.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249617300962},
  urldate = {2021-01-22},
  abstract = {The ‘free energy principle’ (FEP) has been suggested to provide a unified theory of the brain, integrating data and theory relating to action, perception, and learning. The theory and implementation of the FEP combines insights from Helmholtzian ‘perception as inference’, machine learning theory, and statistical thermodynamics. Here, we provide a detailed mathematical evaluation of a suggested biologically plausible implementation of the FEP that has been widely used to develop the theory. Our objectives are (i) to describe within a single article the mathematical structure of this implementation of the FEP; (ii) provide a simple but complete agent-based model utilising the FEP and (iii) to disclose the assumption structure of this implementation of the FEP to help elucidate its significance for the brain sciences.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GWFZ8399/Buckley et al. - 2017 - The free energy principle for action and perceptio.pdf}
}

@article{buckleyFreeEnergyPrinciple2017a,
  title = {The Free Energy Principle for Action and Perception: {{A}} Mathematical Review},
  author = {Buckley, Christopher L and Kim, Chang Sub and McGregor, Simon and Seth, Anil K},
  date = {2017},
  journaltitle = {Journal of Mathematical Psychology},
  pages = {25},
  abstract = {The ‘free energy principle’ (FEP) has been suggested to provide a unified theory of the brain, integrating data and theory relating to action, perception, and learning. The theory and implementation of the FEP combines insights from Helmholtzian ‘perception as inference’, machine learning theory, and statistical thermodynamics. Here, we provide a detailed mathematical evaluation of a suggested biologically plausible implementation of the FEP that has been widely used to develop the theory. Our objectives are (i) to describe within a single article the mathematical structure of this implementation of the FEP; (ii) provide a simple but complete agent-based model utilising the FEP and (iii) to disclose the assumption structure of this implementation of the FEP to help elucidate its significance for the brain sciences.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/587D2VB9/Buckley et al. - 2017 - The free energy principle for action and perceptio.pdf}
}

@article{buiWhenPeopleJudgments,
  title = {When People’s Judgments of Learning ({{JOLs}}) Are Extremely Accurate at Predicting Subsequent Recall: The “{{Displaced}}-{{JOL}} Effect”},
  author = {Bui, Young and Pyc, Mary A and Bailey, Heather},
  pages = {14},
  abstract = {Judgments of learning (JOL) made after a delay more accurately predict subsequent recall than JOLs made immediately after learning. One explanation is that delayed JOLs involve retrieving information about the target item from secondary memory, whereas immediate JOLs involve retrieval from primary memory. One view of working memory claims that information in primary memory is displaced to secondary memory when attention is shifted to a secondary task. Thus, immediate JOLs might be as accurate as delayed JOLs if an intervening task displaces the target item from primary memory, requiring retrieval from secondary memory, prior to making the JOL. In four experiments, participants saw related word-pairs and made JOLs predicting later recall of the item. In Experiment 1, delayed JOLs were more accurate than JOLs made shortly after learning, regardless of whether a secondary task intervened between learning and JOL. In Experiments 2–4, the secondary task demands increased and JOLs made shortly after learning with an intervening task were just as accurate as delayed JOLs, and both were more accurate than immediate JOLs with no intervening task (Experiment 4). These results are consistent with a retrieval-based account of JOLs, and demonstrate that the “delayed-JOL effect” can be obtained without a long delay.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5E6NA2FU/Bui et al. - When people’s judgments of learning (JOLs) are ext.pdf}
}

@article{buiWhenPeopleJudgmentsa,
  title = {When People’s Judgments of Learning ({{JOLs}}) Are Extremely Accurate at Predicting Subsequent Recall: The “{{Displaced}}-{{JOL}} Effect”},
  author = {Bui, Young and Pyc, Mary A and Bailey, Heather},
  pages = {14},
  abstract = {Judgments of learning (JOL) made after a delay more accurately predict subsequent recall than JOLs made immediately after learning. One explanation is that delayed JOLs involve retrieving information about the target item from secondary memory, whereas immediate JOLs involve retrieval from primary memory. One view of working memory claims that information in primary memory is displaced to secondary memory when attention is shifted to a secondary task. Thus, immediate JOLs might be as accurate as delayed JOLs if an intervening task displaces the target item from primary memory, requiring retrieval from secondary memory, prior to making the JOL. In four experiments, participants saw related word-pairs and made JOLs predicting later recall of the item. In Experiment 1, delayed JOLs were more accurate than JOLs made shortly after learning, regardless of whether a secondary task intervened between learning and JOL. In Experiments 2–4, the secondary task demands increased and JOLs made shortly after learning with an intervening task were just as accurate as delayed JOLs, and both were more accurate than immediate JOLs with no intervening task (Experiment 4). These results are consistent with a retrieval-based account of JOLs, and demonstrate that the “delayed-JOL effect” can be obtained without a long delay.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EP3Z3AHI/Bui et al. - When people’s judgments of learning (JOLs) are ext.pdf}
}

@online{burdaLargeScaleStudyCuriosityDriven2018,
  title = {Large-{{Scale Study}} of {{Curiosity}}-{{Driven Learning}}},
  author = {Burda, Yuri and Edwards, Harri and Pathak, Deepak and Storkey, Amos and Darrell, Trevor and Efros, Alexei A.},
  date = {2018-08-13},
  eprint = {1808.04355},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1808.04355},
  urldate = {2021-01-22},
  abstract = {Reinforcement learning algorithms rely on carefully engineering environment rewards that are extrinsic to the agent. However, annotating each environment with hand-designed, dense rewards is not scalable, motivating the need for developing reward functions that are intrinsic to the agent. Curiosity is a type of intrinsic reward function which uses prediction error as reward signal. In this paper: (a) We perform the first large-scale study of purely curiosity-driven learning, i.e. without any extrinsic rewards, across 54 standard benchmark environments, including the Atari game suite. Our results show surprisingly good performance, and a high degree of alignment between the intrinsic curiosity objective and the handdesigned extrinsic rewards of many game environments. (b) We investigate the effect of using different feature spaces for computing prediction error and show that random features are sufficient for many popular RL game benchmarks, but learned features appear to generalize better (e.g. to novel game levels in Super Mario Bros.). (c) We demonstrate limitations of the prediction-based rewards in stochastic setups. Game-play videos and code are at https://pathak22.github. io/large-scale-curiosity/.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/6LR4S63C/Burda et al. - 2018 - Large-Scale Study of Curiosity-Driven Learning.pdf}
}

@online{burdaLargeScaleStudyCuriosityDriven2018a,
  title = {Large-{{Scale Study}} of {{Curiosity}}-{{Driven Learning}}},
  author = {Burda, Yuri and Edwards, Harri and Pathak, Deepak and Storkey, Amos and Darrell, Trevor and Efros, Alexei A.},
  date = {2018-08-13},
  eprint = {1808.04355},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1808.04355},
  urldate = {2021-01-22},
  abstract = {Reinforcement learning algorithms rely on carefully engineering environment rewards that are extrinsic to the agent. However, annotating each environment with hand-designed, dense rewards is not scalable, motivating the need for developing reward functions that are intrinsic to the agent. Curiosity is a type of intrinsic reward function which uses prediction error as reward signal. In this paper: (a) We perform the first large-scale study of purely curiosity-driven learning, i.e. without any extrinsic rewards, across 54 standard benchmark environments, including the Atari game suite. Our results show surprisingly good performance, and a high degree of alignment between the intrinsic curiosity objective and the handdesigned extrinsic rewards of many game environments. (b) We investigate the effect of using different feature spaces for computing prediction error and show that random features are sufficient for many popular RL game benchmarks, but learned features appear to generalize better (e.g. to novel game levels in Super Mario Bros.). (c) We demonstrate limitations of the prediction-based rewards in stochastic setups. Game-play videos and code are at https://pathak22.github. io/large-scale-curiosity/.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/S6TVICL4/Burda et al. - 2018 - Large-Scale Study of Curiosity-Driven Learning.pdf}
}

@article{burnhamAICModelSelection2011,
  title = {{{AIC}} Model Selection and Multimodel Inference in Behavioral Ecology: Some Background, Observations, and Comparisons},
  author = {Burnham, Kenneth P and Anderson, David R and Huyvaert, Kathryn P},
  date = {2011},
  journaltitle = {Behav Ecol Sociobiol},
  pages = {13},
  abstract = {We briefly outline the information-theoretic (I-T) approaches to valid inference including a review of some simple methods for making formal inference from all the hypotheses in the model set (multimodel inference). The I-T approaches can replace the usual t tests and ANOVA tables that are so inferentially limited, but still commonly used. The I-T methods are easy to compute and understand and provide formal measures of the strength of evidence for both the null and alternative hypotheses, given the data. We give an example to highlight the importance of deriving alternative hypotheses and representing these as probability models. Fifteen technical issues are addressed to clarify various points that have appeared incorrectly in the recent literature. We offer several remarks regarding the future of empirical science and data analysis under an I-T framework.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3NGVDDZA/Burnham et al. - 2011 - AIC model selection and multimodel inference in be.pdf;/Users/alexten/Zotero/storage/7J9DHVVL/Burnham et al. - 2011 - AIC model selection and multimodel inference in be.pdf}
}

@article{burnhamMultimodelInferenceUnderstanding2004,
  title = {Multimodel {{Inference}}: {{Understanding AIC}} and {{BIC}} in {{Model Selection}}},
  author = {Burnham, Kenneth P and Anderson, David R},
  date = {2004},
  pages = {45},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/T9EI5LRN/Burnham and Anderson - 2004 - Multimodel Inference Understanding AIC and BIC in.pdf}
}

@article{burnhamMultimodelInferenceUnderstanding2004a,
  title = {Multimodel {{Inference}}: {{Understanding AIC}} and {{BIC}} in {{Model Selection}}},
  author = {Burnham, Kenneth P and Anderson, David R},
  date = {2004},
  pages = {45},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/J7X82N3W/Burnham and Anderson - 2004 - Multimodel Inference Understanding AIC and BIC in.pdf}
}

@article{butterfieldErrorsCommittedHigh,
  title = {Errors {{Committed With High Confidence Are Hypercorrected}}},
  author = {Butterfield, Brady and Metcalfe, Janet},
  pages = {5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7MXES38T/Butterfield and Metcalfe - Errors Committed With High Confidence Are Hypercor.pdf;/Users/alexten/Zotero/storage/FYAJPIQA/Butterfield and Metcalfe - Errors Committed With High Confidence Are Hypercor.pdf}
}

@article{carassaRepresentationalRedescriptionCognitive,
  title = {Representational Redescription and Cognitive Architectures},
  author = {Carassa, Antonella and Tirassa, Maurizio},
  pages = {2},
  abstract = {We focus on Karmiloff-Smith's Representational redescription model, arguing that it poses some problems concerning the architecture of a redescribing system. To discuss the topic, we consider the implicit/explicit dichotomy and the relations between natural language and the language of thought. We argue that the model regards how knowledge is employed rather than how it is represented in the system.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/T3RIQKBZ/Carassa and Tirassa - Representational redescription and cognitive archi.pdf}
}

@article{carassaRepresentationalRedescriptionCognitivea,
  title = {Representational Redescription and Cognitive Architectures},
  author = {Carassa, Antonella and Tirassa, Maurizio},
  pages = {2},
  abstract = {We focus on Karmiloff-Smith's Representational redescription model, arguing that it poses some problems concerning the architecture of a redescribing system. To discuss the topic, we consider the implicit/explicit dichotomy and the relations between natural language and the language of thought. We argue that the model regards how knowledge is employed rather than how it is represented in the system.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9YDBNS3P/Carassa and Tirassa - Representational redescription and cognitive archi.pdf}
}

@article{cazeHippocampalReplaysScrutiny,
  title = {Hippocampal Replays under the Scrutiny of Reinforcement Learning Models},
  author = {Cazé, Romain and Khamassi, Mehdi and Aubin, Lise and Girard, Benoît},
  journaltitle = {J Neurophysiol},
  pages = {20},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2DWY8RXX/Cazé et al. - Hippocampal replays under the scrutiny of reinforc.pdf;/Users/alexten/Zotero/storage/C3DF8PYG/Cazé et al. - Hippocampal replays under the scrutiny of reinforc.pdf}
}

@article{cerasoliIntrinsicMotivationExtrinsic,
  title = {Intrinsic {{Motivation}} and {{Extrinsic Incentives Jointly Predict Performance}}: {{A}} 40-{{Year Meta}}-{{Analysis}}},
  author = {Cerasoli, Christopher P and Nicklin, Jessica M and Ford, Michael T},
  pages = {29},
  abstract = {More than 4 decades of research and 9 meta-analyses have focused on the undermining effect: namely, the debate over whether the provision of extrinsic incentives erodes intrinsic motivation. This review and meta-analysis builds on such previous reviews by focusing on the interrelationship among intrinsic motivation, extrinsic incentives, and performance, with reference to 2 moderators: performance type (quality vs. quantity) and incentive contingency (directly performance-salient vs. indirectly performancesalient), which have not been systematically reviewed to date. Based on random-effects meta-analytic methods, findings from school, work, and physical domains (k ϭ 183, N ϭ 212,468) indicate that intrinsic motivation is a medium to strong predictor of performance (␳ ϭ .21–45). The importance of intrinsic motivation to performance remained in place whether incentives were presented. In addition, incentive salience influenced the predictive validity of intrinsic motivation for performance: In a “crowding out” fashion, intrinsic motivation was less important to performance when incentives were directly tied to performance and was more important when incentives were indirectly tied to performance. Considered simultaneously through meta-analytic regression, intrinsic motivation predicted more unique variance in quality of performance, whereas incentives were a better predictor of quantity of performance. With respect to performance, incentives and intrinsic motivation are not necessarily antagonistic and are best considered simultaneously. Future research should consider using nonperformance criteria (e.g., well-being, job satisfaction) as well as applying the percent-of-maximum-possible (POMP) method in meta-analyses.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/66D25NEW/Cerasoli et al. - Intrinsic Motivation and Extrinsic Incentives Join.pdf;/Users/alexten/Zotero/storage/VID695PG/Cerasoli et al. - Intrinsic Motivation and Extrinsic Incentives Join.pdf}
}

@article{charpentierValuationKnowledgeIgnorance,
  title = {Valuation of Knowledge and Ignorance in Mesolimbic Reward Circuitry},
  author = {Charpentier, Caroline J and Bromberg-Martin, Ethan S and Sharot, Tali},
  journaltitle = {COGNITIVE SCIENCES},
  pages = {10},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BUZQJ7JD/Charpentier et al. - Valuation of knowledge and ignorance in mesolimbic.pdf;/Users/alexten/Zotero/storage/LUMKZF52/Charpentier et al. - Valuation of knowledge and ignorance in mesolimbic.pdf}
}

@article{chaterProbabilisticModelsCognition,
  title = {Probabilistic Models of Cognition: {{Conceptual}} Foundations},
  author = {Chater, Nick and Tenenbaum, Joshua B and Yuille, Alan},
  pages = {5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/USLYHPVL/Chater et al. - Probabilistic models of cognition Conceptual foun.pdf}
}

@article{chaterProbabilisticModelsCognition2006,
  title = {Probabilistic Models of Cognition: {{Conceptual}} Foundations},
  shorttitle = {Probabilistic Models of Cognition},
  author = {Chater, Nick and Tenenbaum, Joshua B. and Yuille, Alan},
  date = {2006-07},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {10},
  number = {7},
  pages = {287--291},
  issn = {13646613},
  doi = {10.1016/j.tics.2006.05.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S136466130600132X},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5JSJ8AAK/Chater et al. - 2006 - Probabilistic models of cognition Conceptual foun.pdf}
}

@article{chaterUnderappreciatedDriveSensemaking2016,
  title = {The Under-Appreciated Drive for Sense-Making},
  author = {Chater, Nick},
  date = {2016},
  pages = {18},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6AMJYKL3/Chater - 2016 - The under-appreciated drive for sense-making.pdf}
}

@article{chaterUnderappreciatedDriveSensemaking2016a,
  title = {The Under-Appreciated Drive for Sense-Making},
  author = {Chater, Nick},
  date = {2016},
  pages = {18},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JQXB3HKM/Chater - 2016 - The under-appreciated drive for sense-making.pdf}
}

@article{chenEpistemicCognitionMotivation,
  title = {Epistemic {{Cognition}} and {{Motivation}}},
  author = {Chen, Jason A and Barger, Michael M},
  pages = {31},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/J8SHRR63/Chen and Barger - Epistemic Cognition and Motivation.pdf;/Users/alexten/Zotero/storage/M6NEZG4K/Chen and Barger - Epistemic Cognition and Motivation.pdf}
}

@article{chenWhenBoubaEquals2016,
  title = {When “{{Bouba}}” Equals “{{Kiki}}”: {{Cultural}} Commonalities and Cultural Differences in Sound-Shape Correspondences},
  shorttitle = {When “{{Bouba}}” Equals “{{Kiki}}”},
  author = {Chen, Yi-Chuan and Huang, Pi-Chun and Woods, Andy and Spence, Charles},
  date = {2016-05},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {6},
  number = {1},
  pages = {26681},
  issn = {2045-2322},
  doi = {10.1038/srep26681},
  url = {http://www.nature.com/articles/srep26681},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/TAHCAYKL/Chen et al. - 2016 - When “Bouba” equals “Kiki” Cultural commonalities.pdf;/Users/alexten/Zotero/storage/Y9D3Q7EP/Chen - When “Bouba” equals “Kiki” Cultural commonalities.pdf}
}

@online{choffinDAS3HModelingStudent2019,
  title = {{{DAS3H}}: {{Modeling Student Learning}} and {{Forgetting}} for {{Optimally Scheduling Distributed Practice}} of {{Skills}}},
  shorttitle = {{{DAS3H}}},
  author = {Choffin, Benoît and Popineau, Fabrice and Bourda, Yolaine and Vie, Jill-Jênn},
  date = {2019-05-14},
  eprint = {1905.06873},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1905.06873},
  urldate = {2021-01-22},
  abstract = {Spaced repetition is among the most studied learning strategies in the cognitive science literature. It consists in temporally distributing exposure to an information so as to improve long-term memorization. Providing students with an adaptive and personalized distributed practice schedule would benefit more than just a generic scheduler. However, the applicability of such adaptive schedulers seems to be limited to pure memorization, e.g. flashcards or foreign language learning. In this article, we first frame the research problem of optimizing an adaptive and personalized spaced repetition scheduler when memorization concerns the application of underlying multiple skills. To this end, we choose to rely on a student model for inferring knowledge state and memory dynamics on any skill or combination of skills. We argue that no knowledge tracing model takes both memory decay and multiple skill tagging into account for predicting student performance. As a consequence, we propose a new student learning and forgetting model suited to our research problem: DAS3H builds on the additive factor models and includes a representation of the temporal distribution of past practice on the skills involved by an item. In particular, DAS3H allows the learning and forgetting curves to differ from one skill to another. Finally, we provide empirical evidence on three real-world educational datasets that DAS3H outperforms other state-of-the-art EDM models. These results suggest that incorporating both item-skill relationships and forgetting effect improves over student models that consider one or the other.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Statistics - Applications,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/YRS2L5HN/Choffin et al. - 2019 - DAS3H Modeling Student Learning and Forgetting fo.pdf}
}

@article{chouinardAdultReformulationsChild,
  title = {Adult {{Reformulations}} of {{Child Errors}} as {{Negative Evidence}}},
  author = {Chouinard, Michelle M and Clark, Eve V},
  pages = {57},
  abstract = {We propose that parental reformulations of erroneous child utterances provide children with information about the locus of an error and hence the error itself. Since the meanings of the child utterance and the adult reformulation are the same although the forms are different, children infer that adults must be offering a correction. Analyses of longitudinal data from five children (three acquiring English and two acquiring French) show that (a) adults reformulate their children’s erroneous utterances and do so significantly more often than they replay or repeat error-free utterances; (b) their rates of reformulation are similar across error-types (phonological, morphological, lexical, and syntactic); (c) they reformulate significantly more often to younger children, who make more errors, and these reformulations decrease significantly with age. Evidence that children attend to such reformulations comes from three measures: (a) their explicit repeats of such reformulations in their next turn; (b) their acknowledgements (yeah or uh-huh as a preface to their next turn, or a repeat of any new information included in the reformulation); and (c) their explicit rejections of reformulations where the adult has misunderstood them.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/55CJMNQY/Chouinard and Clark - Adult Reformulations of Child Errors as Negative E.pdf;/Users/alexten/Zotero/storage/RNY5PQ5N/Chouinard and Clark - Adult Reformulations of Child Errors as Negative E.pdf}
}

@article{christiansenGeneralizationConnectionistLanguage,
  title = {Generalization and {{Connectionist Language Learning}}},
  author = {Christiansen, Morten H and Chater, Nick},
  pages = {17},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4Z8YXE9S/Christiansen and Chater - Generalization and Connectionist Language Learning.pdf;/Users/alexten/Zotero/storage/HBC4K246/Christiansen and Chater - Generalization and Connectionist Language Learning.pdf}
}

@article{christiansenNaturalLanguageRecursion,
  title = {Natural {{Language Recursion}} and {{Recurrent Neural Networks}}},
  author = {Christiansen, Morten H and Chater, Nick},
  pages = {9},
  abstract = {The recursive structure of natural language was one of the principal, and most telling, sources of di culty for associationist models of linguistic behaviour. It has, more recently, become a focus in the debate surrounding the generality of neural network models of language, which many would regard as the natural heirs of the associationist legacy. Can neural networks learn to handle recursive structures? If not, many would argue, neural networks can be ruled out a priori as viable models of language processing. In this paper, we shall reconsider the implications of natural language recursion for neural network models, and present a range of simulations in which recurrent neural networks are trained on very simple recursive structures. We suggest implications for theories of human language processing.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/RGKTEDEN/Christiansen and Chater - Natural Language Recursion and Recurrent Neural Ne.pdf}
}

@article{christiansenNaturalLanguageRecursiona,
  title = {Natural {{Language Recursion}} and {{Recurrent Neural Networks}}},
  author = {Christiansen, Morten H and Chater, Nick},
  pages = {9},
  abstract = {The recursive structure of natural language was one of the principal, and most telling, sources of di culty for associationist models of linguistic behaviour. It has, more recently, become a focus in the debate surrounding the generality of neural network models of language, which many would regard as the natural heirs of the associationist legacy. Can neural networks learn to handle recursive structures? If not, many would argue, neural networks can be ruled out a priori as viable models of language processing. In this paper, we shall reconsider the implications of natural language recursion for neural network models, and present a range of simulations in which recurrent neural networks are trained on very simple recursive structures. We suggest implications for theories of human language processing.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IIXJ38IG/Christiansen and Chater - Natural Language Recursion and Recurrent Neural Ne.pdf}
}

@article{chulefHierarchicalTaxonomyHuman2001,
  title = {A {{Hierarchical Taxonomy}} of {{Human Goals}}},
  author = {Chulef, Ada S and Read, Stephen J and Walsh, David A},
  date = {2001},
  journaltitle = {Motivation and Emotion},
  pages = {43},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/J6L5D7N4/Chulef et al. - 2001 - A Hierarchical Taxonomy of Human Goals.pdf;/Users/alexten/Zotero/storage/SMVE7QGP/Chulef et al. - 2001 - A Hierarchical Taxonomy of Human Goals.pdf}
}

@article{cleeremansConsciousnessMetarepresentationComputational2007,
  title = {Consciousness and Metarepresentation: {{A}} Computational Sketch},
  author = {Cleeremans, Axel and Timmermans, Bert and Pasquali, Antoine},
  date = {2007},
  journaltitle = {Neural Networks},
  pages = {8},
  abstract = {When one is conscious of something, one is also conscious that one is conscious. Higher-Order Thought Theory [Rosenthal, D. (1997). A theory of consciousness. In N. Block, O. Flanagan, \& G. Gu¨zeldere (Eds.), The nature of consciousness: Philosophical debates. Cambridge, MA: MIT Press] takes it that it is in virtue of the fact that one is conscious of being conscious, that one is conscious. Here, we ask what the computational mechanisms may be that implement this intuition. Our starting point is Clark and Karmiloff-Smith’s [Clark, A., \& Karmiloff-Smith, A. (1993). The cognizer’s innards: A psychological and philosophical perspective on the development of thought. Mind and Language, 8, 487–519] point that knowledge acquired by a connectionist network always remains “knowledge in the network rather than knowledge for the network”. That is, while connectionist networks may become exquisitely sensitive to regularities contained in their input–output environment, they never exhibit the ability to access and manipulate this knowledge as knowledge: The knowledge can only be expressed through performing the task upon which the network was trained; it remains forever embedded in the causal pathways that developed as a result of training. To address this issue, we present simulations in which two networks interact. The states of a first-order network trained to perform a simple categorization task become input to a second-order network trained either as an encoder or on another categorization task. Thus, the second-order network “observes” the states of the first-order network and has, in the first case, to reproduce these states on its output units, and in the second case, to use the states as cues in order to solve the secondary task. This implements a limited form of metarepresentation, to the extent that the second-order network’s internal representations become re-representations of the first-order network’s internal states. We conclude that this mechanism provides the beginnings of a computational mechanism to account for mental attitudes, that is, an understanding by a cognitive system of the manner in which its firstorder knowledge is held (belief, hope, fear, etc.). Consciousness, in this light, thus involves knowledge of the geography of one own’s internal representations — a geography that is itself learned over time as a result of an agent’s attributing value to the various experiences it enjoys through interaction with itself, the world, and others.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/LW8H6N7X/Cleeremans et al. - 2007 - Consciousness and metarepresentation A computatio.pdf}
}

@article{clementAdaptivePersonalizationPedagogical,
  title = {Adaptive {{Personalization}} of {{Pedagogical Sequences}} Using {{Machine Learning}}},
  author = {Clément, Benjamin},
  pages = {139},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DUTDM7TJ/Clément - Adaptive Personalization of Pedagogical Sequences .pdf}
}

@article{cohenControlAutomaticProcesses,
  title = {On the {{Control}} of {{Automatic Processes}}: {{A Parallel Distributed Processing Account}} of the {{Stroop Effect}}},
  author = {Cohen, Jonathan D and McClelland, James L and Dunbar, Kevin},
  pages = {30},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BMJH3HF7/Cohen et al. - On the Control of Automatic Processes A Parallel .pdf}
}

@article{cohenControlAutomaticProcessesa,
  title = {On the {{Control}} of {{Automatic Processes}}: {{A Parallel Distributed Processing Account}} of the {{Stroop Effect}}},
  author = {Cohen, Jonathan D and McClelland, James L and Dunbar, Kevin},
  pages = {30},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WAT8T5PA/Cohen et al. - On the Control of Automatic Processes A Parallel .pdf}
}

@article{cohenMultipleRegressionGeneral1968,
  title = {Multiple Regression as a General Data-Analytic System.},
  author = {Cohen, Jacob},
  date = {1968},
  journaltitle = {Psychological Bulletin},
  shortjournal = {Psychological Bulletin},
  volume = {70},
  pages = {426--443},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/h0026714},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0026714},
  urldate = {2021-05-23},
  issue = {6, Pt.1},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/79QDLMLI/Cohen - 1968 - Multiple regression as a general data-analytic sys.pdf}
}

@article{cohenShouldStayShould2007a,
  title = {Should {{I}} Stay or Should {{I}} Go? {{How}} the Human Brain Manages the Trade-off between Exploitation and Exploration},
  shorttitle = {Should {{I}} Stay or Should {{I}} Go?},
  author = {Cohen, Jonathan D and McClure, Samuel M and Yu, Angela J},
  date = {2007-05-29},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  shortjournal = {Phil. Trans. R. Soc. B},
  volume = {362},
  number = {1481},
  pages = {933--942},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2007.2098},
  url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2007.2098},
  urldate = {2021-01-22},
  abstract = {Many large and small decisions we make in our daily lives—which ice cream to choose, what research projects to pursue, which partner to marry—require an exploration of alternatives before committing to and exploiting the benefits of a particular choice. Furthermore, many decisions require re-evaluation, and further exploration of alternatives, in the face of changing needs or circumstances. That is, often our decisions depend on a higher level choice: whether to exploit well known but possibly suboptimal alternatives or to explore risky but potentially more profitable ones. How adaptive agents choose between exploitation and exploration remains an important and open question that has received relatively limited attention in the behavioural and brain sciences. The choice could depend on a number of factors, including the familiarity of the environment, how quickly the environment is likely to change and the relative value of exploiting known sources of reward versus the cost of reducing uncertainty through exploration. There is no known generally optimal solution to the exploration versus exploitation problem, and a solution to the general case may indeed not be possible. However, there have been formal analyses of the optimal policy under constrained circumstances. There have also been specific suggestions of how humans and animals may respond to this problem under particular experimental conditions as well as proposals about the brain mechanisms involved. Here, we provide a brief review of this work, discuss how exploration and exploitation may be mediated in the brain and highlight some promising future directions for research.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/U4JCUZVZ/Cohen et al. - 2007 - Should I stay or should I go How the human brain .pdf}
}

@article{cohnImprovingGeneralizationActive,
  title = {Improving Generalization with Active Learning},
  author = {Cohn, David},
  pages = {21},
  abstract = {Activelearningdiffersfrom "learningfromexamples"in that the learningalgorithmassumesat least somecontroloverwhatpart of the inputdomainit receivesinformationabout.In somesituations,activelearning is provablymore powerfulthan learningfrom examplesalone, givingbetter generalizationfor a fixed number of training examples.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/64XCWJUV/Cohn - Improving generalization with active learning.pdf}
}

@article{collinsNeuralSignatureHierarchically2016a,
  title = {Neural Signature of Hierarchically Structured Expectations Predicts Clustering and Transfer of Rule Sets in Reinforcement Learning},
  author = {Collins, Anne Gabrielle Eva},
  date = {2016},
  pages = {10},
  abstract = {Often the world is structured such that distinct sensory contexts signify the same abstract rule set. Learning from feedback thus informs us not only about the value of stimulus-action associations but also about which rule set applies. Hierarchical clustering models suggest that learners discover structure in the environment, clustering distinct sensory events into a single latent rule set. Such structure enables a learner to transfer any newly acquired information to other contexts linked to the same rule set, and facilitates re-use of learned knowledge in novel contexts. Here, we show that humans exhibit this transfer, generalization and clustering during learning. Trial-by-trial model-based analysis of EEG signals revealed that subjects’ reward expectations incorporated this hierarchical structure; these structured neural signals were predictive of behavioral transfer and clustering. These results further our understanding of how humans learn and generalize flexibly by building abstract, behaviorally relevant representations of the complex, high-dimensional sensory environment.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Y6GPFVBC/Collins - 2016 - Neural signature of hierarchically structured expe.pdf}
}

@article{constantinescuOrganizingConceptualKnowledge,
  title = {Organizing Conceptual Knowledge in Humans with a Gridlike Code},
  author = {Constantinescu, Alexandra O},
  pages = {6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/TG6KRJHE/Constantinescu - Organizing conceptual knowledge in humans with a g.pdf}
}

@article{constantinescuOrganizingConceptualKnowledge2016,
  title = {Organizing Conceptual Knowledge in Humans with a Gridlike Code},
  author = {Constantinescu, A. O. and OReilly, J. X. and Behrens, T. E. J.},
  date = {2016-06-17},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {352},
  number = {6292},
  pages = {1464--1468},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aaf0941},
  url = {https://www.sciencemag.org/lookup/doi/10.1126/science.aaf0941},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/V9RPUYUG/Constantinescu et al. - 2016 - Organizing conceptual knowledge in humans with a g.pdf}
}

@article{cooperSingleLevelAccountsRole2015,
  title = {Beyond {{Single}}-{{Level Accounts}}: {{The Role}} of {{Cognitive Architectures}} in {{Cognitive Scientiﬁc Explanation}}},
  author = {Cooper, Richard P and Peebles, David},
  date = {2015},
  journaltitle = {Topics in Cognitive Science},
  pages = {17},
  abstract = {We consider approaches to explanation within the cognitive sciences that begin with Marr’s computational level (e.g., purely Bayesian accounts of cognitive phenomena) or Marr’s implementational level (e.g., reductionist accounts of cognitive phenomena based only on neural-level evidence) and argue that each is subject to fundamental limitations which impair their ability to provide adequate explanations of cognitive phenomena. For this reason, it is argued, explanation cannot proceed at either level without tight coupling to the algorithmic and representation level. Even at this level, however, we argue that additional constraints relating to the decomposition of the cognitive system into a set of interacting subfunctions (i.e., a cognitive architecture) are required. Integrated cognitive architectures that permit abstract specification of the functions of components and that make contact with the neural level provide a powerful bridge for linking the algorithmic and representational level to both the computational level and the implementational level.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3JAPHDZH/Cooper and Peebles - 2015 - Beyond Single-Level Accounts The Role of Cognitiv.pdf;/Users/alexten/Zotero/storage/6QH9PK6I/Cooper and Peebles - 2015 - Beyond Single-Level Accounts The Role of Cognitiv.pdf}
}

@article{coopersteinActiveLearningConstructivist2004,
  title = {Beyond Active Learning: A Constructivist Approach to Learning},
  author = {Cooperstein, Susan E and Kocevar‐Weidinger, Elizabeth},
  date = {2004},
  journaltitle = {Reference Services Review},
  volume = {32},
  number = {2},
  pages = {11},
  abstract = {Guided by four principles – learners construct their own meaning; new learning builds on prior knowledge; learning is enhanced by social interaction; and learning develops through “authentic” tasks – constructivist learning moves from experience to knowledge and not the other way around. In a constructivist classroom, the activities lead to the concepts; the students construct the meanings. Learning happens! Abstract concepts become meaningful, transferable, and retained because they are attached to the performance of a concrete activity. This article discusses the elements of constructive learning and describes ways to apply those elements to library instruction to create truly “active” learning. An appendix contains sample exercises.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BTTGJ997/Cooperstein and Kocevar‐Weidinger - 2004 - Beyond active learning a constructivist approach .pdf}
}

@article{costaSubcorticalSubstratesExploreExploit,
  title = {Subcortical {{Substrates}} of {{Explore}}-{{Exploit Decisions}} in {{Primates}}},
  author = {Costa, Vincent D},
  pages = {19},
  abstract = {The explore-exploit dilemma refers to the challenge of deciding when to forego immediate rewards and explore new opportunities that could lead to greater rewards in the future. While motivational neural circuits facilitate learning based on past choices and outcomes, it is unclear whether they also support computations relevant for deciding when to explore. We recorded neural activity in the amygdala and ventral striatum of rhesus macaques as they solved a task that required them to balance novelty-driven exploration with exploitation of what they had already learned. Using a partially observable Markov decision process (POMDP) model to quantify explore-exploit trade-offs, we identified that the ventral striatum and amygdala differ in how they represent the immediate value of exploitative choices and the future value of exploratory choices. These findings show that subcortical motivational circuits are important in guiding explore-exploit decisions.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/T55IGPU3/Costa - Subcortical Substrates of Explore-Exploit Decision.pdf}
}

@article{costaSubcorticalSubstratesExploreExploit2019,
  title = {Subcortical {{Substrates}} of {{Explore}}-{{Exploit Decisions}} in {{Primates}}},
  author = {Costa, Vincent D. and Mitz, Andrew R. and Averbeck, Bruno B.},
  date = {2019-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {103},
  number = {3},
  pages = {533-545.e5},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.05.017},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627319304428},
  urldate = {2021-01-22},
  abstract = {The explore-exploit dilemma refers to the challenge of deciding when to forego immediate rewards and explore new opportunities that could lead to greater rewards in the future. While motivational neural circuits facilitate learning based on past choices and outcomes, it is unclear whether they also support computations relevant for deciding when to explore. We recorded neural activity in the amygdala and ventral striatum of rhesus macaques as they solved a task that required them to balance novelty-driven exploration with exploitation of what they had already learned. Using a partially observable Markov decision process (POMDP) model to quantify explore-exploit trade-offs, we identified that the ventral striatum and amygdala differ in how they represent the immediate value of exploitative choices and the future value of exploratory choices. These findings show that subcortical motivational circuits are important in guiding explore-exploit decisions.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/R25F9ZY7/Costa et al. - 2019 - Subcortical Substrates of Explore-Exploit Decision.pdf}
}

@article{CostlyCuriosityPeople2019,
  title = {Costly Curiosity\_ {{People}} Pay a Price to Resolve an Uncertain Gamble Early},
  date = {2019},
  journaltitle = {Behavioural Processes},
  pages = {6},
  abstract = {Humans are inherently curious creatures, continuously seeking out information about future outcomes. Such advance information is often valuable, potentially allowing people to select better courses of action. In nonhuman animals, this drive for information can be so strong that they forego food or water to find out a few seconds earlier whether an uncertain option will provide a reward. Here, we assess whether people will exhibit a similar sub-optimal preference for advance information. Participants played a card-flipping task where they were probabilistically rewarded based on the pattern of 3 cards that were revealed after a 5-s delay. During this delay, participants could instead pay a cost to find out the next card’s identity immediately. This choice to find out early did not influence the eventual outcome. Participants preferred to find out early about 80\% of the time when the information was free; they were even willing to incur an expense to get advance information about the eventual outcome. The expected magnitude of the outcome, however, had little impact on the likelihood of finding out early. These results suggest that humans, like animals, value non-instrumental information and will pay a price for such information, independent of its utility.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5IHK53RK/2019 - Costly curiosity_ People pay a price to resolve an.pdf;/Users/alexten/Zotero/storage/BCNFHEB3/2019 - Costly curiosity_ People pay a price to resolve an.pdf}
}

@article{cushmanHabitualControlGoal2015,
  title = {Habitual Control of Goal Selection in Humans},
  author = {Cushman, Fiery and Morris, Adam},
  date = {2015-11-10},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc Natl Acad Sci USA},
  volume = {112},
  number = {45},
  pages = {13817--13822},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1506367112},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1506367112},
  urldate = {2021-01-22},
  abstract = {Humans choose actions based on both habit and planning. Habitual control is computationally frugal but adapts slowly to novel circumstances, whereas planning is computationally expensive but can adapt swiftly. Current research emphasizes the competition between habits and plans for behavioral control, yet many complex tasks instead favor their integration. We consider a hierarchical architecture that exploits the computational efficiency of habitual control to select goals while preserving the flexibility of planning to achieve those goals. We formalize this mechanism in a reinforcement learning setting, illustrate its costs and benefits, and experimentally demonstrate its spontaneous application in a sequential decision-making task.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/VUEK5Y2P/Cushman and Morris - Habitual control of goal selection in humans.pdf;/Users/alexten/Zotero/storage/W36A36VP/Cushman and Morris - 2015 - Habitual control of goal selection in humans.pdf}
}

@article{daddaouaIntrinsicallyMotivatedOculomotor2016,
  title = {Intrinsically Motivated Oculomotor Exploration Guided by Uncertainty Reduction and Conditioned Reinforcement in Non-Human Primates},
  author = {Daddaoua, Nabil and Lopes, Manuel and Gottlieb, Jacqueline},
  date = {2016-04},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {6},
  number = {1},
  pages = {20202},
  issn = {2045-2322},
  doi = {10.1038/srep20202},
  url = {http://www.nature.com/articles/srep20202},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/948G4CNM/Daddaoua et al. - 2016 - Intrinsically motivated oculomotor exploration gui.pdf;/Users/alexten/Zotero/storage/ZKJP3IVG/Daddaoua - Intrinsically motivated oculomotor exploration gui.pdf}
}

@article{dawCOGNITIVENEUROSCIENCEMOTIVATION,
  title = {{{THE COGNITIVE NEUROSCIENCE OF MOTIVATION AND LEARNING}}},
  author = {Daw, Nathaniel D and Shohamy, Daphna},
  pages = {28},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3RXJ6QE6/Daw and Shohamy - THE COGNITIVE NEUROSCIENCE OF MOTIVATION AND LEARN.pdf}
}

@article{dawCognitiveNeuroscienceMotivation2008,
  title = {The {{Cognitive Neuroscience}} of {{Motivation}} and {{Learning}}},
  author = {Daw, Nathaniel D. and Shohamy, Daphna},
  date = {2008-10},
  journaltitle = {Social Cognition},
  shortjournal = {Social Cognition},
  volume = {26},
  number = {5},
  pages = {593--620},
  issn = {0278-016X},
  doi = {10.1521/soco.2008.26.5.593},
  url = {http://guilfordjournals.com/doi/10.1521/soco.2008.26.5.593},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WN5FGSCA/Daw and Shohamy - 2008 - The Cognitive Neuroscience of Motivation and Learn.pdf}
}

@article{dawComputationalNeurobiologyLearning2006,
  title = {The Computational Neurobiology of Learning and Reward},
  author = {Daw, Nathaniel D and Doya, Kenji},
  date = {2006},
  journaltitle = {Current Opinion in Neurobiology},
  pages = {6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/V6M4RZDE/Daw and Doya - 2006 - The computational neurobiology of learning and rew.pdf}
}

@article{dawComputationalNeurobiologyLearning2006a,
  title = {The Computational Neurobiology of Learning and Reward},
  author = {Daw, Nathaniel D and Doya, Kenji},
  date = {2006},
  journaltitle = {Current Opinion in Neurobiology},
  pages = {6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/54J6395A/Daw and Doya - 2006 - The computational neurobiology of learning and rew.pdf}
}

@article{dawCorticalSubstratesExploratory2006,
  title = {Cortical Substrates for Exploratory Decisions in Humans},
  author = {Daw, Nathaniel D and O’Doherty, John P and Dayan, Peter and Seymour, Ben and Dolan, Raymond J},
  date = {2006},
  volume = {441},
  pages = {5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DFS2MNPF/Daw et al. - 2006 - Cortical substrates for exploratory decisions in h.pdf;/Users/alexten/Zotero/storage/VH82AFTL/Daw et al. - 2006 - Cortical substrates for exploratory decisions in h.pdf}
}

@article{dawsonCorrespondenceCoherenceScience2009,
  title = {Correspondence and Coherence in Science: {{A}} Brief Historical Perspective},
  author = {Dawson, Neal V and Gregory, Fredrick},
  date = {2009},
  journaltitle = {Judgment and Decision Making},
  volume = {4},
  number = {2},
  pages = {8},
  abstract = {This paper introduces historical aspects of the concepts correspondence and coherence with emphasis on the nineteenth century when key aspects of modern science were emerging. It is not intended to be a definitive history of the concepts of correspondence and coherence as they have been used across the centuries in the field of inquiry that we now call science. Rather it is a brief history that highlights the apparent origins of the concepts and provides a discussion of how these concepts contributed to two important science related controversies. The first relates to aspects of evolution in which correspondence and coherence, as competing theories of truth, played a central role. The controversy about evolution continues into the beginning of the twenty-first century in forms that are recognizably similar to those of the middle of the nineteenth century. The second controversy relates to the etiology of blood-born infections (sepsis) during childbirth (childbed fever). In addition to correspondence and coherence, the authors introduce other theories of truth and discuss an evolutionarily cogent theory of truth, the pragmatic theory of truth.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/HGNTWITC/Dawson and Gregory - 2009 - Correspondence and coherence in science A brief h.pdf;/Users/alexten/Zotero/storage/UPC7IPSJ/Dawson and Gregory - 2009 - Correspondence and coherence in science A brief h.pdf}
}

@article{dawTrialbytrialDataAnalysisa,
  title = {Trial-by-Trial Data Analysis Using Computational Models},
  author = {Daw, Nathaniel D},
  pages = {26},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9IIYNUWW/Daw - Trial-by-trial data analysis using computational m.pdf}
}

@incollection{dawValueLearningReinforcement2014,
  title = {Value {{Learning}} through {{Reinforcement}}},
  booktitle = {Neuroeconomics},
  author = {Daw, Nathaniel D. and Tobler, Philippe N.},
  date = {2014},
  pages = {283--298},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-12-416008-8.00015-2},
  url = {https://linkinghub.elsevier.com/retrieve/pii/B9780124160088000152},
  urldate = {2021-01-22},
  isbn = {978-0-12-416008-8},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Y9TGANC2/Daw and Tobler - 2014 - Value Learning through Reinforcement.pdf}
}

@article{dayanDecisionTheoryReinforcement,
  title = {Decision Theory, Reinforcement Learning, and the Brain},
  author = {Dayan, Peter and Daw, Nathaniel D},
  journaltitle = {DECISION THEORY},
  pages = {25},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3JM2FYAS/Dayan and Daw - Decision theory, reinforcement learning, and the b.pdf}
}

@article{dayanModelbasedModelfreePavlovian,
  title = {Model-Based and Model-Free {{Pavlovian}} Reward Learning: {{Revaluation}}, Revision, and Revelation},
  author = {Dayan, Peter and Berridge, Kent C},
  journaltitle = {Cogn Affect Behav Neurosci},
  pages = {20},
  abstract = {Evidence supports at least two methods for learning about reward and punishment and making predictions for guiding actions. One method, called model-free, progressively acquires cached estimates of the long-run values of circumstances and actions from retrospective experience. The other method, called model-based, uses representations of the environment, expectations, and prospective calculations to make cognitive predictions of future value. Extensive attention has been paid to both methods in computational analyses of instrumental learning. By contrast, although a full computational analysis has been lacking, Pavlovian learning and prediction has typically been presumed to be solely model-free. Here, we revise that presumption and review compelling evidence from Pavlovian revaluation experiments showing that Pavlovian predictions can involve their own form of model-based evaluation. In model-based Pavlovian evaluation, prevailing states of the body and brain influence value computations, and thereby produce powerful incentive motivations that can sometimes be quite new. We consider the consequences of this revised Pavlovian view for the computational landscape of prediction, response, and choice. We also revisit differences between Pavlovian and instrumental learning in the control of incentive motivation.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SUJFPZPS/Dayan and Berridge - Model-based and model-free Pavlovian reward learni.pdf}
}

@article{dayanModelbasedModelfreePavloviana,
  title = {Model-Based and Model-Free {{Pavlovian}} Reward Learning: {{Revaluation}}, Revision, and Revelation},
  author = {Dayan, Peter and Berridge, Kent C},
  journaltitle = {Cogn Affect Behav Neurosci},
  pages = {20},
  abstract = {Evidence supports at least two methods for learning about reward and punishment and making predictions for guiding actions. One method, called model-free, progressively acquires cached estimates of the long-run values of circumstances and actions from retrospective experience. The other method, called model-based, uses representations of the environment, expectations, and prospective calculations to make cognitive predictions of future value. Extensive attention has been paid to both methods in computational analyses of instrumental learning. By contrast, although a full computational analysis has been lacking, Pavlovian learning and prediction has typically been presumed to be solely model-free. Here, we revise that presumption and review compelling evidence from Pavlovian revaluation experiments showing that Pavlovian predictions can involve their own form of model-based evaluation. In model-based Pavlovian evaluation, prevailing states of the body and brain influence value computations, and thereby produce powerful incentive motivations that can sometimes be quite new. We consider the consequences of this revised Pavlovian view for the computational landscape of prediction, response, and choice. We also revisit differences between Pavlovian and instrumental learning in the control of incentive motivation.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7XSN6HUR/Dayan and Berridge - Model-based and model-free Pavlovian reward learni.pdf}
}

@article{dayanReinforcementLearningGood2008,
  title = {Reinforcement Learning: {{The Good}}, {{The Bad}} and {{The Ugly}}},
  author = {Dayan, Peter and Niv, Yael},
  date = {2008},
  journaltitle = {Current Opinion in Neurobiology},
  pages = {12},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/V258QC6C/Dayan and Niv - 2008 - Reinforcement learning The Good, The Bad and The .pdf}
}

@article{dayanReinforcementLearningGood2008a,
  title = {Reinforcement Learning: {{The Good}}, {{The Bad}} and {{The Ugly}}},
  author = {Dayan, Peter and Niv, Yael},
  date = {2008},
  journaltitle = {Current Opinion in Neurobiology},
  pages = {12},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Y2CEX28W/Dayan and Niv - 2008 - Reinforcement learning The Good, The Bad and The .pdf}
}

@article{declippelReasonbasedChoiceBargaining2012,
  title = {Reason-Based Choice: {{A}} Bargaining Rationale for the Attraction and Compromise Effects: {{Reason}}-Based Choice},
  shorttitle = {Reason-Based Choice},
  author = {de Clippel, Geoffroy and Eliaz, Kfir},
  options = {useprefix=true},
  date = {2012-01},
  journaltitle = {Theoretical Economics},
  volume = {7},
  number = {1},
  pages = {125--162},
  issn = {19336837},
  doi = {10.3982/TE798},
  url = {http://doi.wiley.com/10.3982/TE798},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SRZU85A3/de Clippel and Eliaz - 2012 - Reason-based choice A bargaining rationale for th.pdf}
}

@article{desenderPostdecisionalNeuralMarker,
  title = {A {{Postdecisional Neural Marker}} of {{Confidence Predicts Information}}-{{Seeking}} in {{Decision}}-{{Making}}},
  author = {Desender, X Kobe and Murphy, X Peter and Boldt, X Annika and Verguts, X Tom and Yeung, X Nick},
  pages = {11},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4VJ4J579/Desender et al. - A Postdecisional Neural Marker of Confidence Predi.pdf}
}

@article{desenderSubjectiveConfidencePredicts,
  title = {Subjective {{Confidence Predicts Information Seeking}} in {{Decision Making}}},
  author = {Desender, Kobe and Boldt, Annika and Yeung, Nick},
  pages = {19},
  abstract = {There is currently little direct evidence regarding the function of subjective confidence in decision making: The tight correlation between objective accuracy and subjective confidence makes it difficult to distinguish each variable’s unique contribution. Here, we created conditions in a perceptual decision task that were matched in accuracy but differed in subjective evaluation of accuracy by orthogonally varying the strength versus variability of evidence. Confidence was reduced with variable (vs. weak) evidence, even across conditions matched for difficulty. Building on this dissociation, we constructed a paradigm in which participants (N = 20) could choose to seek further information before making their decision. The data provided clear support for the hypothesis that subjective confidence predicts information seeking in decision making: Participants were more likely to sample additional information before giving a response in the condition with low confidence, despite matched accuracy. In a preregistered replication (N = 50), these findings were replicated with increased task difficulty levels.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4MAUH7WG/Desender et al. - Subjective Confidence Predicts Information Seeking.pdf}
}

@article{desenderSubjectiveConfidencePredictsa,
  title = {Subjective {{Confidence Predicts Information Seeking}} in {{Decision Making}}},
  author = {Desender, Kobe and Boldt, Annika and Yeung, Nick},
  pages = {19},
  abstract = {There is currently little direct evidence regarding the function of subjective confidence in decision making: The tight correlation between objective accuracy and subjective confidence makes it difficult to distinguish each variable’s unique contribution. Here, we created conditions in a perceptual decision task that were matched in accuracy but differed in subjective evaluation of accuracy by orthogonally varying the strength versus variability of evidence. Confidence was reduced with variable (vs. weak) evidence, even across conditions matched for difficulty. Building on this dissociation, we constructed a paradigm in which participants (N = 20) could choose to seek further information before making their decision. The data provided clear support for the hypothesis that subjective confidence predicts information seeking in decision making: Participants were more likely to sample additional information before giving a response in the condition with low confidence, despite matched accuracy. In a preregistered replication (N = 50), these findings were replicated with increased task difficulty levels.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DH428E4X/Desender et al. - Subjective Confidence Predicts Information Seeking.pdf}
}

@article{desousaEMOTIONSWHATKNOW,
  title = {{{EMOTIONS}}: {{WHAT I KNOW}}, {{WHAT I}}'{{D LIKE TO THINK I KNOW}}, {{AND WHAT I}}'{{D LIKE TO THINK}}.},
  author = {de Sousa, Ronald},
  options = {useprefix=true},
  pages = {21},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6KBDMULT/de Sousa - EMOTIONS WHAT I KNOW, WHAT I'D LIKE TO THINK I KN.pdf;/Users/alexten/Zotero/storage/WPNAJGEF/de Sousa - EMOTIONS WHAT I KNOW, WHAT I'D LIKE TO THINK I KN.pdf}
}

@article{deterdingCuriosityGamesInterdisciplinary,
  title = {Curiosity in {{Games}}: {{An Interdisciplinary Workshop}}},
  author = {Deterding, Sebastian and Smith, Davy and Powley, Edward J and Hammer, Jessica},
  pages = {2},
  abstract = {Curiosity is emerging as an important source of gameplay engagement and enjoyment. While there is rich and growing work on human and computational curiosity across fields, there is little multidisciplinary dialogue on curiosity and how to design for it in games, manually or computationally. This one-day workshop therefore convenes HCI, design, and AI researchers to establish and advance the state of the art in curiosity in games.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/TF8LBW7S/Deterding et al. - Curiosity in Games An Interdisciplinary Workshop.pdf;/Users/alexten/Zotero/storage/VWS5Z4BR/Deterding et al. - Curiosity in Games An Interdisciplinary Workshop.pdf}
}

@article{didomenicoEmergingNeuroscienceIntrinsic2017,
  title = {The {{Emerging Neuroscience}} of {{Intrinsic Motivation}}: {{A New Frontier}} in {{Self}}-{{Determination Research}}},
  shorttitle = {The {{Emerging Neuroscience}} of {{Intrinsic Motivation}}},
  author = {Di Domenico, Stefano I. and Ryan, Richard M.},
  date = {2017-03-24},
  journaltitle = {Frontiers in Human Neuroscience},
  shortjournal = {Front. Hum. Neurosci.},
  volume = {11},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2017.00145},
  url = {http://journal.frontiersin.org/article/10.3389/fnhum.2017.00145/full},
  urldate = {2021-01-22},
  abstract = {Intrinsic motivation refers to people’s spontaneous tendencies to be curious and interested, to seek out challenges and to exercise and develop their skills and knowledge, even in the absence of operationally separable rewards. Over the past four decades, experimental and field research guided by self-determination theory (SDT; Ryan and Deci, 2017) has found intrinsic motivation to predict enhanced learning, performance, creativity, optimal development and psychological wellness. Only recently, however, have studies begun to examine the neurobiological substrates of intrinsic motivation. In the present article, we trace the history of intrinsic motivation research, compare and contrast intrinsic motivation to closely related topics (flow, curiosity, trait plasticity), link intrinsic motivation to key findings in the comparative affective neurosciences, and review burgeoning neuroscience research on intrinsic motivation. We review converging evidence suggesting that intrinsically motivated exploratory and mastery behaviors are phylogenetically ancient tendencies that are subserved by dopaminergic systems. Studies also suggest that intrinsic motivation is associated with patterns of activity across large-scale neural networks, namely, those that support salience detection, attentional control and self-referential cognition. We suggest novel research directions and offer recommendations for the application of neuroscience methods in the study of intrinsic motivation.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ALPVL7YU/Di Domenico and Ryan - 2017 - The Emerging Neuroscience of Intrinsic Motivation.pdf}
}

@article{dienesBayesianOrthodoxStatistics2011,
  title = {Bayesian {{Versus Orthodox Statistics}}: {{Which Side Are You On}}?},
  shorttitle = {Bayesian {{Versus Orthodox Statistics}}},
  author = {Dienes, Zoltan},
  date = {2011-05},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {6},
  number = {3},
  pages = {274--290},
  issn = {1745-6916, 1745-6924},
  doi = {10.1177/1745691611406920},
  url = {http://journals.sagepub.com/doi/10.1177/1745691611406920},
  urldate = {2021-01-22},
  abstract = {Researchers are often confused about what can be inferred from significance tests. One problem occurs when people apply Bayesian intuitions to significance testing—two approaches that must be firmly separated. This article presents some common situations in which the approaches come to different conclusions; you can see where your intuitions initially lie. The situations include multiple testing, deciding when to stop running participants, and when a theory was thought of relative to finding out results. The interpretation of nonsignificant results has also been persistently problematic in a way that Bayesian inference can clarify. The Bayesian and orthodox approaches are placed in the context of different notions of rationality, and I accuse myself and others as having been irrational in the way we have been using statistics on a key notion of rationality. The reader is shown how to apply Bayesian inference in practice, using free online software, to allow more coherent inferences from data.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FCTAE4UV/Dienes - 2011 - Bayesian Versus Orthodox Statistics Which Side Ar.pdf;/Users/alexten/Zotero/storage/GRCJEJEE/Dienes - 2011 - Bayesian Versus Orthodox Statistics Which Side Ar.pdf}
}

@article{dingemanseArbitrarinessIconicitySystematicity2015,
  title = {Arbitrariness, {{Iconicity}}, and {{Systematicity}} in {{Language}}},
  author = {Dingemanse, Mark and Blasi, Damián E. and Lupyan, Gary and Christiansen, Morten H. and Monaghan, Padraic},
  date = {2015-10},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {19},
  number = {10},
  pages = {603--615},
  issn = {13646613},
  doi = {10.1016/j.tics.2015.07.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661315001771},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QIT8HF44/Dingemanse et al. - 2015 - Arbitrariness, Iconicity, and Systematicity in Lan.pdf}
}

@article{dixonTheoryRevisionRedescription2007,
  title = {Theory {{Revision}} and {{Redescription}}: {{Complementary Processes}} in {{Knowledge Acquisition}}},
  shorttitle = {Theory {{Revision}} and {{Redescription}}},
  author = {Dixon, James A. and Kelley, Elizabeth},
  date = {2007-04},
  journaltitle = {Current Directions in Psychological Science},
  shortjournal = {Curr Dir Psychol Sci},
  volume = {16},
  number = {2},
  pages = {111--115},
  issn = {0963-7214, 1467-8721},
  doi = {10.1111/j.1467-8721.2007.00486.x},
  url = {http://journals.sagepub.com/doi/10.1111/j.1467-8721.2007.00486.x},
  urldate = {2021-01-22},
  abstract = {Children acquire complex relational representations of the world. Explaining the acquisition of these representations has been a significant challenge for theories of cognitive development. Recent work suggests that two processes, theory revision and redescription, operate in an iterative, complementary fashion to produce new representations. Given a novel situation, children use theory revision to generate a candidate relational structure and can modify that structure in response to error. Redescription detects regularities created through successful use of that structure in interaction with the environment; these regularities are consolidated into new representations, which are then available to the theoryrevision process. The complementary nature of these processes is illustrated by recent work on representational change in a gear-system task and in arithmetic concepts. Theory revision and redescription occupy different, but mutually supportive, niches in knowledge acquisition.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/I4UJBTB3/Dixon and Kelley - 2007 - Theory Revision and Redescription Complementary P.pdf}
}

@article{Doi101053,
  title = {Doi:10.1053/j.Seminhematol.2008.04.003},
  pages = {6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2UVUQHW8/doi10.1053j.seminhematol.2008.04.003.pdf}
}

@article{dollUbiquityModelbasedReinforcement2012,
  title = {The Ubiquity of Model-Based Reinforcement Learning},
  author = {Doll, Bradley B},
  date = {2012},
  journaltitle = {Current Opinion in Neurobiology},
  pages = {7},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/HUSEIWKF/Doll - 2012 - The ubiquity of model-based reinforcement learning.pdf}
}

@article{dollUbiquityModelbasedReinforcement2012a,
  title = {The Ubiquity of Model-Based Reinforcement Learning},
  author = {Doll, Bradley B},
  date = {2012},
  journaltitle = {Current Opinion in Neurobiology},
  pages = {7},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/K9WNQB49/Doll - 2012 - The ubiquity of model-based reinforcement learning.pdf}
}

@article{domenicoEmergingNeuroscienceIntrinsic2017,
  title = {The {{Emerging Neuroscience}} of {{Intrinsic Motivation}}: {{A New Frontier}} in {{Self}}-{{Determination Research}}},
  author = {Domenico, Stefano I Di},
  date = {2017},
  journaltitle = {Frontiers in Human Neuroscience},
  volume = {11},
  pages = {14},
  abstract = {Intrinsic motivation refers to people’s spontaneous tendencies to be curious and interested, to seek out challenges and to exercise and develop their skills and knowledge, even in the absence of operationally separable rewards. Over the past four decades, experimental and field research guided by self-determination theory (SDT; Ryan and Deci, 2017) has found intrinsic motivation to predict enhanced learning, performance, creativity, optimal development and psychological wellness. Only recently, however, have studies begun to examine the neurobiological substrates of intrinsic motivation. In the present article, we trace the history of intrinsic motivation research, compare and contrast intrinsic motivation to closely related topics (flow, curiosity, trait plasticity), link intrinsic motivation to key findings in the comparative affective neurosciences, and review burgeoning neuroscience research on intrinsic motivation. We review converging evidence suggesting that intrinsically motivated exploratory and mastery behaviors are phylogenetically ancient tendencies that are subserved by dopaminergic systems. Studies also suggest that intrinsic motivation is associated with patterns of activity across large-scale neural networks, namely, those that support salience detection, attentional control and self-referential cognition. We suggest novel research directions and offer recommendations for the application of neuroscience methods in the study of intrinsic motivation.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SYGYJDFQ/Domenico - 2017 - The Emerging Neuroscience of Intrinsic Motivation.pdf}
}

@article{doncieuxRepresentationalRedescriptionNext,
  title = {Representational Redescription: The next Challenge?},
  author = {Doncieux, Stephane},
  pages = {2},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/A795EI9N/Doncieux - Representational redescription the next challenge.pdf}
}

@article{doncieuxRepresentationalRedescriptionNexta,
  title = {Representational Redescription: The next Challenge?},
  author = {Doncieux, Stephane},
  pages = {2},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MCH59IHD/Doncieux - Representational redescription the next challenge.pdf}
}

@article{doroudiWhereReward,
  title = {Where’s the {{Reward}}?},
  author = {Doroudi, Shayan},
  journaltitle = {International Journal of Artificial Intelligence in Education},
  pages = {53},
  abstract = {Since the 1960s, researchers have been trying to optimize the sequencing of instructional activities using the tools of reinforcement learning (RL) and sequential decision making under uncertainty. Many researchers have realized that reinforcement learning provides a natural framework for optimal instructional sequencing given a particular model of student learning, and excitement towards this area of research is as alive now as it was over fifty years ago. But does RL actually help students learn? If so, when and where might we expect it to be most helpful? To help answer these questions, we review the variety of attempts to use RL for instructional sequencing. First, we present a historical narrative of this research area. We identify three waves of research, which gives us a sense of the various communities of researchers that have been interested in this problem and where the field is going. Second, we review all of the empirical research that has compared RL-induced instructional policies to baseline methods of sequencing. We find that over half of the studies found that RL-induced policies significantly outperform baselines. Moreover, we identify five clusters of studies with different characteristics and varying levels of success in using RL to help students learn. We find that reinforcement learning has been most successful in cases where it has been constrained with ideas and theories from cognitive psychology and the learning sciences. However, given that our theories and models are limited, we also find that it has been useful to complement this approach with running more robust offline analyses that do not rely heavily on the assumptions of one particular model. Given that many researchers are turning to deep reinforcement learning and big data to tackle instructional sequencing, we believe keeping these best practices in mind can help guide the way to the reward in using RL for instructional sequencing.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9T3M3L6N/Doroudi - Where’s the Reward.pdf}
}

@article{doroudiWhereRewarda,
  title = {Where’s the {{Reward}}?},
  author = {Doroudi, Shayan},
  journaltitle = {International Journal of Artificial Intelligence in Education},
  pages = {53},
  abstract = {Since the 1960s, researchers have been trying to optimize the sequencing of instructional activities using the tools of reinforcement learning (RL) and sequential decision making under uncertainty. Many researchers have realized that reinforcement learning provides a natural framework for optimal instructional sequencing given a particular model of student learning, and excitement towards this area of research is as alive now as it was over fifty years ago. But does RL actually help students learn? If so, when and where might we expect it to be most helpful? To help answer these questions, we review the variety of attempts to use RL for instructional sequencing. First, we present a historical narrative of this research area. We identify three waves of research, which gives us a sense of the various communities of researchers that have been interested in this problem and where the field is going. Second, we review all of the empirical research that has compared RL-induced instructional policies to baseline methods of sequencing. We find that over half of the studies found that RL-induced policies significantly outperform baselines. Moreover, we identify five clusters of studies with different characteristics and varying levels of success in using RL to help students learn. We find that reinforcement learning has been most successful in cases where it has been constrained with ideas and theories from cognitive psychology and the learning sciences. However, given that our theories and models are limited, we also find that it has been useful to complement this approach with running more robust offline analyses that do not rely heavily on the assumptions of one particular model. Given that many researchers are turning to deep reinforcement learning and big data to tackle instructional sequencing, we believe keeping these best practices in mind can help guide the way to the reward in using RL for instructional sequencing.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MRLZ7PNX/Doroudi - Where’s the Reward.pdf}
}

@article{doyaModulatorsDecisionMaking2008,
  title = {Modulators of Decision Making},
  author = {Doya, Kenji},
  date = {2008-04},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {11},
  number = {4},
  pages = {410--416},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn2077},
  url = {http://www.nature.com/articles/nn2077},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ERVDA9LB/Doya - 2008 - Modulators of decision making.pdf}
}

@article{doyaModulatorsDecisionMaking2008a,
  title = {Modulators of Decision Making},
  author = {Doya, Kenji},
  date = {2008-04},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {11},
  number = {4},
  pages = {410--416},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn2077},
  url = {http://www.nature.com/articles/nn2077},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EQFD7QGI/Doya - 2008 - Modulators of decision making.pdf}
}

@article{doyaReinforcementLearningComputational2007,
  title = {Reinforcement Learning: {{Computational}} Theory and Biological Mechanisms},
  author = {Doya, Kenji},
  date = {2007},
  journaltitle = {HFSP Journal},
  volume = {1},
  pages = {11},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/S74SMCWA/Doya - 2007 - Reinforcement learning Computational theory and b.pdf}
}

@article{doyaReinforcementLearningComputational2007a,
  title = {Reinforcement Learning: {{Computational}} Theory and Biological Mechanisms},
  author = {Doya, Kenji},
  date = {2007},
  journaltitle = {HFSP Journal},
  volume = {1},
  pages = {11},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/YQJJYTWJ/Doya - 2007 - Reinforcement learning Computational theory and b.pdf}
}

@article{dubeyIfItImportant,
  title = {If It’s Important, Then {{I}} Am Curious: {{A}} Value Intervention to Induce Curiosity},
  author = {Dubey, Rachit and Griffiths, Thomas L and Lombrozo, Tania},
  pages = {7},
  abstract = {Curiosity is considered essential for learning and sustained engagement, yet stimulating curiosity in educational contexts remains a challenge. Can people’s curiosity about a topic be stimulated by evidence that the topic has potential value? In two experiments we show that increasing people’s perceptions about the usefulness of a scientific topic also influences their curiosity and subsequent information search. Our results also show that simply presenting interesting facts is not enough to influence curiosity, and that people are more likely to be curious about a topic if they perceive it to be directly valuable to them. Given the link between curiosity and learning, these results have important implications for science communication and education more broadly.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/E7E39L6A/Dubey et al. - If it’s important, then I am curious A value inte.pdf;/Users/alexten/Zotero/storage/Z2GRKGDJ/Dubey et al. - If it’s important, then I am curious A value inte.pdf}
}

@article{dubeyReconcilingNoveltyComplexitya,
  title = {Reconciling {{Novelty}} and {{Complexity Through}} a {{Rational Analysis}} of {{Curiosity}}},
  author = {Dubey, Rachit and Griffiths, Thomas L},
  pages = {22},
  abstract = {Curiosity is considered to be the essence of science and an integral component of cognition. What prompts curiosity in a learner? Previous theoretical accounts of curiosity remain divided—novelty-based theories propose that new and highly uncertain stimuli pique curiosity, whereas complexity-based theories propose that stimuli with an intermediate degree of uncertainty stimulate curiosity. In this article, we present a rational analysis of curiosity by considering the computational problem underlying curiosity, which allows us to model these distinct accounts of curiosity in a common framework. Our approach posits that a rational agent should explore stimuli that maximally increase the usefulness of its knowledge and that curiosity is the mechanism by which humans approximate this rational behavior. Critically, our analysis show that the causal structure of the environment can determine whether curiosity is driven by either highly uncertain or moderately uncertain stimuli. This suggests that previous theories need not be in contention but are special cases of a more general account of curiosity. Experimental results confirm our predictions and demonstrate that our theory explains a wide range of findings about human curiosity, including its subjectivity and malleability.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/L3EMTP8B/Dubey and Griffiths - Reconciling Novelty and Complexity Through a Ratio.pdf}
}

@article{dunloskySecondOrderJudgmentsJudgments2005,
  title = {Second-{{Order Judgments About Judgments}} of {{Learning}}},
  author = {Dunlosky, John and Serra, Michael J. and Matvey, Greg and Rawson, Katherine A.},
  date = {2005-10},
  journaltitle = {The Journal of General Psychology},
  shortjournal = {The Journal of General Psychology},
  volume = {132},
  number = {4},
  pages = {335--346},
  issn = {0022-1309, 1940-0888},
  doi = {10.3200/GENP.132.4.335-346},
  url = {http://www.tandfonline.com/doi/abs/10.3200/GENP.132.4.335-346},
  urldate = {2021-01-22},
  abstract = {The authors explored the relations between predictions of the likelihood of recalling studied items (called judgments of learning, or JOLs) and second-order judgments (SOJs), in which one rates confidence in the accuracy of each JOL. Each participant studied paired–associate items and made JOLs. A given JOL was either immediate or delayed and was followed immediately by an SOJ. After all items were studied and judged, paired–associate recall occurred. The incorporation of SOJs into this standard method yielded numerous outcomes relevant to theory of metacognitive judgments. SOJs were greater for extreme JOLs (0, 100) than for intermediate JOLs (40, 50). Also, JOL accuracy was greater for delayed than for immediate JOLs, and, reflecting this delayedJOL effect, SOJs were greater for delayed than for immediate JOLs. These and other outcomes support 2-process hypotheses of how people make JOLs and uncover some pitfalls in interpreting poor judgment accuracy.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QYMUAKSU/Dunlosky et al. - 2005 - Second-Order Judgments About Judgments of Learning.pdf}
}

@article{dysvikIntrinsicExtrinsicMotivation,
  title = {Intrinsic and Extrinsic Motivation as Predictors of Work Effort: {{The}} Moderating Role of Achievement Goals},
  author = {Dysvik, Anders},
  pages = {19},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6YMRXNU6/Dysvik - Intrinsic and extrinsic motivation as predictors o.pdf;/Users/alexten/Zotero/storage/L7G3XWES/Dysvik - Intrinsic and extrinsic motivation as predictors o.pdf}
}

@article{einsteinWORLDSEEIT,
  title = {{{THE WORLD AS I SEE IT}}},
  author = {Einstein, Albert},
  pages = {76},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/X7IJSDAI/Einstein - THE WORLD AS I SEE IT.pdf}
}

@article{einsteinWORLDSEEITa,
  title = {{{THE WORLD AS I SEE IT}}},
  author = {Einstein, Albert},
  pages = {76},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EWHW5D9J/Einstein - THE WORLD AS I SEE IT.pdf}
}

@article{eldarInteractionEmotionalState2015,
  title = {Interaction between Emotional State and Learning Underlies Mood Instability},
  author = {Eldar, Eran},
  date = {2015},
  journaltitle = {NATURE COMMUNICATIONS},
  pages = {10},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/G9H495TZ/Eldar - 2015 - Interaction between emotional state and learning u.pdf;/Users/alexten/Zotero/storage/J75KZ8NM/Eldar - 2015 - Interaction between emotional state and learning u.pdf}
}

@article{eliazExperimentalTestingIntrinsic2007,
  title = {Experimental {{Testing}} of {{Intrinsic Preferences}} for {{NonInstrumental Information}}},
  author = {Eliaz, Kfir and Schotter, Andrew},
  date = {2007-04-01},
  journaltitle = {American Economic Review},
  shortjournal = {American Economic Review},
  volume = {97},
  number = {2},
  pages = {166--169},
  issn = {0002-8282},
  doi = {10.1257/aer.97.2.166},
  url = {https://pubs.aeaweb.org/doi/10.1257/aer.97.2.166},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/88AQXFC6/Eliaz and Schotter - Experimental Testing of Intrinsic Preferences for .pdf;/Users/alexten/Zotero/storage/JC9SIP7P/Eliaz and Schotter - 2007 - Experimental Testing of Intrinsic Preferences for .pdf}
}

@article{elliotApproachAvoidanceAchievement,
  title = {Approach and {{Avoidance Achievement Goals}} and {{Intrinsic Motivation}}: {{A Mediational Analysis}}},
  author = {Elliot, Andrew J and Harackiewicz, Judith M},
  pages = {16},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/44ZN9DT7/Elliot and Harackiewicz - Approach and Avoidance Achievement Goals and Intri.pdf}
}

@article{elliotMeasurementAchievementGoals,
  title = {On the {{Measurement}} of {{Achievement Goals}}: {{Critique}}, {{Illustration}}, and {{Application}}},
  author = {Elliot, Andrew J and Murayama, Kou},
  pages = {16},
  abstract = {The authors identified several specific problems with the measurement of achievement goals in the current literature and illustrated these problems, focusing primarily on A. J. Elliot and H. A. McGregor’s (2001) Achievement Goal Questionnaire (AGQ). They attended to these problems by creating the AGQ-Revised and conducting a study that examined the measure’s structural validity and predictive utility with 229 (76 male, 150 female, 3 unspecified) undergraduates. The hypothesized factor and dimensional structures of the measure were confirmed and shown to be superior to a host of alternatives. The predictions were nearly uniformly supported with regard to both the antecedents (need for achievement and fear of failure) and consequences (intrinsic motivation and exam performance) of the 4 achievement goals. In discussing their work, the authors highlight the importance and value of additional precision in the area of achievement goal measurement.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QD2QXE3S/Elliot and Murayama - On the Measurement of Achievement Goals Critique,.pdf}
}

@article{elliotMeasurementAchievementGoals2008,
  title = {On the Measurement of Achievement Goals: {{Critique}}, Illustration, and Application.},
  shorttitle = {On the Measurement of Achievement Goals},
  author = {Elliot, Andrew J. and Murayama, Kou},
  date = {2008-08},
  journaltitle = {Journal of Educational Psychology},
  shortjournal = {Journal of Educational Psychology},
  volume = {100},
  number = {3},
  pages = {613--628},
  issn = {1939-2176, 0022-0663},
  doi = {10.1037/0022-0663.100.3.613},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0022-0663.100.3.613},
  urldate = {2021-01-22},
  abstract = {The authors identified several specific problems with the measurement of achievement goals in the current literature and illustrated these problems, focusing primarily on A. J. Elliot and H. A. McGregor’s (2001) Achievement Goal Questionnaire (AGQ). They attended to these problems by creating the AGQ-Revised and conducting a study that examined the measure’s structural validity and predictive utility with 229 (76 male, 150 female, 3 unspecified) undergraduates. The hypothesized factor and dimensional structures of the measure were confirmed and shown to be superior to a host of alternatives. The predictions were nearly uniformly supported with regard to both the antecedents (need for achievement and fear of failure) and consequences (intrinsic motivation and exam performance) of the 4 achievement goals. In discussing their work, the authors highlight the importance and value of additional precision in the area of achievement goal measurement.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EX7GRBRD/Elliot and Murayama - 2008 - On the measurement of achievement goals Critique,.pdf}
}

@article{elmanLearningDevelopmentNeural1993a,
  title = {Learning and Development in Neural Networks: The Importance of Starting Small},
  author = {Elman, L},
  date = {1993},
  pages = {29},
  abstract = {It is a striking fact that in humans the greatest learnmg occurs precisely at that point in time - childhood - when the most dramatic maturational changes also occur. This report describes possible synergistic interactions between maturational change and the ability to learn a complex domain (language), as investigated in connectionist networks. The networks are trained to process complex sentences involving relative clauses, number agreement, and several types of verb argument structure. Training fails in the case of networks which are fully formed and ‘adultlike’ in their capacity. Training succeeds only when networks begin with limited working memory and gradually ‘mature’ to the adult state. This result suggests that rather than being a limitation, developmental restrictions on resources may constitute a necessary prerequisite for mastering certain complex domains. Specifically, successful learning may depend on starting small.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/294SYRGE/Elman - 1993 - Learning and development in neural networks the i.pdf}
}

@article{ericksonMetacognitionConfidenceComparing2015a,
  title = {Metacognition and Confidence: Comparing Math to Other Academic Subjects},
  author = {Erickson, Shanna},
  date = {2015},
  journaltitle = {Frontiers in Psychology},
  volume = {6},
  pages = {10},
  abstract = {Two studies addressed student metacognition in math, measuring confidence accuracy about math performance. Underconfidence would be expected in light of pervasive math anxiety. However, one might alternatively expect overconfidence based on previous results showing overconfidence in other subject domains. Metacognitive judgments and performance were assessed for biology, literature, and mathematics tests. In Study 1, high school students took three different tests and provided estimates of their performance both before and after taking each test. In Study 2, undergraduates similarly took three shortened SAT II Subject Tests. Students were overconfident in predicting math performance, indeed showing greater overconfidence compared to other academic subjects. It appears that both overconfidence and anxiety can adversely affect metacognitive ability and can lead to math avoidance. The results have implications for educational practice and other environments that require extensive use of math.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JIST74VD/Erickson - 2015 - Metacognition and confidence comparing math to ot.pdf}
}

@article{etzIntroductionBayesianInference,
  title = {Introduction to {{Bayesian Inference}} for {{Psychology}}},
  author = {Etz, Alexander and Vandekerckhove, Joachim},
  pages = {24},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CG5MRR5U/Etz and Vandekerckhove - Introduction to Bayesian Inference for Psychology.pdf}
}

@article{evansEvaluationBiasfreeMeasure,
  title = {Evaluation of a ‘Bias-Free’ Measure of Awareness},
  author = {Evans, Simon and Azzopardi, Paul},
  pages = {18},
  abstract = {The derivation of a reliable, subjective measure of awareness that is not contaminated by observers’ response bias is a problem that has long occupied researchers. Kunimoto et al. (2001) proposed a measure of awareness (a ) which apparently meets this criterion: a is derived from confidence ratings and is based on the intuition that confidence should reflect awareness. The aim of this paper is to explore the validity of this measure. Some calculations suggested that, contrary to Kunimoto et al.’s intention, a can vary as a result of changes in response bias affecting the relative proportions of high- and low-confidence responses. This was not evident in the results of Kunimoto et al.’s original experiments because their method may have artificially ‘clamped’ observers’ response bias close to zero. A predicted consequence of allowing response bias to vary freely is that it can result in a varying from negative, through zero, to positive values, for a given value of discriminability (d ). We tested whether such variations are likely to occur in practice by employing Kunimoto et al.’s paradigm with various modifications, notably the removal of constraints upon the proportions of low- and high-confidence responses, in a visual discrimination task. As predicted, a varied with response bias in all participants. Similar results were found when a was calculated from pre-existing data obtained from a patient with blindsight: a varied through a range of positive results without approaching zero, which is inconsistent with his well-documented lack of awareness. A second experiment showed how response bias could be manipulated to yield elevated values of a . On the basis of these findings we conclude that Kunimoto’s measure is not as impervious to response bias as was originally assumed.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PXPCU4XZ/Evans and Azzopardi - Evaluation of a ‘bias-free’ measure of awareness.pdf}
}

@article{ferrignoMetacognitiveIllusionMonkeys,
  title = {A Metacognitive Illusion in Monkeys},
  author = {Ferrigno, Stephen and Kornell, Nate and Cantlon, Jessica F},
  pages = {6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EAHGL25A/Ferrigno et al. - A metacognitive illusion in monkeys.pdf;/Users/alexten/Zotero/storage/NGSQA8TV/Ferrigno et al. - A metacognitive illusion in monkeys.pdf}
}

@article{ferrignoSimilarBasisJudging,
  title = {A {{Similar Basis}} for {{Judging Confidence}} in {{Monkeys}} and {{Humans}}},
  author = {Ferrigno, Stephen and Bueno, Gabrielle L and Cantlon, Jessica F},
  pages = {9},
  abstract = {A variety of animals have been shown to make confidence judgments about their own knowledge or performance, but the mechanism for these metacognitive decisions is still debated. Much of the work on animal metacognitive abilities has been to rule out alternative, non-introspective mechanisms such as associative learning, behavioral cue association, or environmental cue association. However, the human metacognition literature has shown that even humans often do not use true introspection or directly access their own memory to make metacognitive judgments–they sometimes use heuristic strategies based on perceptual salience. Often these heuristic strategies are inaccurate and cause metacognitive errors. Here we offer a new route to testing animal metacognitive abilities by comparing the fragility of human and animal metacognition. We show that monkeys’ confidence judgments, like those of humans, are at least partly based on salient perceptual features of the stimuli and susceptible to faulty heuristics.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/G7YPI4VI/Ferrigno et al. - A Similar Basis for Judging Confidence in Monkeys .pdf;/Users/alexten/Zotero/storage/K8UHMKQW/Ferrigno et al. - 2019 - A similar basis for judging confidence in monkeys .pdf}
}

@article{fiedlerInformationEcologyExplanation,
  title = {Information {{Ecology}} and the {{Explanation}} of {{Social Cognition}} and {{Behavior}}},
  author = {Fiedler, Klaus},
  pages = {25},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/M6NAXEI5/Fiedler - Information Ecology and the Explanation of Social .pdf}
}

@article{finchIncrementalCalculationWeighted,
  title = {Incremental Calculation of Weighted Mean and Variance},
  author = {Finch, Tony},
  pages = {8},
  abstract = {In these notes I explain how to derive formulae for numerically stable calculation of the mean and standard deviation, which are also suitable for incremental on-line calculation. I then generalize these formulae to weighted means and standard deviations. I unpick the difficulties that arise when generalizing further to normalized weights. Finally I show that the exponentially weighted moving average is a special case of the incremental normalized weighted mean formula, and derive a formula for the exponentially weighted moving standard deviation.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NVF3WNQ8/Finch - Incremental calculation of weighted mean and varia.pdf}
}

@article{finnOverconfidenceChildrenMultitrial2014,
  title = {Overconfidence in Children's Multi-Trial Judgments of Learning},
  author = {Finn, Bridgid and Metcalfe, Janet},
  date = {2014-08},
  journaltitle = {Learning and Instruction},
  shortjournal = {Learning and Instruction},
  volume = {32},
  pages = {1--9},
  issn = {09594752},
  doi = {10.1016/j.learninstruc.2014.01.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959475214000036},
  urldate = {2021-01-22},
  abstract = {The underconfidence with practice effect (UWP) refers to the finding that people’s judgments of learning shift from overconfidence to underconfidence on and after a first study-test trial (Koriat, Ma’ayan, \& Sheffer, 2002). Finn and Metcalfe (2007, 2008) proposed that people show UWP because they use their memory of prior test performance as a cue to make subsequent judgments of learning and inadequately account for new learning (i.e. the Memory for Past Test (MPT) heuristic). In contrast to adults, 3rd and 5th graders’ judgments showed persistent overconfidence on and after a first study-test trial. A second experiment tested children’s ability to remember their prior test performance. Children’s prior performance discriminations were accurate for items that they answered correctly on the prior trial, but were overconfident for items they had answered incorrectly indicating that their continued overconfidence was a result of faulty memory, rather than a failure to use the MPT heuristic.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BYVL2R86/Finn and Metcalfe - 2014 - Overconfidence in children's multi-trial judgments.pdf}
}

@article{finnOverconfidenceChildrenMultitrial2014a,
  title = {Overconfidence in Children's Multi-Trial Judgments of Learning},
  author = {Finn, Bridgid},
  date = {2014},
  journaltitle = {Learning and Instruction},
  pages = {9},
  abstract = {The underconfidence with practice effect (UWP) refers to the finding that people’s judgments of learning shift from overconfidence to underconfidence on and after a first study-test trial (Koriat, Ma’ayan, \& Sheffer, 2002). Finn and Metcalfe (2007, 2008) proposed that people show UWP because they use their memory of prior test performance as a cue to make subsequent judgments of learning and inadequately account for new learning (i.e. the Memory for Past Test (MPT) heuristic). In contrast to adults, 3rd and 5th graders’ judgments showed persistent overconfidence on and after a first study-test trial. A second experiment tested children’s ability to remember their prior test performance. Children’s prior performance discriminations were accurate for items that they answered correctly on the prior trial, but were overconfident for items they had answered incorrectly indicating that their continued overconfidence was a result of faulty memory, rather than a failure to use the MPT heuristic.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BP4WWZZA/Finn - 2014 - Overconfidence in children's multi-trial judgments.pdf}
}

@article{firestoneCognitionDoesNot,
  title = {Cognition Does Not Affect Perception: {{Evaluating}} the Evidence for “Top-down” Effects},
  author = {Firestone, Chaz and Scholl, Brian J},
  pages = {77},
  abstract = {What determines what we see? In contrast to the traditional “modular” understanding of perception, according to which visual processing is encapsulated from higher-level cognition, a tidal wave of recent research alleges that states such as beliefs, desires, emotions, motivations, intentions, and linguistic representations exert direct, top-down influences on what we see. There is a growing consensus that such effects are ubiquitous, and that the distinction between perception and cognition may itself be unsustainable. We argue otherwise: None of these hundreds of studies – either individually or collectively – provides compelling evidence for true top-down effects on perception, or “cognitive penetrability.” In particular, and despite their variety, we suggest that these studies all fall prey to only a handful of pitfalls. And whereas abstract theoretical challenges have failed to resolve this debate in the past, our presentation of these pitfalls is empirically anchored: In each case, we show not only how certain studies could be susceptible to the pitfall (in principle), but also how several alleged top-down effects actually are explained by the pitfall (in practice). Moreover, these pitfalls are perfectly general, with each applying to dozens of other top-down effects. We conclude by extracting the lessons provided by these pitfalls into a checklist that future work could use to convincingly demonstrate top-down effects on visual perception. The discovery of substantive top-down effects of cognition on perception would revolutionize our understanding of how the mind is organized; but without addressing these pitfalls, no such empirical report will license such exciting conclusions.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/E8VJM3YG/Firestone and Scholl - Cognition does not affect perception Evaluating t.pdf}
}

@article{fischhoffKnowingCertaintyAppropriateness,
  title = {Knowing with {{Certainty}}: {{The Appropriateness}} of {{Extreme Confidence}}},
  author = {Fischhoff, Baruch and Slovic, Paul and Lichtenstein, Sarah},
  pages = {13},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/254HBFZY/Fischhoff et al. - Knowing with Certainty The Appropriateness of Ext.pdf}
}

@article{fischhoffKnowingCertaintyAppropriatenessa,
  title = {Knowing with {{Certainty}}: {{The Appropriateness}} of {{Extreme Confidence}}},
  author = {Fischhoff, Baruch and Slovic, Paul and Lichtenstein, Sarah},
  pages = {13},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/I862ETGT/Fischhoff et al. - Knowing with Certainty The Appropriateness of Ext.pdf}
}

@article{flagelNeurobiologicalBasisIndividual2017,
  title = {Neurobiological Basis of Individual Variation in Stimulus-Reward Learning},
  author = {Flagel, Shelly B and Robinson, Terry E},
  date = {2017},
  journaltitle = {Current Opinion in Behavioral Sciences},
  pages = {8},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9ITCTNRG/Flagel and Robinson - 2017 - Neurobiological basis of individual variation in s.pdf}
}

@article{flagelNeurobiologicalBasisIndividual2017a,
  title = {Neurobiological Basis of Individual Variation in Stimulus-Reward Learning},
  author = {Flagel, Shelly B and Robinson, Terry E},
  date = {2017-02},
  journaltitle = {Current Opinion in Behavioral Sciences},
  shortjournal = {Current Opinion in Behavioral Sciences},
  volume = {13},
  pages = {178--185},
  issn = {23521546},
  doi = {10.1016/j.cobeha.2016.12.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2352154616302662},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/39RWFVN7/Flagel and Robinson - 2017 - Neurobiological basis of individual variation in s.pdf}
}

@article{flanaganPredictionPrecedesControl2003,
  title = {Prediction {{Precedes Control}} in {{Motor Learning}}},
  author = {Flanagan, J.Randall and Vetter, Philipp and Johansson, Roland S and Wolpert, Daniel M},
  date = {2003-01},
  journaltitle = {Current Biology},
  shortjournal = {Current Biology},
  volume = {13},
  number = {2},
  pages = {146--150},
  issn = {09609822},
  doi = {10.1016/S0960-9822(03)00007-1},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982203000071},
  urldate = {2021-01-22},
  abstract = {Skilled motor behavior relies on the brain learning both to control the body and predict the consequences of this control. Prediction turns motor commands into expected sensory consequences [1], whereas control turns desired consequences into motor commands. To capture this symmetry, the neural processes underlying prediction and control are termed the forward and inverse internal models, respectively [2–5]. Here, we investigate how these two fundamental processes are related during motor learning. We used an object manipulation task in which subjects learned to move a hand-held object with novel dynamic properties along a prescribed path. We independently and simultaneously measured subjects’ ability to control their actions and to predict their consequences. We found different time courses for predictor and controller learning, with prediction being learned far more rapidly than control. In early stages of manipulating the object, subjects could predict the consequences of their actions, as measured by the grip force they used to grasp the object, but could not generate appropriate actions for control, as measured by their hand trajectory. As predicted by several recent theoretical models of sensorimotor control [6–8], our results indicate that people can learn to predict the consequences of their actions before they can learn to control their actions.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/S3P5KTLT/Flanagan et al. - 2003 - Prediction Precedes Control in Motor Learning.pdf}
}

@article{flemingHowMeasureMetacognition2014,
  title = {How to Measure Metacognition},
  author = {Fleming, Stephen M. and Lau, Hakwan C.},
  date = {2014-07-15},
  journaltitle = {Frontiers in Human Neuroscience},
  shortjournal = {Front. Hum. Neurosci.},
  volume = {8},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2014.00443},
  url = {http://journal.frontiersin.org/article/10.3389/fnhum.2014.00443/abstract},
  urldate = {2021-01-22},
  abstract = {The ability to recognize one’s own successful cognitive processing, in e.g., perceptual or memory tasks, is often referred to as metacognition. How should we quantitatively measure such ability? Here we focus on a class of measures that assess the correspondence between trial-by-trial accuracy and one’s own confidence. In general, for healthy subjects endowed with metacognitive sensitivity, when one is confident, one is more likely to be correct. Thus, the degree of association between accuracy and confidence can be taken as a quantitative measure of metacognition. However, many studies use a statistical correlation coefficient (e.g., Pearson’s r) or its variant to assess this degree of association, and such measures are susceptible to undesirable influences from factors such as response biases. Here we review other measures based on signal detection theory and receiver operating characteristics (ROC) analysis that are “bias free,” and relate these quantities to the calibration and discrimination measures developed in the probability estimation literature. We go on to distinguish between the related concepts of metacognitive bias (a difference in subjective confidence despite basic task performance remaining constant), metacognitive sensitivity (how good one is at distinguishing between one’s own correct and incorrect judgments) and metacognitive efficiency (a subject’s level of metacognitive sensitivity given a certain level of task performance). Finally, we discuss how these three concepts pose interesting questions for the study of metacognition and conscious awareness.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7P5CK9ZE/Fleming and Lau - 2014 - How to measure metacognition.pdf}
}

@article{flemingIrrationalityCategoricalPerception,
  title = {The {{Irrationality}} of {{Categorical Perception}}},
  author = {Fleming, Stephen M and Maloney, Laurence T and Daw, Nathaniel D},
  pages = {11},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Z9ZLNC4C/Fleming et al. - The Irrationality of Categorical Perception.pdf}
}

@article{flemingIrrationalityCategoricalPerception2013,
  title = {The {{Irrationality}} of {{Categorical Perception}}},
  author = {Fleming, S. M. and Maloney, L. T. and Daw, N. D.},
  date = {2013-12-04},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {Journal of Neuroscience},
  volume = {33},
  number = {49},
  pages = {19060--19070},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1263-13.2013},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1263-13.2013},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9I57BPNK/Fleming et al. - 2013 - The Irrationality of Categorical Perception.pdf}
}

@article{flemingMetacognitionComputationBiology2012,
  title = {Metacognition: Computation, Biology and Function},
  shorttitle = {Metacognition},
  author = {Fleming, Stephen M. and Dolan, Raymond J. and Frith, Christopher D.},
  date = {2012-05-19},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  shortjournal = {Phil. Trans. R. Soc. B},
  volume = {367},
  number = {1594},
  pages = {1280--1286},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2012.0021},
  url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2012.0021},
  urldate = {2021-01-22},
  abstract = {Many complex systems maintain a self-referential check and balance. In animals, such reflective monitoring and control processes have been grouped under the rubric of metacognition. In this introductory article to a Theme Issue on metacognition, we review recent and rapidly progressing developments from neuroscience, cognitive psychology, computer science and philosophy of mind. While each of these areas is represented in detail by individual contributions to the volume, we take this opportunity to draw links between disciplines, and highlight areas where further integration is needed. Specifically, we cover the definition, measurement, neurobiology and possible functions of metacognition, and assess the relationship between metacognition and consciousness. We propose a framework in which level of representation, order of behaviour and access consciousness are orthogonal dimensions of the conceptual landscape.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UUHG6TLM/Fleming et al. - 2012 - Metacognition computation, biology and function.pdf}
}

@article{flemingMetacognitionComputationBiology2012a,
  title = {Metacognition: Computation, Biology and Function},
  author = {Fleming, Stephen M and Dolan, Raymond J and Frith, Christopher D},
  date = {2012},
  pages = {7},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6YSHSVMI/Fleming et al. - 2012 - Metacognition computation, biology and function.pdf}
}

@article{flemingNeuralBasisMetacognitive,
  title = {The Neural Basis of Metacognitive Ability},
  author = {Fleming, Stephen M and Dolan, Raymond J},
  pages = {14},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5ZYT7MY7/Fleming and Dolan - The neural basis of metacognitive ability.pdf}
}

@article{flemingNeuralBasisMetacognitive2012,
  title = {The Neural Basis of Metacognitive Ability},
  author = {Fleming, Stephen M. and Dolan, Raymond J.},
  date = {2012-05-19},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  shortjournal = {Phil. Trans. R. Soc. B},
  volume = {367},
  number = {1594},
  pages = {1338--1349},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2011.0417},
  url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2011.0417},
  urldate = {2021-01-22},
  abstract = {Ability in various cognitive domains is often assessed by measuring task performance, such as the accuracy of a perceptual categorization. A similar analysis can be applied to metacognitive reports about a task to quantify the degree to which an individual is aware of his or her success or failure. Here, we review the psychological and neural underpinnings of metacognitive accuracy, drawing on research in memory and decision-making. These data show that metacognitive accuracy is dissociable from task performance and varies across individuals. Convergent evidence indicates that the function of the rostral and dorsal aspect of the lateral prefrontal cortex (PFC) is important for the accuracy of retrospective judgements of performance. In contrast, prospective judgements of performance may depend upon medial PFC. We close with a discussion of how metacognitive processes relate to concepts of cognitive control, and propose a neural synthesis in which dorsolateral and anterior prefrontal cortical subregions interact with interoceptive cortices (cingulate and insula) to promote accurate judgements of performance.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/HS5L48KY/Fleming and Dolan - 2012 - The neural basis of metacognitive ability.pdf}
}

@article{flemingSelfEvaluationDecisionMakingGeneral,
  title = {Self-{{Evaluation}} of {{Decision}}-{{Making}}: {{A General Bayesian Framework}} for {{Metacognitive Computation}}},
  author = {Fleming, Stephen M and Daw, Nathaniel D},
  pages = {24},
  abstract = {People are often aware of their mistakes, and report levels of confidence in their choices that correlate with objective performance. These metacognitive assessments of decision quality are important for the guidance of behavior, particularly when external feedback is absent or sporadic. However, a computational framework that accounts for both confidence and error detection is lacking. In addition, accounts of dissociations between performance and metacognition have often relied on ad hoc assumptions, precluding a unified account of intact and impaired self-evaluation. Here we present a general Bayesian framework in which self-evaluation is cast as a “second-order” inference on a coupled but distinct decision system, computationally equivalent to inferring the performance of another actor. Second-order computation may ensue whenever there is a separation between internal states supporting decisions and confidence estimates over space and/or time. We contrast second-order computation against simpler first-order models in which the same internal state supports both decisions and confidence estimates. Through simulations we show that second-order computation provides a unified account of different types of self-evaluation often considered in separate literatures, such as confidence and error detection, and generates novel predictions about the contribution of one’s own actions to metacognitive judgments. In addition, the model provides insight into why subjects’ metacognition may sometimes be better or worse than task performance. We suggest that second-order computation may underpin self-evaluative judgments across a range of domains.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MJS5YSQE/Fleming and Daw - Self-Evaluation of Decision-Making A General Baye.pdf}
}

@article{flemingSelfevaluationDecisionmakingGeneral2017,
  title = {Self-Evaluation of Decision-Making: {{A}} General {{Bayesian}} Framework for Metacognitive Computation.},
  shorttitle = {Self-Evaluation of Decision-Making},
  author = {Fleming, Stephen M. and Daw, Nathaniel D.},
  date = {2017-01},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {124},
  number = {1},
  pages = {91--114},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/rev0000045},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/rev0000045},
  urldate = {2021-01-22},
  abstract = {People are often aware of their mistakes, and report levels of confidence in their choices that correlate with objective performance. These metacognitive assessments of decision quality are important for the guidance of behavior, particularly when external feedback is absent or sporadic. However, a computational framework that accounts for both confidence and error detection is lacking. In addition, accounts of dissociations between performance and metacognition have often relied on ad hoc assumptions, precluding a unified account of intact and impaired self-evaluation. Here we present a general Bayesian framework in which self-evaluation is cast as a “second-order” inference on a coupled but distinct decision system, computationally equivalent to inferring the performance of another actor. Second-order computation may ensue whenever there is a separation between internal states supporting decisions and confidence estimates over space and/or time. We contrast second-order computation against simpler first-order models in which the same internal state supports both decisions and confidence estimates. Through simulations we show that second-order computation provides a unified account of different types of self-evaluation often considered in separate literatures, such as confidence and error detection, and generates novel predictions about the contribution of one’s own actions to metacognitive judgments. In addition, the model provides insight into why subjects’ metacognition may sometimes be better or worse than task performance. We suggest that second-order computation may underpin self-evaluative judgments across a range of domains.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6YXHQ7M7/Fleming and Daw - 2017 - Self-evaluation of decision-making A general Baye.pdf}
}

@article{fristonActiveInferenceCuriosity2017,
  title = {Active {{Inference}}, {{Curiosity}} and {{Insight}}},
  author = {Friston, Karl J. and Lin, Marco and Frith, Christopher D. and Pezzulo, Giovanni and Hobson, J. Allan and Ondobaka, Sasha},
  date = {2017-10},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {29},
  number = {10},
  pages = {2633--2683},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco_a_00999},
  url = {https://www.mitpressjournals.org/doi/abs/10.1162/neco_a_00999},
  urldate = {2021-01-22},
  abstract = {This article offers a formal account of curiosity and insight in terms of active (Bayesian) inference. It deals with the dual problem of inferring states of the world and learning its statistical structure. In contrast to current trends in machine learning (e.g., deep learning), we focus on how people attain insight and understanding using just a handful of observations, which are solicited through curious behavior. We use simulations of abstract rule learning and approximate Bayesian inference to show that minimizing (expected) variational free energy leads to active sampling of novel contingencies. This epistemic behavior closes explanatory gaps in generative models of the world, thereby reducing uncertainty and satisfying curiosity. We then move from epistemic learning to model selection or structure learning to show how abductive processes emerge when agents test plausible hypotheses about symmetries (i.e., invariances or rules) in their generative models. The ensuing Bayesian model reduction evinces mechanisms associated with sleep and has all the hallmarks of “aha” moments. This formulation moves toward a computational account of consciousness in the pre-Cartesian sense of sharable knowledge (i.e., con: “together”; scire: “to know”).},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5WFCIRAE/Friston et al. - 2017 - Active Inference, Curiosity and Insight.pdf;/Users/alexten/Zotero/storage/HSCKRTIM/Friston et al. - 2017 - Active Inference, Curiosity and Insight.pdf}
}

@article{fristonActiveInferenceLearning2016,
  title = {Active Inference and Learning},
  author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and O⿿Doherty, John and Pezzulo, Giovanni},
  date = {2016-09},
  journaltitle = {Neuroscience \& Biobehavioral Reviews},
  shortjournal = {Neuroscience \& Biobehavioral Reviews},
  volume = {68},
  pages = {862--879},
  issn = {01497634},
  doi = {10.1016/j.neubiorev.2016.06.022},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0149763416301336},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CTSF3NG5/Friston - 2016 - Active inference and learning.pdf;/Users/alexten/Zotero/storage/RPYFWGMR/Friston et al. - 2016 - Active inference and learning.pdf}
}

@article{fristonFreeEnergyPrinciple2006,
  title = {A Free Energy Principle for the Brain},
  author = {Friston, Karl and Kilner, James and Harrison, Lee},
  date = {2006},
  journaltitle = {Journal of Physiology},
  pages = {18},
  abstract = {By formulating Helmholtz’s ideas about perception, in terms of modern-day theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts: using constructs from statistical physics, the problems of inferring the causes of sensory input and learning the causal structure of their generation can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organisation and responses.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3SEEK28D/Friston et al. - 2006 - A free energy principle for the brain.pdf;/Users/alexten/Zotero/storage/GPHNSASN/Friston et al. - 2006 - A free energy principle for the brain.pdf}
}

@article{gaglianoLearningAssociationPlants,
  title = {Learning by {{Association}} in {{Plants}}},
  author = {Gagliano, Monica},
  journaltitle = {Scientific Reports},
  pages = {9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6LMJQUGH/Gagliano - Learning by Association in Plants.pdf}
}

@article{gaglianoLearningAssociationPlants2016,
  title = {Learning by {{Association}} in {{Plants}}},
  author = {Gagliano, Monica and Vyazovskiy, Vladyslav V. and Borbély, Alexander A. and Grimonprez, Mavra and Depczynski, Martial},
  date = {2016-12},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {6},
  number = {1},
  pages = {38427},
  issn = {2045-2322},
  doi = {10.1038/srep38427},
  url = {http://www.nature.com/articles/srep38427},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7ZJX6S6L/Gagliano et al. - 2016 - Learning by Association in Plants.pdf}
}

@article{gauthierBecomingGreebleExpert1997,
  title = {Becoming a “{{Greeble}}” {{Expert}}: {{Exploring Mechanisms}} for {{Face Recognition}}},
  shorttitle = {Becoming a “{{Greeble}}” {{Expert}}},
  author = {Gauthier, Isabel and Tarr, Michael J.},
  date = {1997-06},
  journaltitle = {Vision Research},
  shortjournal = {Vision Research},
  volume = {37},
  number = {12},
  pages = {1673--1682},
  issn = {00426989},
  doi = {10.1016/S0042-6989(96)00286-6},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0042698996002866},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FEUW4KHS/Gauthier and Tarr - Becoming a “Greeble” Expert Exploring Mechanisms .pdf;/Users/alexten/Zotero/storage/LNAFECDU/Gauthier and Tarr - 1997 - Becoming a “Greeble” Expert Exploring Mechanisms .pdf}
}

@article{geanaBoredomInformationSeekingExploration,
  title = {Boredom, {{Information}}-{{Seeking}} and {{Exploration}}},
  author = {Geana, Andra and Daw, Nathaniel},
  pages = {6},
  abstract = {Any adaptive organism faces the choice between taking actions with known benefits (exploitation), and sampling new actions to check for other, more valuable opportunities available (exploration). The latter involves informationseeking, a drive so fundamental to learning and long-term reward that it can reasonably be considered, through evolution or development, to have acquired its own value, independent of immediate reward. Similarly, behaviors that fail to yield information may have come to be associated with aversive experiences such as boredom, demotivation, and task disengagement. In accord with these suppositions, we propose that boredom reflects an adaptive signal for managing the exploration-exploitation tradeoff, in the service of optimizing information acquisition and long-term reward. We tested participants in three experiments, manipulating the information content in their immediate task environment, and showed that increased perceptions of boredom arise in environments in which there is little useful information, and that higher boredom correlates with higher exploration. These findings are the first step toward a model formalizing the relationship between exploration, exploitation and boredom.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DDYXEU4D/Geana and Daw - Boredom, Information-Seeking and Exploration.pdf}
}

@article{gelmanAnalysisVarianceWhy2005,
  title = {Analysis of Variance—Why It Is More Important than Ever},
  author = {Gelman, Andrew},
  date = {2005-02},
  journaltitle = {The Annals of Statistics},
  shortjournal = {Ann. Statist.},
  volume = {33},
  number = {1},
  pages = {1--53},
  issn = {0090-5364},
  doi = {10.1214/009053604000001048},
  url = {https://projecteuclid.org/euclid.aos/1112967698},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PTX3SA26/Gelman - 2005 - Analysis of variance—why it is more important than.pdf}
}

@article{gelmanDifferenceSignificantNot2006,
  title = {The {{Difference Between}} “{{Significant}}” and “{{Not Significant}}” Is Not {{Itself Statistically Significant}}},
  author = {Gelman, Andrew and Stern, Hal},
  date = {2006-11},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {60},
  number = {4},
  pages = {328--331},
  issn = {0003-1305, 1537-2731},
  doi = {10.1198/000313006X152649},
  url = {http://www.tandfonline.com/doi/abs/10.1198/000313006X152649},
  urldate = {2021-05-23},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/N9AF2TBE/Gelman and Stern - 2006 - The Difference Between “Significant” and “Not Sign.pdf}
}

@article{gelmanMultilevelHierarchicalModeling2006,
  title = {Multilevel ({{Hierarchical}}) {{Modeling}}: {{What It Can}} and {{Cannot Do}}},
  author = {Gelman, Andrew},
  date = {2006},
  volume = {48},
  number = {3},
  pages = {4},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SQYPV2A5/Gelman - 2006 - Multilevel (Hierarchical) Modeling What It Can an.pdf}
}

@article{gelmanMultilevelHierarchicalModeling2006a,
  title = {Multilevel ({{Hierarchical}}) {{Modeling}}: {{What It Can}} and {{Cannot Do}}},
  author = {Gelman, Andrew},
  date = {2006},
  volume = {48},
  number = {3},
  pages = {4},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QMD6EH54/Gelman - 2006 - Multilevel (Hierarchical) Modeling What It Can an.pdf}
}

@article{gershmanDeconstructingHumanAlgorithms2018,
  title = {Deconstructing the Human Algorithms for Exploration},
  author = {Gershman, Samuel J},
  date = {2018},
  pages = {9},
  abstract = {The dilemma between information gathering (exploration) and reward seeking (exploitation) is a fundamental problem for reinforcement learning agents. How humans resolve this dilemma is still an open question, because experiments have provided equivocal evidence about the underlying algorithms used by humans. We show that two families of algorithms can be distinguished in terms of how uncertainty affects exploration. Algorithms based on uncertainty bonuses predict a change in response bias as a function of uncertainty, whereas algorithms based on sampling predict a change in response slope. Two experiments provide evidence for both bias and slope changes, and computational modeling confirms that a hybrid model is the best quantitative account of the data.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/44YGZWCF/Gershman - 2018 - Deconstructing the human algorithms for exploratio.pdf}
}

@article{gershmanHowNeverBe,
  title = {How to Never Be Wrong},
  author = {Gershman, Samuel J},
  journaltitle = {Psychon Bull Rev},
  pages = {16},
  abstract = {Human beliefs have remarkable robustness in the face of disconfirmation. This robustness is often explained as the product of heuristics or motivated reasoning. However, robustness can also arise from purely rational principles when the reasoner has recourse to ad hoc auxiliary hypotheses. Auxiliary hypotheses primarily function as the linking assumptions connecting different beliefs to one another and to observational data, but they can also function as a “protective belt” that explains away disconfirmation by absorbing some of the blame. The present article traces the role of auxiliary hypotheses from philosophy of science to Bayesian models of cognition and a host of behavioral phenomena, demonstrating their wide-ranging implications.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GK8HCTXF/Gershman - How to never be wrong.pdf;/Users/alexten/Zotero/storage/XJISCL4R/Gershman - How to never be wrong.pdf}
}

@article{gershmanLearningLatentStructure2010,
  title = {Learning Latent Structure: Carving Nature at Its Joints},
  shorttitle = {Learning Latent Structure},
  author = {Gershman, Samuel J and Niv, Yael},
  date = {2010-04},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  volume = {20},
  number = {2},
  pages = {251--256},
  issn = {09594388},
  doi = {10.1016/j.conb.2010.02.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438810000309},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6CFUP4Y8/Gershman and Niv - 2010 - Learning latent structure carving nature at its j.pdf}
}

@article{gershmanLearningLatentStructure2010a,
  title = {Learning Latent Structure: Carving Nature at Its Joints},
  author = {Gershman, Samuel J and Niv, Yael},
  date = {2010},
  journaltitle = {Current Opinion in Neurobiology},
  pages = {6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8D9ABPSS/Gershman and Niv - 2010 - Learning latent structure carving nature at its j.pdf}
}

@article{gershmanTutorialBayesianNonparametric2012,
  title = {A Tutorial on {{Bayesian}} Nonparametric Models},
  author = {Gershman, Samuel J. and Blei, David M.},
  date = {2012-02},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {56},
  number = {1},
  pages = {1--12},
  issn = {00222496},
  doi = {10.1016/j.jmp.2011.08.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S002224961100071X},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4TBTXFBN/Gershman and Blei - 2012 - A tutorial on Bayesian nonparametric models.pdf;/Users/alexten/Zotero/storage/REWE954M/Gershman and Blei - 2012 - A tutorial on Bayesian nonparametric models.pdf}
}

@article{gershmanUncertaintyExploration2018,
  title = {Uncertainty and {{Exploration}}},
  author = {Gershman, Samuel J.},
  date = {2018-02-14},
  doi = {10.1101/265504},
  url = {http://biorxiv.org/lookup/doi/10.1101/265504},
  urldate = {2021-01-22},
  abstract = {In order to discover the most rewarding actions, agents must collect information about their environment, potentially foregoing reward. The optimal solution to this “exploreexploit” dilemma is computationally intractable, but principled algorithmic approximations exist. These approximations utilize uncertainty about action values in different ways. Some random exploration algorithms scale the level of choice stochasticity with the level of uncertainty. Other directed exploration algorithms add a “bonus” to action values with high uncertainty. Random exploration algorithms are sensitive to total uncertainty across actions, whereas directed exploration algorithms are sensitive to relative uncertainty. This paper reports a multi-armed bandit experiment in which total and relative uncertainty were orthogonally manipulated. We found that humans employ both exploration strategies, and that these strategies are independently controlled by different uncertainty computations.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4E5GUQUY/Gershman - Uncertainty and exploration.pdf;/Users/alexten/Zotero/storage/5PDK7MKT/Gershman - 2018 - Uncertainty and Exploration.pdf}
}

@online{ghavamzadehBayesianReinforcementLearning2016,
  title = {Bayesian {{Reinforcement Learning}}: {{A Survey}}},
  shorttitle = {Bayesian {{Reinforcement Learning}}},
  author = {Ghavamzadeh, Mohammad and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
  date = {2016-09-14},
  eprint = {1609.04436},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  doi = {10.1561/2200000049},
  url = {http://arxiv.org/abs/1609.04436},
  urldate = {2021-01-22},
  abstract = {Bayesian methods for machine learning have been widely investigated, yielding principled methods for incorporating prior information into inference algorithms. In this survey, we provide an in-depth review of the role of Bayesian methods for the reinforcement learning (RL) paradigm. The major incentives for incorporating Bayesian reasoning in RL are: 1) it provides an elegant approach to action-selection (exploration/exploitation) as a function of the uncertainty in learning; and 2) it provides a machinery to incorporate prior knowledge into the algorithms. We first discuss models and methods for Bayesian inference in the simple single-step Bandit model. We then review the extensive recent literature on Bayesian methods for model-based RL, where prior information can be expressed on the parameters of the Markov model. We also present Bayesian methods for model-free RL, where priors are expressed over the value function or policy class. The objective of the paper is to provide a comprehensive survey on Bayesian RL algorithms and their theoretical and empirical properties.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/7BSSH7JD/Ghavamzadeh et al. - 2016 - Bayesian Reinforcement Learning A Survey.pdf;/Users/alexten/Zotero/storage/UL8UIBWN/Ghavamzadeh et al. - 2015 - Bayesian Reinforcement Learning A Survey.pdf}
}

@article{gilzenratPupilDiameterTracks,
  title = {Pupil Diameter Tracks Changes in Control State Predicted by the Adaptive Gain Theory of Locus Coeruleus Function},
  author = {Gilzenrat, Mark S and Nieuwenhuis, Sander and Jepma, Marieke and Cohen, Jonathan D},
  pages = {19},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/77VZEGFD/Gilzenrat et al. - Pupil diameter tracks changes in control state pre.pdf}
}

@article{glascherStatesRewardsDissociable2010,
  title = {States versus {{Rewards}}: {{Dissociable Neural Prediction Error Signals Underlying Model}}-{{Based}} and {{Model}}-{{Free Reinforcement Learning}}},
  shorttitle = {States versus {{Rewards}}},
  author = {Gläscher, Jan and Daw, Nathaniel and Dayan, Peter and O'Doherty, John P.},
  date = {2010-05},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {66},
  number = {4},
  pages = {585--595},
  issn = {08966273},
  doi = {10.1016/j.neuron.2010.04.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627310002874},
  urldate = {2021-01-22},
  abstract = {Reinforcement learning (RL) uses sequential experience with situations (‘‘states’’) and outcomes to assess actions. Whereas model-free RL uses this experience directly, in the form of a reward prediction error (RPE), model-based RL uses it indirectly, building a model of the state transition and outcome structure of the environment, and evaluating actions by searching this model. A state prediction error (SPE) plays a central role, reporting discrepancies between the current model and the observed state transitions. Using functional magnetic resonance imaging in humans solving a probabilistic Markov decision task, we found the neural signature of an SPE in the intraparietal sulcus and lateral prefrontal cortex, in addition to the previously well-characterized RPE in the ventral striatum. This finding supports the existence of two unique forms of learning signal in humans, which may form the basis of distinct computational strategies for guiding behavior.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/43SVCRKU/Gläscher et al. - 2010 - States versus Rewards Dissociable Neural Predicti.pdf}
}

@article{gligaMetacognitionPreverbalInfants,
  title = {Metacognition: {{Pre}}-Verbal {{Infants Adapt Their Behaviour}} to {{Their Knowledge States}}},
  author = {Gliga, Teodora},
  journaltitle = {Current Biology},
  pages = {4},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QTKDC9TT/Gliga - Metacognition Pre-verbal Infants Adapt Their Beha.pdf}
}

@article{gligaMetacognitionPreverbalInfantsa,
  title = {Metacognition: {{Pre}}-Verbal {{Infants Adapt Their Behaviour}} to {{Their Knowledge States}}},
  author = {Gliga, Teodora},
  journaltitle = {Current Biology},
  pages = {4},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PG6UGFQ3/Gliga - Metacognition Pre-verbal Infants Adapt Their Beha.pdf}
}

@article{goldPredictabilityUncertaintyPleasure2019,
  title = {Predictability and {{Uncertainty}} in the {{Pleasure}} of {{Music}}: {{A Reward}} for {{Learning}}?},
  shorttitle = {Predictability and {{Uncertainty}} in the {{Pleasure}} of {{Music}}},
  author = {Gold, Benjamin P. and Pearce, Marcus T. and Mas-Herrero, Ernest and Dagher, Alain and Zatorre, Robert J.},
  date = {2019-11-20},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {39},
  number = {47},
  pages = {9397--9409},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0428-19.2019},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.0428-19.2019},
  urldate = {2021-07-16},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KPFUBGFJ/Gold et al. - 2019 - Predictability and Uncertainty in the Pleasure of .pdf}
}

@article{golmanInformationGapsTheory2018,
  title = {Information Gaps: {{A}} Theory of Preferences Regarding the Presence and Absence of Information.},
  shorttitle = {Information Gaps},
  author = {Golman, Russell and Loewenstein, George},
  date = {2018-07},
  journaltitle = {Decision},
  shortjournal = {Decision},
  volume = {5},
  number = {3},
  pages = {143--164},
  issn = {2325-9973, 2325-9965},
  doi = {10.1037/dec0000068},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/dec0000068},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WGK5AU6Q/Golman and Loewenstein - 2018 - Information gaps A theory of preferences regardin.pdf}
}

@article{goodmanDirtyDozenTwelve2008,
  title = {A {{Dirty Dozen}}: {{Twelve P}}-{{Value Misconceptions}}},
  shorttitle = {A {{Dirty Dozen}}},
  author = {Goodman, Steven},
  date = {2008-07},
  journaltitle = {Seminars in Hematology},
  shortjournal = {Seminars in Hematology},
  volume = {45},
  number = {3},
  pages = {135--140},
  issn = {00371963},
  doi = {10.1053/j.seminhematol.2008.04.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0037196308000620},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2J6LAUUA/Goodman - 2008 - A Dirty Dozen Twelve P-Value Misconceptions.pdf}
}

@article{goodwinAcquisitionBooleanConcepts,
  title = {The Acquisition of {{Boolean}} Concepts},
  author = {Goodwin, Geoffrey P and Johnson-Laird, Philip N},
  pages = {6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9V8EZ4J7/Goodwin and Johnson-Laird - The acquisition of Boolean concepts.pdf}
}

@article{goodwinAcquisitionBooleanConceptsa,
  title = {The Acquisition of {{Boolean}} Concepts},
  author = {Goodwin, Geoffrey P and Johnson-Laird, Philip N},
  pages = {6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GKVPWB69/Goodwin and Johnson-Laird - The acquisition of Boolean concepts.pdf}
}

@book{gopnikCausalLearning2007,
  title = {Causal {{Learning}}},
  author = {Gopnik, Alison and Schulz, Laura},
  date = {2007-04-26},
  publisher = {{Oxford University Press}},
  doi = {10.1093/acprof:oso/9780195176803.001.0001},
  url = {http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780195176803.001.0001/acprof-9780195176803},
  urldate = {2021-01-22},
  isbn = {978-0-19-517680-3},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6TVQGP25/Gopnik and Schulz - 2007 - Causal Learning.pdf}
}

@article{gottliebInformationseekingCuriosityAttention2013,
  title = {Information-Seeking, Curiosity, and Attention: Computational and Neural Mechanisms},
  shorttitle = {Information-Seeking, Curiosity, and Attention},
  author = {Gottlieb, Jacqueline and Oudeyer, Pierre-Yves and Lopes, Manuel and Baranes, Adrien},
  date = {2013-11},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {17},
  number = {11},
  pages = {585--593},
  issn = {13646613},
  doi = {10.1016/j.tics.2013.09.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661313002052},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/M7SXI4T6/Gottlieb et al. - 2013 - Information-seeking, curiosity, and attention com.pdf}
}

@incollection{gottliebMotivatedCognitionNeural2016,
  title = {Motivated {{Cognition}}: {{Neural}} and {{Computational Mechanisms}} of {{Curiosity}}, {{Attention}}, and {{Intrinsic Motivation}}},
  shorttitle = {Motivated {{Cognition}}},
  booktitle = {Advances in {{Motivation}} and {{Achievement}}},
  author = {Gottlieb, Jacqueline and Lopes, Manuel and Oudeyer, Pierre-Yves},
  editor = {Kim, Sung-il and Reeve, Johnmarshall and Bong, Mimi},
  date = {2016-11-21},
  volume = {19},
  pages = {149--172},
  publisher = {{Emerald Group Publishing Limited}},
  doi = {10.1108/S0749-742320160000019017},
  url = {https://www.emerald.com/insight/content/doi/10.1108/S0749-742320160000019017/full/html},
  urldate = {2021-01-22},
  isbn = {978-1-78635-474-7 978-1-78635-473-0},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FXKD7SUB/Gottlieb et al. - 2016 - Motivated Cognition Neural and Computational Mech.pdf}
}

@article{gottliebNeuroscienceActiveSampling2018,
  title = {Towards a Neuroscience of Active Sampling and Curiosity},
  author = {Gottlieb, Jacqueline and Oudeyer, Pierre-Yves},
  date = {2018-12},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {19},
  number = {12},
  pages = {758--770},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/s41583-018-0078-0},
  url = {http://www.nature.com/articles/s41583-018-0078-0},
  urldate = {2021-01-22},
  abstract = {In natural behaviour, animals actively interrogate their environments using endogenously generated ‘question-and-answer’ strategies. However, in laboratory settings participants typically engage with externally imposed stimuli and tasks, and the mechanisms of active sampling remain poorly understood. We review a nascent neuroscientific literature that examines active-sampling policies and their relation to attention and curiosity. We distinguish between information sampling, in which organisms reduce uncertainty relevant to a familiar task, and information search, in which they investigate in an open-ended fashion to discover new tasks. We review evidence that both sampling and search depend on individual preferences over cognitive states, including attitudes towards uncertainty, learning progress and types of information. We propose that, although these preferences are non-instrumental and can on occasion interfere with external goals, they are important heuristics that allow organisms to cope with the high complexity of both sampling and search, and generate curiosity-driven investigations in large, open environments in which rewards are sparse and ex ante unknown.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/78YLQP9K/Gottlieb and Oudeyer - 2018 - Towards a neuroscience of active sampling and curi.pdf}
}

@article{gottliebUnderstandingActiveSampling2018,
  title = {Understanding Active Sampling Strategies: {{Empirical}} Approaches and Implications for Attention and Decision Research},
  shorttitle = {Understanding Active Sampling Strategies},
  author = {Gottlieb, Jacqueline},
  date = {2018-05},
  journaltitle = {Cortex},
  shortjournal = {Cortex},
  volume = {102},
  pages = {150--160},
  issn = {00109452},
  doi = {10.1016/j.cortex.2017.08.019},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010945217302769},
  urldate = {2021-01-22},
  abstract = {In natural behavior we actively gather information using attention and active sensing behaviors (such as shifts of gaze) to sample relevant cues. However, while attention and decision making are naturally coordinated, in the laboratory they have been dissociated. Attention is studied independently of the actions it serves. Conversely, decision theories make the simplifying assumption that the relevant information is given, and do not attempt to describe how the decision maker may learn and implement active sampling policies. In this paper I review recent studies that address questions of attentional learning, cue validity and information seeking in humans and non-human primates. These studies suggest that learning a sampling policy involves large scale interactions between networks of attention and valuation, which implement these policies based on reward maximization, uncertainty reduction and the intrinsic utility of cognitive states. I discuss the importance of using such paradigms for formalizing the role of attention, as well as devising more realistic theories of decision making that capture a broader range of empirical observations.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IZT2G945/Gottlieb - 2018 - Understanding active sampling strategies Empirica.pdf}
}

@article{gottliebUnderstandingActiveSampling2018a,
  title = {Understanding Active Sampling Strategies: {{Empirical}} Approaches and Implications for Attention and Decision Research},
  shorttitle = {Understanding Active Sampling Strategies},
  author = {Gottlieb, Jacqueline},
  date = {2018-05},
  journaltitle = {Cortex},
  shortjournal = {Cortex},
  volume = {102},
  pages = {150--160},
  issn = {00109452},
  doi = {10.1016/j.cortex.2017.08.019},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010945217302769},
  urldate = {2021-01-22},
  abstract = {In natural behavior we actively gather information using attention and active sensing behaviors (such as shifts of gaze) to sample relevant cues. However, while attention and decision making are naturally coordinated, in the laboratory they have been dissociated. Attention is studied independently of the actions it serves. Conversely, decision theories make the simplifying assumption that the relevant information is given, and do not attempt to describe how the decision maker may learn and implement active sampling policies. In this paper I review recent studies that address questions of attentional learning, cue validity and information seeking in humans and non-human primates. These studies suggest that learning a sampling policy involves large scale interactions between networks of attention and valuation, which implement these policies based on reward maximization, uncertainty reduction and the intrinsic utility of cognitive states. I discuss the importance of using such paradigms for formalizing the role of attention, as well as devising more realistic theories of decision making that capture a broader range of empirical observations.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MJQ4CRAU/Gottlieb - 2018 - Understanding active sampling strategies Empirica.pdf}
}

@article{goupilBehavioralNeuralIndices2016,
  title = {Behavioral and {{Neural Indices}} of {{Metacognitive Sensitivity}} in {{Preverbal Infants}}},
  author = {Goupil, Louise and Kouider, Sid},
  date = {2016-11},
  journaltitle = {Current Biology},
  shortjournal = {Current Biology},
  volume = {26},
  number = {22},
  pages = {3038--3045},
  issn = {09609822},
  doi = {10.1016/j.cub.2016.09.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982216310533},
  urldate = {2021-01-22},
  abstract = {Humans adapt their behavior not only by observing the consequences of their actions but also by internally monitoring their performance. This capacity, termed metacognitive sensitivity [1, 2], has traditionally been denied to young children because they have poor capacities in verbally reporting their own mental states [3–5]. Yet, these observations might reflect children’s limited capacities for explicit self-reports, rather than limitations in metacognition per se. Indeed, metacognitive sensitivity has been shown to reflect simple computational mechanisms [1, 6–8], and can be found in various non-verbal species [7–10]. Thus, it might be that this faculty is present early in development, although it would be discernible through implicit behaviors and neural indices rather than explicit self-reports. Here, by relying on such non-verbal indices, we show that 12- and 18-monthold infants internally monitor the accuracy of their own decisions. At the behavioral level, infants showed increased persistence in their initial choice after making a correct as compared to an incorrect response, evidencing an appropriate evaluation of decision confidence. Moreover, infants were able to use decision confidence adaptively to either confirm their initial choice or change their mind. At the neural level, we found that a well-established electrophysiological signature of error monitoring in adults, the errorrelated negativity, is similarly elicited when infants make an incorrect choice. Hence, although explicit forms of metacognition mature later during childhood, infants already estimate decision confidence, monitor their errors, and use these metacognitive evaluations to regulate subsequent behavior.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JKFEFQZ5/Goupil - Behavioral and Neural Indices of Metacognitive Sen.pdf;/Users/alexten/Zotero/storage/JXW8VAX3/Goupil and Kouider - 2016 - Behavioral and Neural Indices of Metacognitive Sen.pdf}
}

@book{greeneHandbookEpistemicCognition2016,
  title = {Handbook of {{Epistemic Cognition}}},
  author = {Greene, Jeffrey A.},
  date = {2016-01-22},
  edition = {1},
  publisher = {{Routledge}},
  location = {{New York : Routledge, 2016. | Series: Educational psychology handbook series}},
  doi = {10.4324/9781315795225},
  url = {https://www.taylorfrancis.com/books/9781315795225},
  urldate = {2021-01-22},
  isbn = {978-1-315-79522-5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6UV8DC3P/Greene - 2016 - Handbook of Epistemic Cognition.pdf;/Users/alexten/Zotero/storage/V5C6R9L3/Greene - 2016 - Handbook of Epistemic Cognition.pdf}
}

@article{greeneInteractingEpistemicSystems,
  title = {Interacting {{Epistemic Systems}} within and beyond the {{Classroom}}},
  author = {Greene, Jeffrey A},
  pages = {15},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/HAXAYHBN/Greene - Interacting Epistemic Systems within and beyond th.pdf}
}

@article{griffithsProbabilisticModelsCognition,
  title = {Probabilistic Models of Cognition: Exploring Representations and Inductive Biases},
  author = {Griffiths, Thomas L},
  pages = {8},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QSKTG65C/Griffiths - Probabilistic models of cognition exploring repre.pdf}
}

@article{griffithsProbabilisticModelsCognitiona,
  title = {Probabilistic Models of Cognition: Exploring Representations and Inductive Biases},
  author = {Griffiths, Thomas L},
  pages = {8},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Y2F7FJTX/Griffiths - Probabilistic models of cognition exploring repre.pdf}
}

@article{grimmerIntroductionBayesianInference,
  title = {An {{Introduction}} to {{Bayesian Inference}} via {{Variational Approximations}}},
  author = {Grimmer, Justin},
  pages = {16},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DD23GLS3/Grimmer - An Introduction to Bayesian Inference via Variatio.pdf}
}

@article{gruberStatesCuriosityModulate2014,
  title = {States of {{Curiosity Modulate Hippocampus}}-{{Dependent Learning}} via the {{Dopaminergic Circuit}}},
  author = {Gruber, Matthias J. and Gelman, Bernard D. and Ranganath, Charan},
  date = {2014-10},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {84},
  number = {2},
  pages = {486--496},
  issn = {08966273},
  doi = {10.1016/j.neuron.2014.08.060},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627314008046},
  urldate = {2021-01-22},
  abstract = {People find it easier to learn about topics that interest them, but little is known about the mechanisms by which intrinsic motivational states affect learning. We used functional magnetic resonance imaging to investigate how curiosity (intrinsic motivation to learn) influences memory. In both immediate and one-day-delayed memory tests, participants showed improved memory for information that they were curious about and for incidental material learned during states of high curiosity. Functional magnetic resonance imaging results revealed that activity in the midbrain and the nucleus accumbens was enhanced during states of high curiosity. Importantly, individual variability in curiosity-driven memory benefits for incidental material was supported by anticipatory activity in the midbrain and hippocampus and by functional connectivity between these regions. These findings suggest a link between the mechanisms supporting extrinsic reward motivation and intrinsic curiosity and highlight the importance of stimulating curiosity to create more effective learning experiences.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/XKCRRQ7D/Gruber et al. - 2014 - States of Curiosity Modulate Hippocampus-Dependent.pdf}
}

@article{gruberStatesCuriosityModulate2014a,
  title = {States of {{Curiosity Modulate Hippocampus}}-{{Dependent Learning}} via the {{Dopaminergic Circuit}}},
  author = {Gruber, Matthias J. and Gelman, Bernard D. and Ranganath, Charan},
  date = {2014-10},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {84},
  number = {2},
  pages = {486--496},
  issn = {08966273},
  doi = {10.1016/j.neuron.2014.08.060},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627314008046},
  urldate = {2021-01-22},
  abstract = {People find it easier to learn about topics that interest them, but little is known about the mechanisms by which intrinsic motivational states affect learning. We used functional magnetic resonance imaging to investigate how curiosity (intrinsic motivation to learn) influences memory. In both immediate and one-day-delayed memory tests, participants showed improved memory for information that they were curious about and for incidental material learned during states of high curiosity. Functional magnetic resonance imaging results revealed that activity in the midbrain and the nucleus accumbens was enhanced during states of high curiosity. Importantly, individual variability in curiosity-driven memory benefits for incidental material was supported by anticipatory activity in the midbrain and hippocampus and by functional connectivity between these regions. These findings suggest a link between the mechanisms supporting extrinsic reward motivation and intrinsic curiosity and highlight the importance of stimulating curiosity to create more effective learning experiences.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CKW5V8SC/Gruber et al. - 2014 - States of Curiosity Modulate Hippocampus-Dependent.pdf}
}

@article{gustafssonFoodNeophobiaSocial,
  title = {Food {{Neophobia}} and {{Social Learning Opportunities}} in {{Great Apes}}},
  author = {Gustafsson, Erik and Jalme, Michel Saint and Bomsel, Marie-Claude and Krief, Sabrina},
  pages = {44},
  abstract = {Finding food resources and maintaining a balanced diet are major concerns for all animals. A compromise between neophobia and neophilia is hypothesised to enable animals to enlarge their diet while limiting the risk of poisoning. However, little is known about how primates respond to novel food items and whether their use is socially transmitted. By comparing how four different species of great apes respond to novel food items, we investigated how differences in physiology (digestive tract size and microbial content), habitats (predictability of food availability), and social systems (group size and composition) affect their response toward novelty. We presented two familiar foods, one novel fruit, four novel aromatic plants from herbal medicine, and kaolin to captive chimpanzees (Pan troglodytes), western gorillas (Gorilla gorilla), Bornean orangutans (Pongo pygmaeus) and Sumatran orangutans (Pongo abelii). We recorded smelling, approach-taste delays, ingestion, interindividual observations, and food transfers with continuous sampling. We found that behaviors differed between the apes: chimpanzees were the most cautious species and observed their conspecifics handling the items more frequently than the other apes. Close observations and food transfers were extremely rare in gorillas in comparison to orangutans and chimpanzees. We suggest that a low neophobia level reflects an adaptive response to digestive physiological features in gorillas and to unpredictable food availability in orangutans. Social interactions appeared to be predominant in chimpanzees and in both orangutan species to overcome food neophobia. They reflect higher social tolerance and more opportunities for social learning and cultural transmission in a feeding context.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/E76X2PIQ/Gustafsson et al. - Food Neophobia and Social Learning Opportunities i.pdf;/Users/alexten/Zotero/storage/ECW3GP97/Gustafsson et al. - Food Neophobia and Social Learning Opportunities i.pdf}
}

@article{halpernCategorizationInformationSelection,
  title = {Categorization, {{Information Selection}} and {{Stimulus Uncertainty}}},
  author = {Halpern, David J and Gureckis, Todd M},
  pages = {6},
  abstract = {Although a common assumption in models of perceptual discrimination, most models of categorization do not explicitly account for uncertainty in stimulus measurement. Such uncertainty may arise from inherent perceptual noise or external measurement noise (e.g., a medical test that gives variable results). In this paper we explore how people decide to gather information from various stimulus properties when each sample or measurement is noisy. The participant’s goal is to correctly classify the given item. Across two experiments we find support for the idea that people take category structure into account when selecting information for a classification decision. In addition, we find some evidence that people are also sensitive to their own perceptual uncertainty when selecting information.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/YCG835GL/Halpern and Gureckis - Categorization, Information Selection and Stimulus.pdf}
}

@article{hamptonMultipleDemonstrationsMetacognition2010,
  title = {Multiple Demonstrations of Metacognition in Nonhumans: {{Converging}} Evidence or Multiple Mechanisms?},
  author = {Hampton, Robert R},
  date = {2010},
  pages = {17},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NTC72N5J/Hampton - 2010 - Multiple demonstrations of metacognition in nonhum.pdf}
}

@article{hamptonMultipleDemonstrationsMetacognition2010a,
  title = {Multiple Demonstrations of Metacognition in Nonhumans: {{Converging}} Evidence or Multiple Mechanisms?},
  author = {Hampton, Robert R},
  date = {2010},
  pages = {17},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/TFQVMFZQ/Hampton - 2010 - Multiple demonstrations of metacognition in nonhum.pdf}
}

@article{hamptonRhesusMonkeysKnow,
  title = {Rhesus Monkeys Know When They Remember},
  author = {Hampton, Robert R},
  pages = {4},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3VRW9CAI/Hampton - Rhesus monkeys know when they remember.pdf}
}

@article{hamptonRhesusMonkeysKnowa,
  title = {Rhesus Monkeys Know When They Remember},
  author = {Hampton, Robert R},
  pages = {4},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PDLZNX8J/Hampton - Rhesus monkeys know when they remember.pdf}
}

@article{hanksPerceptualDecisionMakinga,
  title = {Perceptual {{Decision Making}} in {{Rodents}}, {{Monkeys}}, and {{Humans}}},
  author = {Hanks, Timothy D},
  pages = {17},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/22L92ZKZ/Hanks - Perceptual Decision Making in Rodents, Monkeys, an.pdf}
}

@book{harrellRegressionModelingStrategies2015,
  title = {Regression {{Modeling Strategies}}: {{With Applications}} to {{Linear Models}}, {{Logistic}} and {{Ordinal Regression}}, and {{Survival Analysis}}},
  shorttitle = {Regression {{Modeling Strategies}}},
  author = {Harrell ,, Frank E.},
  date = {2015},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-19425-7},
  url = {http://link.springer.com/10.1007/978-3-319-19425-7},
  urldate = {2021-05-23},
  isbn = {978-3-319-19424-0 978-3-319-19425-7},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CFUAEFS8/Harrell , - 2015 - Regression Modeling Strategies With Applications .pdf}
}

@book{harrellRegressionModelingStrategies2015a,
  title = {Regression {{Modeling Strategies}}: {{With Applications}} to {{Linear Models}}, {{Logistic}} and {{Ordinal Regression}}, and {{Survival Analysis}}},
  shorttitle = {Regression {{Modeling Strategies}}},
  author = {Harrell ,, Frank E.},
  date = {2015},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-19425-7},
  url = {http://link.springer.com/10.1007/978-3-319-19425-7},
  urldate = {2021-05-23},
  isbn = {978-3-319-19424-0 978-3-319-19425-7},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KMV5DPME/Harrell , - 2015 - Regression Modeling Strategies With Applications .pdf}
}

@book{harrellRegressionModelingStrategies2015b,
  title = {Regression {{Modeling Strategies}}: {{With Applications}} to {{Linear Models}}, {{Logistic}} and {{Ordinal Regression}}, and {{Survival Analysis}}},
  shorttitle = {Regression {{Modeling Strategies}}},
  author = {Harrell ,, Frank E.},
  date = {2015},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-19425-7},
  url = {http://link.springer.com/10.1007/978-3-319-19425-7},
  urldate = {2021-05-23},
  isbn = {978-3-319-19424-0 978-3-319-19425-7},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/L4GQBCYI/Harrell , - 2015 - Regression Modeling Strategies With Applications .pdf}
}

@article{harrisonBriefIntroductionMixed2018,
  title = {A Brief Introduction to Mixed Effects Modelling and Multi-Model Inference in Ecology},
  author = {Harrison, Xavier A. and Donaldson, Lynda and Correa-Cano, Maria Eugenia and Evans, Julian and Fisher, David N. and Goodwin, Cecily E.D. and Robinson, Beth S. and Hodgson, David J. and Inger, Richard},
  date = {2018-05-23},
  journaltitle = {PeerJ},
  volume = {6},
  pages = {e4794},
  issn = {2167-8359},
  doi = {10.7717/peerj.4794},
  url = {https://peerj.com/articles/4794},
  urldate = {2021-01-22},
  abstract = {The use of linear mixed effects models (LMMs) is increasingly common in the analysis of biological data. Whilst LMMs offer a flexible approach to modelling a broad range of data types, ecological data are often complex and require complex model structures, and the fitting and interpretation of such models is not always straightforward. The ability to achieve robust biological inference requires that practitioners know how and when to apply these tools. Here, we provide a general overview of current methods for the application of LMMs to biological data, and highlight the typical pitfalls that can be encountered in the statistical modelling process. We tackle several issues regarding methods of model selection, with particular reference to the use of information theory and multi-model inference in ecology. We offer practical solutions and direct the reader to key references that provide further technical detail for those seeking a deeper understanding. This overview should serve as a widely accessible code of best practice for applying LMMs to complex biological problems and model structures, and in doing so improve the robustness of conclusions drawn from studies investigating ecological and evolutionary questions.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7I7TH439/Harrison et al. - 2018 - A brief introduction to mixed effects modelling an.pdf;/Users/alexten/Zotero/storage/HWKFU9LM/Harrison - 2018 - A brief introduction to mixed effects modelling an.pdf}
}

@incollection{hasenjagerActiveLearningSelfOrganizing1999,
  title = {Active {{Learning}} in {{Self}}-{{Organizing Maps}}},
  booktitle = {Kohonen {{Maps}}},
  author = {Hasenjäger, M. and Ritter, H. and Obermayer, K.},
  date = {1999},
  pages = {57--70},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-044450270-4/50005-X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/B978044450270450005X},
  urldate = {2021-01-22},
  isbn = {978-0-444-50270-4},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/RLHCTXMC/Hasenjäger et al. - 1999 - Active Learning in Self-Organizing Maps.pdf}
}

@article{hauserSeparateMesocorticalMesolimbic,
  title = {Separate Mesocortical and Mesolimbic Pathways Encode Effort and Reward Learning Signals},
  author = {Hauser, Tobias U and Eldar, Eran and Dolan, Raymond J},
  journaltitle = {COGNITIVE SCIENCES},
  pages = {10},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NPNRN7MT/Hauser et al. - Separate mesocortical and mesolimbic pathways enco.pdf}
}

@article{hauserSeparateMesocorticalMesolimbica,
  title = {Separate Mesocortical and Mesolimbic Pathways Encode Effort and Reward Learning Signals},
  author = {Hauser, Tobias U and Eldar, Eran and Dolan, Raymond J},
  journaltitle = {COGNITIVE SCIENCES},
  pages = {10},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CCZXMB2L/Hauser et al. - Separate mesocortical and mesolimbic pathways enco.pdf}
}

@article{hawkinsWhyNeuronsHave2016,
  title = {Why {{Neurons Have Thousands}} of {{Synapses}}, a {{Theory}} of {{Sequence Memory}} in {{Neocortex}}},
  author = {Hawkins, Jeff},
  date = {2016},
  journaltitle = {Frontiers in Neural Circuits},
  volume = {10},
  pages = {13},
  abstract = {Pyramidal neurons represent the majority of excitatory neurons in the neocortex. Each pyramidal neuron receives input from thousands of excitatory synapses that are segregated onto dendritic branches. The dendrites themselves are segregated into apical, basal, and proximal integration zones, which have different properties. It is a mystery how pyramidal neurons integrate the input from thousands of synapses, what role the different dendrites play in this integration, and what kind of network behavior this enables in cortical tissue. It has been previously proposed that non-linear properties of dendrites enable cortical neurons to recognize multiple independent patterns. In this paper we extend this idea in multiple ways. First we show that a neuron with several thousand synapses segregated on active dendrites can recognize hundreds of independent patterns of cellular activity even in the presence of large amounts of noise and pattern variation. We then propose a neuron model where patterns detected on proximal dendrites lead to action potentials, defining the classic receptive field of the neuron, and patterns detected on basal and apical dendrites act as predictions by slightly depolarizing the neuron without generating an action potential. By this mechanism, a neuron can predict its activation in hundreds of independent contexts. We then present a network model based on neurons with these properties that learns time-based sequences. The network relies on fast local inhibition to preferentially activate neurons that are slightly depolarized. Through simulation we show that the network scales well and operates robustly over a wide range of parameters as long as the network uses a sparse distributed code of cellular activations. We contrast the properties of the new network model with several other neural network models to illustrate the relative capabilities of each. We conclude that pyramidal neurons with thousands of synapses, active dendrites, and multiple integration zones create a robust and powerful sequence memory. Given the prevalence and similarity of excitatory neurons throughout the neocortex and the importance of sequence memory in inference and behavior, we propose that this form of sequence memory may be a universal property of neocortical tissue.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/RZZPGURF/Hawkins - 2016 - Why Neurons Have Thousands of Synapses, a Theory o.pdf}
}

@article{hawkinsWhyNeuronsHave2016a,
  title = {Why {{Neurons Have Thousands}} of {{Synapses}}, a {{Theory}} of {{Sequence Memory}} in {{Neocortex}}},
  author = {Hawkins, Jeff},
  date = {2016},
  journaltitle = {Frontiers in Neural Circuits},
  volume = {10},
  pages = {13},
  abstract = {Pyramidal neurons represent the majority of excitatory neurons in the neocortex. Each pyramidal neuron receives input from thousands of excitatory synapses that are segregated onto dendritic branches. The dendrites themselves are segregated into apical, basal, and proximal integration zones, which have different properties. It is a mystery how pyramidal neurons integrate the input from thousands of synapses, what role the different dendrites play in this integration, and what kind of network behavior this enables in cortical tissue. It has been previously proposed that non-linear properties of dendrites enable cortical neurons to recognize multiple independent patterns. In this paper we extend this idea in multiple ways. First we show that a neuron with several thousand synapses segregated on active dendrites can recognize hundreds of independent patterns of cellular activity even in the presence of large amounts of noise and pattern variation. We then propose a neuron model where patterns detected on proximal dendrites lead to action potentials, defining the classic receptive field of the neuron, and patterns detected on basal and apical dendrites act as predictions by slightly depolarizing the neuron without generating an action potential. By this mechanism, a neuron can predict its activation in hundreds of independent contexts. We then present a network model based on neurons with these properties that learns time-based sequences. The network relies on fast local inhibition to preferentially activate neurons that are slightly depolarized. Through simulation we show that the network scales well and operates robustly over a wide range of parameters as long as the network uses a sparse distributed code of cellular activations. We contrast the properties of the new network model with several other neural network models to illustrate the relative capabilities of each. We conclude that pyramidal neurons with thousands of synapses, active dendrites, and multiple integration zones create a robust and powerful sequence memory. Given the prevalence and similarity of excitatory neurons throughout the neocortex and the importance of sequence memory in inference and behavior, we propose that this form of sequence memory may be a universal property of neocortical tissue.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/U2YE7IH4/Hawkins - 2016 - Why Neurons Have Thousands of Synapses, a Theory o.pdf}
}

@article{heeneLevelsMeasurementStatistical,
  title = {Levels of Measurement and Statistical Analyses {{Matt N}}. {{Williams}}},
  author = {Heene, Moritz and McGrane, J and Kyngdon, A},
  pages = {14},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IRCWY29W/Heene et al. - Levels of measurement and statistical analyses Mat.pdf}
}

@article{hehmanAdvancedMousetrackingAnalytic2015,
  title = {Advanced Mouse-Tracking Analytic Techniques for Enhancing Psychological Science},
  author = {Hehman, Eric and Stolier, Ryan M. and Freeman, Jonathan B.},
  date = {2015-05},
  journaltitle = {Group Processes \& Intergroup Relations},
  shortjournal = {Group Processes \& Intergroup Relations},
  volume = {18},
  number = {3},
  pages = {384--401},
  issn = {1368-4302, 1461-7188},
  doi = {10.1177/1368430214538325},
  url = {http://journals.sagepub.com/doi/10.1177/1368430214538325},
  urldate = {2021-01-22},
  abstract = {Computer mouse-tracking is a relatively recently developed behavioral methodology that can contribute unique insight into a wide variety of psychological phenomena. By recording mouse movements en route to specific responses on a screen, researchers glean continuous information about tentative commitments to multiple response alternatives over time. This approach yields a richness of data that can be fully explored with a variety of sophisticated analytic techniques, but these approaches are relatively underutilized and can be difficult to adopt. Here we describe several techniques for researchers to examine the onset and timing of evolving decision processes; test the degree of response competition at different time points; assess trajectory complexity with spatial disorder analyses; identify qualitatively distinct psychological processes during response generation; and finally to distill unique and meaningful components from mouse-tracking data for subsequent analysis. With this guide, we hope researchers can address novel hypotheses otherwise inaccessible with more traditional methods.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QP9H8QXG/Hehman et al. - 2015 - Advanced mouse-tracking analytic techniques for en.pdf}
}

@article{heisigWhyYouShould,
  title = {Why {{You Should Always Include}} a {{Random Slope}} for the {{Lower}}-{{Level Variable Involved}} in a {{Cross}}-{{Level Interaction}}},
  author = {Heisig, Jan Paul and Schaeffer, Merlin},
  pages = {77},
  abstract = {Mixed effects multilevel models are often used to investigate cross-level interactions, a specific type of context effect that may be understood as an upper-level variable moderating the association between a lower-level predictor and the outcome. We argue that multilevel models involving crosslevel interactions should always include random slopes on the lower-level components of those interactions. Failure to do so will usually result in severely anti-conservative statistical inference. Monte Carlo simulations and illustrative empirical analyses highlight the practical relevance of the issue. Using European Social Survey data, we examine a total 30 cross-level interactions. Introducing a random slope term on the lower-level variable involved in a cross-level interaction, reduces the absolute t-ratio by 31\% or more in three quarters of cases, with an average reduction of 42\%. Many practitioners seem to be unaware of these issues. Roughly half of the cross-level interaction estimates published in the European Sociological Review between 2011 and 2016 are based on models that omit the crucial random slope term. Detailed analysis of the associated test statistics suggests that many of the estimates would not meet conventional standards of statistical significance if estimated using the correct specification. This raises the question how much robust evidence of cross-level interactions sociology has actually produced over the past decades.},
  langid = {english},
  keywords = {starred},
  file = {/Users/alexten/Zotero/storage/P3663A7S/Heisig and Schaeffer - Why You Should Always Include a Random Slope for t.pdf}
}

@article{hertelAccuracyBeliefsRetrieval,
  title = {The Accuracy of Beliefs about Retrieval Cues},
  author = {Hertel, Paula T and Anooshian, L J and Ashbrook, P W},
  pages = {6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/J9X9VGEZ/Hertel et al. - The accuracy of beliefs about retrieval cues.pdf}
}

@article{hertelAccuracyBeliefsRetrieval1986,
  title = {The Accuracy of Beliefs about Retrieval Cues},
  author = {Hertel, Paula T. and Anooshian, Linda J. and Ashbrook, Patricia},
  date = {1986-05},
  journaltitle = {Memory \& Cognition},
  shortjournal = {Memory \& Cognition},
  volume = {14},
  number = {3},
  pages = {265--269},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03197702},
  url = {http://link.springer.com/10.3758/BF03197702},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IDFBNY7N/Hertel et al. - 1986 - The accuracy of beliefs about retrieval cues.pdf}
}

@article{heyesKnowingOurselvesTogether2020,
  title = {Knowing {{Ourselves Together}}: {{The Cultural Origins}} of {{Metacognition}}},
  shorttitle = {Knowing {{Ourselves Together}}},
  author = {Heyes, Cecilia and Bang, Dan and Shea, Nicholas and Frith, Christopher D. and Fleming, Stephen M.},
  date = {2020-05},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {24},
  number = {5},
  pages = {349--362},
  issn = {13646613},
  doi = {10.1016/j.tics.2020.02.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661320300590},
  urldate = {2021-05-28},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/T7DDZSZN/Heyes et al. - 2020 - Knowing Ourselves Together The Cultural Origins o.pdf}
}

@article{heyesKnowingOurselvesTogether2020a,
  title = {Knowing {{Ourselves Together}}: {{The Cultural Origins}} of {{Metacognition}}},
  shorttitle = {Knowing {{Ourselves Together}}},
  author = {Heyes, Cecilia and Bang, Dan and Shea, Nicholas and Frith, Christopher D. and Fleming, Stephen M.},
  date = {2020-05},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {24},
  number = {5},
  pages = {349--362},
  issn = {13646613},
  doi = {10.1016/j.tics.2020.02.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661320300590},
  urldate = {2021-05-28},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/YW7J5KFD/Heyes et al. - 2020 - Knowing Ourselves Together The Cultural Origins o.pdf}
}

@article{hidiFourPhaseModelInterest,
  title = {The {{Four}}-{{Phase Model}} of {{Interest Development}}},
  author = {Hidi, Suzanne and Renninger, K Ann},
  pages = {18},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JMIRQEFS/Hidi and Renninger - The Four-Phase Model of Interest Development.pdf}
}

@article{hidiFourPhaseModelInteresta,
  title = {The {{Four}}-{{Phase Model}} of {{Interest Development}}},
  author = {Hidi, Suzanne and Renninger, K Ann},
  pages = {18},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7V9RKYHJ/Hidi and Renninger - The Four-Phase Model of Interest Development.pdf}
}

@article{highamNewImprovedGamma2019,
  title = {New Improved Gamma: {{Enhancing}} the Accuracy of {{Goodman}}–{{Kruskal}}’s Gamma Using {{ROC}} Curves},
  author = {Higham, Philip A},
  date = {2019},
  pages = {18},
  abstract = {For decades, researchers have debated the relative merits of different measures of people’s ability to discriminate the correctness of their own responses (resolution). The probabilistic approach, primarily led by Nelson, has advocated the Goodman–Kruskal gamma coefficient, an ordinal measure of association. The signal detection approach has advocated parametric measures of distance between the evidence distributions or the area under the receiver operating characteristic (ROC) curve. Here we provide mathematical proof that the indices associated with the two approaches are far more similar than has previously been thought: The true value of gamma is equal to twice the true area under the ROC curve minus one. Using this insight, we report 36 simulations involving 3,600,000 virtual participants that pitted gamma estimated with the original concordance/discordance formula against gamma estimated via ROC curves and the trapezoidal rule. In all but five of our simulations—which systematically varied resolution, the number of points on the metacognitive scale, and response bias—the ROC-based gamma estimate deviated less from the true value of gamma than did the traditional estimate. Consequently, we recommend using ROC curves to estimate gamma in the future.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/D6Z7IW56/Higham - 2019 - New improved gamma Enhancing the accuracy of Good.pdf}
}

@article{highamNewImprovedGamma2019a,
  title = {New Improved Gamma: {{Enhancing}} the Accuracy of {{Goodman}}–{{Kruskal}}’s Gamma Using {{ROC}} Curves},
  shorttitle = {New Improved Gamma},
  author = {Higham, Philip A. and Higham, D. Paul},
  date = {2019-02},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {51},
  number = {1},
  pages = {108--125},
  issn = {1554-3528},
  doi = {10.3758/s13428-018-1125-5},
  url = {http://link.springer.com/10.3758/s13428-018-1125-5},
  urldate = {2021-01-22},
  abstract = {For decades, researchers have debated the relative merits of different measures of people’s ability to discriminate the correctness of their own responses (resolution). The probabilistic approach, primarily led by Nelson, has advocated the Goodman–Kruskal gamma coefficient, an ordinal measure of association. The signal detection approach has advocated parametric measures of distance between the evidence distributions or the area under the receiver operating characteristic (ROC) curve. Here we provide mathematical proof that the indices associated with the two approaches are far more similar than has previously been thought: The true value of gamma is equal to twice the true area under the ROC curve minus one. Using this insight, we report 36 simulations involving 3,600,000 virtual participants that pitted gamma estimated with the original concordance/discordance formula against gamma estimated via ROC curves and the trapezoidal rule. In all but five of our simulations—which systematically varied resolution, the number of points on the metacognitive scale, and response bias—the ROC-based gamma estimate deviated less from the true value of gamma than did the traditional estimate. Consequently, we recommend using ROC curves to estimate gamma in the future.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/TATXZW5A/Higham and Higham - 2019 - New improved gamma Enhancing the accuracy of Good.pdf}
}

@article{hobsonDreamingBrainCognitive2000,
  title = {Dreaming and the Brain: {{Toward}} a Cognitive Neuroscience of Conscious States},
  author = {Hobson, J Allan and Pace-Schott, Edward F and Stickgold, Robert},
  date = {2000},
  journaltitle = {BEHAVIORAL AND BRAIN SCIENCES},
  pages = {51},
  abstract = {Sleep researchers in different disciplines disagree about how fully dreaming can be explained in terms of brain physiology. Debate has focused on whether REM sleep dreaming is qualitatively different from nonREM (NREM) sleep and waking. A review of psychophysiological studies shows clear quantitative differences between REM and NREM mentation and between REM and waking mentation. Recent neuroimaging and neurophysiological studies also differentiate REM, NREM, and waking in features with phenomenological implications. Both evidence and theory suggest that there are isomorphisms between the phenomenology and the physiology of dreams. We present a three-dimensional model with specific examples from normally and abnormally changing conscious states.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DFKXIJ2I/Hobson et al. - 2000 - Dreaming and the brain Toward a cognitive neurosc.pdf;/Users/alexten/Zotero/storage/UUBS2U7F/Hobson et al. - 2000 - Dreaming and the brain Toward a cognitive neurosc.pdf}
}

@article{hoferEpistemicCognitionPsychological,
  title = {Epistemic {{Cognition}} as a {{Psychological Construct}}:},
  author = {Hofer, Barbara K},
  pages = {38},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/J42BIZXY/Hofer - Epistemic Cognition as a Psychological Construct.pdf;/Users/alexten/Zotero/storage/QIQ5J28F/Hofer - Epistemic Cognition as a Psychological Construct.pdf}
}

@article{hoffrageResearchHindsightBias2003,
  title = {Research on Hindsight Bias: {{A}} Rich Past, a Productive Present, and a Challenging Future},
  shorttitle = {Research on Hindsight Bias},
  author = {Hoffrage, Ulrich and Pohl, Rüdiger},
  date = {2003-01},
  journaltitle = {Memory},
  shortjournal = {Memory},
  volume = {11},
  number = {4-5},
  pages = {329--335},
  issn = {0965-8211, 1464-0686},
  doi = {10.1080/09658210344000080},
  url = {http://www.tandfonline.com/doi/abs/10.1080/09658210344000080},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FJHYM2PP/Hoffrage and Pohl - 2003 - Research on hindsight bias A rich past, a product.pdf}
}

@article{hoffrageResearchHindsightBias2003a,
  title = {Research on Hindsight Bias: {{A}} Rich Past, a Productive Present, and a Challenging Future},
  shorttitle = {Research on Hindsight Bias},
  author = {Hoffrage, Ulrich and Pohl, Rüdiger},
  date = {2003-01},
  journaltitle = {Memory},
  shortjournal = {Memory},
  volume = {11},
  number = {4-5},
  pages = {329--335},
  issn = {0965-8211, 1464-0686},
  doi = {10.1080/09658210344000080},
  url = {http://www.tandfonline.com/doi/abs/10.1080/09658210344000080},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JLRIMRBE/Hoffrage and Pohl - 2003 - Research on hindsight bias A rich past, a product.pdf}
}

@article{holmEpisodicCuriosityAvoiding2019,
  title = {Episodic Curiosity for Avoiding Asteroids: {{Per}}-Trial Information Gain for Choice Outcomes Drive Information Seeking},
  shorttitle = {Episodic Curiosity for Avoiding Asteroids},
  author = {Holm, Linus and Wadenholt, Gustaf and Schrater, Paul},
  date = {2019-12},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {9},
  number = {1},
  pages = {11265},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-47671-x},
  url = {http://www.nature.com/articles/s41598-019-47671-x},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/F2NDNJ6L/Holm - Episodic curiosity for avoiding asteroids Per-tri.pdf;/Users/alexten/Zotero/storage/I6KV3BUZ/Holm et al. - 2019 - Episodic curiosity for avoiding asteroids Per-tri.pdf}
}

@article{hourihanSmallerBetterWhen,
  title = {Smaller {{Is Better}} ({{When Sampling From}} the {{Crowd Within}}): {{Low Memory}}-{{Span Individuals Benefit More From Multiple Opportunities}} for {{Estimation}}},
  author = {Hourihan, Kathleen L and Benjamin, Aaron S},
  pages = {8},
  abstract = {Recently, Vul and Pashler (2008) demonstrated that the average of 2 responses from a single subject to general knowledge questions was more accurate than either single estimate. Importantly, this reveals that each guess contributes unique evidence relevant to the decision, contrary to views that eschew probabilistic representations of the evidence-gathering and decision-making processes. We tested an implication of that view by evaluating this effect separately in individuals with a range of memory spans. If memory span is the buffer in which retrieved information is assembled into an evaluation, then multiple estimates in individuals with lower memory spans should exhibit greater independence from one another than in individuals with higher spans. Our results supported this theory by showing that averaging 2 guesses from lower span individuals is more beneficial than averaging 2 guesses from higher span individuals. These results demonstrate a rare circumstance in which lower memory span confers a relative advantage on a cognitive task.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/D54AHATX/Hourihan and Benjamin - Smaller Is Better (When Sampling From the Crowd Wi.pdf}
}

@article{hourihanSmallerBetterWhen2010,
  title = {Smaller Is Better (When Sampling from the Crowd within): {{Low}} Memory-Span Individuals Benefit More from Multiple Opportunities for Estimation.},
  shorttitle = {Smaller Is Better (When Sampling from the Crowd Within)},
  author = {Hourihan, Kathleen L. and Benjamin, Aaron S.},
  date = {2010},
  journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  shortjournal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {36},
  number = {4},
  pages = {1068--1074},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/a0019694},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0019694},
  urldate = {2021-01-22},
  abstract = {Recently, Vul and Pashler (2008) demonstrated that the average of 2 responses from a single subject to general knowledge questions was more accurate than either single estimate. Importantly, this reveals that each guess contributes unique evidence relevant to the decision, contrary to views that eschew probabilistic representations of the evidence-gathering and decision-making processes. We tested an implication of that view by evaluating this effect separately in individuals with a range of memory spans. If memory span is the buffer in which retrieved information is assembled into an evaluation, then multiple estimates in individuals with lower memory spans should exhibit greater independence from one another than in individuals with higher spans. Our results supported this theory by showing that averaging 2 guesses from lower span individuals is more beneficial than averaging 2 guesses from higher span individuals. These results demonstrate a rare circumstance in which lower memory span confers a relative advantage on a cognitive task.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BE3X9F5U/Hourihan and Benjamin - 2010 - Smaller is better (when sampling from the crowd wi.pdf}
}

@online{houthooftVIMEVariationalInformation2017,
  title = {{{VIME}}: {{Variational Information Maximizing Exploration}}},
  shorttitle = {{{VIME}}},
  author = {Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  date = {2017-01-27},
  eprint = {1605.09674},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1605.09674},
  urldate = {2021-01-22},
  abstract = {Scalable and effective exploration remains a key challenge in reinforcement learning (RL). While there are methods with optimality guarantees in the setting of discrete state and action spaces, these methods cannot be applied in high-dimensional deep RL scenarios. As such, most contemporary RL relies on simple heuristics such as -greedy exploration or adding Gaussian noise to the controls. This paper introduces Variational Information Maximizing Exploration (VIME), an exploration strategy based on maximization of information gain about the agent’s belief of environment dynamics. We propose a practical implementation, using variational inference in Bayesian neural networks which efficiently handles continuous state and action spaces. VIME modifies the MDP reward function, and can be applied with several different underlying RL algorithms. We demonstrate that VIME achieves significantly better performance compared to heuristic exploration methods across a variety of continuous control tasks and algorithms, including tasks with very sparse rewards.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/T585IVBA/Houthooft et al. - 2017 - VIME Variational Information Maximizing Explorati.pdf}
}

@article{houwerWhatLearningNature,
  title = {What Is Learning? {{On}} the Nature and Merits of a Functional Definition of Learning},
  author = {Houwer, Jan De and Barnes-Holmes, Dermot and Moors, Agnes},
  journaltitle = {Psychon Bull Rev},
  pages = {12},
  abstract = {Learning has been defined functionally as changes in behavior that result from experience or mechanistically as changes in the organism that result from experience. Both types of definitions are problematic. We define learning as ontogenetic adaptation—that is, as changes in the behavior of an organism that result from regularities in the environment of the organism. This functional definition not only solves the problems of other definitions, but also has important advantages for cognitive learning research.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9LRG6RNG/Houwer et al. - What is learning On the nature and merits of a fu.pdf;/Users/alexten/Zotero/storage/WRH5LM2Q/Houwer et al. - What is learning On the nature and merits of a fu.pdf}
}

@article{huelserMakingRelatedErrors2012,
  title = {Making Related Errors Facilitates Learning, but Learners Do Not Know It},
  author = {Huelser, Barbie J and Metcalfe, Janet},
  date = {2012},
  pages = {14},
  abstract = {Producing an error, so long as it is followed by corrective feedback, has been shown to result in better retention of the correct answers than does simply studying the correct answers from the outset. The reasons for this surprising finding, however, have not been investigated. Our hypothesis was that the effect might occur only when the errors produced were related to the targeted correct response. In Experiment 1, participants studied either related or unrelated word pairs, manipulated between participants. Participants either were given the cue and target to study for 5 or 10 s or generated an error in response to the cue for the first 5 s before receiving the correct answer for the final 5 s. When the cues and targets were related, error-generation led to the highest correct retention. However, consistent with the hypothesis, no benefit was derived from generating an error when the cue and target were unrelated. Latent semantic analysis revealed that the errors generated in the related condition were related to the target, whereas they were not related to the target in the unrelated condition. Experiment 2 replicated these findings in a within-participants design. We found, additionally, that people did not know that generating an error enhanced memory, even after they had just completed the task that produced substantial benefits.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GRH2YQVL/Huelser and Metcalfe - 2012 - Making related errors facilitates learning, but le.pdf}
}

@article{huelserMakingRelatedErrors2012a,
  title = {Making Related Errors Facilitates Learning, but Learners Do Not Know It},
  author = {Huelser, Barbie J. and Metcalfe, Janet},
  date = {2012-05},
  journaltitle = {Memory \& Cognition},
  shortjournal = {Mem Cogn},
  volume = {40},
  number = {4},
  pages = {514--527},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/s13421-011-0167-z},
  url = {http://link.springer.com/10.3758/s13421-011-0167-z},
  urldate = {2021-01-22},
  abstract = {Producing an error, so long as it is followed by corrective feedback, has been shown to result in better retention of the correct answers than does simply studying the correct answers from the outset. The reasons for this surprising finding, however, have not been investigated. Our hypothesis was that the effect might occur only when the errors produced were related to the targeted correct response. In Experiment 1, participants studied either related or unrelated word pairs, manipulated between participants. Participants either were given the cue and target to study for 5 or 10 s or generated an error in response to the cue for the first 5 s before receiving the correct answer for the final 5 s. When the cues and targets were related, error-generation led to the highest correct retention. However, consistent with the hypothesis, no benefit was derived from generating an error when the cue and target were unrelated. Latent semantic analysis revealed that the errors generated in the related condition were related to the target, whereas they were not related to the target in the unrelated condition. Experiment 2 replicated these findings in a within-participants design. We found, additionally, that people did not know that generating an error enhanced memory, even after they had just completed the task that produced substantial benefits.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EYDJGSSC/Huelser and Metcalfe - 2012 - Making related errors facilitates learning, but le.pdf}
}

@article{HungerKnowledgeHow,
  title = {Hunger for {{Knowledge}}: {{How}} the {{Irresistible Lure}} of {{Curiosity}} Is {{Generated}} in the {{Brain}}},
  pages = {36},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/C5QBUMHK/Hunger for Knowledge How the Irresistible Lure of.pdf;/Users/alexten/Zotero/storage/QT6ZCM67/Hunger for Knowledge How the Irresistible Lure of.pdf}
}

@article{iigayaModulationSavouringPrediction,
  title = {The Modulation of Savouring by Prediction Error and Its Effects on Choice.},
  author = {Iigaya, Kiyohito and Story, Giles W and Kurth-Nelson, Zeb and Dolan, Raymond J and Dayan, Peter},
  pages = {24},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PAXRSRTC/Iigaya et al. - The modulation of savouring by prediction error an.pdf}
}

@article{iigayaModulationSavouringPrediction2016,
  title = {The Modulation of Savouring by Prediction Error and Its Effects on Choice},
  author = {Iigaya, Kiyohito and Story, Giles W and Kurth-Nelson, Zeb and Dolan, Raymond J and Dayan, Peter},
  date = {2016-04-21},
  journaltitle = {eLife},
  volume = {5},
  pages = {e13747},
  issn = {2050-084X},
  doi = {10.7554/eLife.13747},
  url = {https://elifesciences.org/articles/13747},
  urldate = {2021-01-22},
  abstract = {When people anticipate uncertain future outcomes, they often prefer to know their fate in advance. Inspired by an idea in behavioral economics that the anticipation of rewards is itself attractive, we hypothesized that this preference of advance information arises because reward prediction errors carried by such information can boost the level of anticipation. We designed new empirical behavioral studies to test this proposal, and confirmed that subjects preferred advance reward information more strongly when they had to wait for rewards for a longer time. We formulated our proposal in a reinforcement-learning model, and we showed that our model could account for a wide range of existing neuronal and behavioral data, without appealing to ambiguous notions such as an explicit value for information. We suggest that such boosted anticipation significantly drives risk-seeking behaviors, most pertinently in gambling.           ,              People, pigeons and monkeys often want to know in advance whether they will receive a reward in the future. This behaviour is irrational when individuals pay for costly information that makes no difference to an eventual outcome. One explanation is that individuals seek information because anticipating reward has hedonic value (it produces a feeling of pleasure). Consistent with this, pigeons are more likely to seek information when they have to wait longer for the potential reward. However, existing models cannot account for why this anticipation of rewards leads to irrational information-seeking.             In many situations, animals are uncertain about what is going to happen. Providing new information can produce a “prediction error” that indexes a discrepancy between what is expected and what actually happens. Iigaya et al. have now developed a mathematical model of information-seeking in which anticipation is boosted by this prediction error.             The model accounts for a wide range of previously unexplained data from monkeys and pigeons. It also successfully explains the behaviour of a group of human volunteers from whom Iigaya et al. elicited informational and actual decisions concerning uncertain and delayed rewards. The longer that the participants had to wait for possible rewards, the more avidly they wanted to find out about them. Further research is now needed to investigate the neural underpinnings of anticipation and its boosting by prediction errors.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DZRWYEBK/Iigaya et al. - 2016 - The modulation of savouring by prediction error an.pdf}
}

@article{iigayaModulationSavouringPrediction2016a,
  title = {The Modulation of Savouring by Prediction Error and Its Effects on Choice},
  author = {Iigaya, Kiyohito and Story, Giles W and Kurth-Nelson, Zeb and Dolan, Raymond J and Dayan, Peter},
  date = {2016-04-21},
  journaltitle = {eLife},
  volume = {5},
  pages = {e13747},
  issn = {2050-084X},
  doi = {10.7554/eLife.13747},
  url = {https://elifesciences.org/articles/13747},
  urldate = {2021-01-22},
  abstract = {When people anticipate uncertain future outcomes, they often prefer to know their fate in advance. Inspired by an idea in behavioral economics that the anticipation of rewards is itself attractive, we hypothesized that this preference of advance information arises because reward prediction errors carried by such information can boost the level of anticipation. We designed new empirical behavioral studies to test this proposal, and confirmed that subjects preferred advance reward information more strongly when they had to wait for rewards for a longer time. We formulated our proposal in a reinforcement-learning model, and we showed that our model could account for a wide range of existing neuronal and behavioral data, without appealing to ambiguous notions such as an explicit value for information. We suggest that such boosted anticipation significantly drives risk-seeking behaviors, most pertinently in gambling.           ,              People, pigeons and monkeys often want to know in advance whether they will receive a reward in the future. This behaviour is irrational when individuals pay for costly information that makes no difference to an eventual outcome. One explanation is that individuals seek information because anticipating reward has hedonic value (it produces a feeling of pleasure). Consistent with this, pigeons are more likely to seek information when they have to wait longer for the potential reward. However, existing models cannot account for why this anticipation of rewards leads to irrational information-seeking.             In many situations, animals are uncertain about what is going to happen. Providing new information can produce a “prediction error” that indexes a discrepancy between what is expected and what actually happens. Iigaya et al. have now developed a mathematical model of information-seeking in which anticipation is boosted by this prediction error.             The model accounts for a wide range of previously unexplained data from monkeys and pigeons. It also successfully explains the behaviour of a group of human volunteers from whom Iigaya et al. elicited informational and actual decisions concerning uncertain and delayed rewards. The longer that the participants had to wait for possible rewards, the more avidly they wanted to find out about them. Further research is now needed to investigate the neural underpinnings of anticipation and its boosting by prediction errors.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UY5RKPZM/Iigaya et al. - 2016 - The modulation of savouring by prediction error an.pdf}
}

@article{iigayaModulationSavouringPrediction2016b,
  title = {The Modulation of Savouring by Prediction Error and Its Effects on Choice},
  author = {Iigaya, Kiyohito and Story, Giles W and Kurth-Nelson, Zeb and Dolan, Raymond J and Dayan, Peter},
  date = {2016-04-21},
  journaltitle = {eLife},
  volume = {5},
  pages = {e13747},
  issn = {2050-084X},
  doi = {10.7554/eLife.13747},
  url = {https://elifesciences.org/articles/13747},
  urldate = {2021-01-22},
  abstract = {When people anticipate uncertain future outcomes, they often prefer to know their fate in advance. Inspired by an idea in behavioral economics that the anticipation of rewards is itself attractive, we hypothesized that this preference of advance information arises because reward prediction errors carried by such information can boost the level of anticipation. We designed new empirical behavioral studies to test this proposal, and confirmed that subjects preferred advance reward information more strongly when they had to wait for rewards for a longer time. We formulated our proposal in a reinforcement-learning model, and we showed that our model could account for a wide range of existing neuronal and behavioral data, without appealing to ambiguous notions such as an explicit value for information. We suggest that such boosted anticipation significantly drives risk-seeking behaviors, most pertinently in gambling.           ,              People, pigeons and monkeys often want to know in advance whether they will receive a reward in the future. This behaviour is irrational when individuals pay for costly information that makes no difference to an eventual outcome. One explanation is that individuals seek information because anticipating reward has hedonic value (it produces a feeling of pleasure). Consistent with this, pigeons are more likely to seek information when they have to wait longer for the potential reward. However, existing models cannot account for why this anticipation of rewards leads to irrational information-seeking.             In many situations, animals are uncertain about what is going to happen. Providing new information can produce a “prediction error” that indexes a discrepancy between what is expected and what actually happens. Iigaya et al. have now developed a mathematical model of information-seeking in which anticipation is boosted by this prediction error.             The model accounts for a wide range of previously unexplained data from monkeys and pigeons. It also successfully explains the behaviour of a group of human volunteers from whom Iigaya et al. elicited informational and actual decisions concerning uncertain and delayed rewards. The longer that the participants had to wait for possible rewards, the more avidly they wanted to find out about them. Further research is now needed to investigate the neural underpinnings of anticipation and its boosting by prediction errors.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4GHGGIUJ/Iigaya et al. - 2016 - The modulation of savouring by prediction error an.pdf}
}

@article{ikedaAchievementGoalsAffect2016,
  title = {Achievement Goals Affect Metacognitive Judgments.},
  author = {Ikeda, Kenji and Yue, Carole L. and Murayama, Kou and Castel, Alan D.},
  date = {2016-12},
  journaltitle = {Motivation Science},
  shortjournal = {Motivation Science},
  volume = {2},
  number = {4},
  pages = {199--219},
  issn = {2333-8121, 2333-8113},
  doi = {10.1037/mot0000047},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/mot0000047},
  urldate = {2021-01-22},
  abstract = {The present study examined the effect of achievement goals on metacognitive judgments, such as judgments of learning (JOLs) and metacomprehension judgments, and actual recall performance. We conducted 5 experiments manipulating the instruction of achievement goals. In each experiment, participants were instructed to adopt masteryapproach goals (i.e., develop their own mental ability through a memory task) or performance-approach goals (i.e., demonstrate their strong memory ability through getting a high score on a memory task). The results of Experiments 1 and 2 showed that JOLs of word pairs in the performance-approach goal condition tended to be higher than those in the mastery-approach goal condition. In contrast, cued recall performance did not differ between the 2 goal conditions. Experiment 3 also demonstrated that metacomprehension judgments of text passages were higher in the performanceapproach goal condition than in the mastery-approach goals condition, whereas test performance did not differ between conditions. These findings suggest that achievement motivation affects metacognitive judgments during learning, even when achievement motivation does not influence actual performance.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/TFQUFHTY/Ikeda et al. - 2016 - Achievement goals affect metacognitive judgments..pdf;/Users/alexten/Zotero/storage/WBMCXGL3/Ikeda et al. - 2016 - Achievement goals affect metacognitive judgments..pdf}
}

@article{ikemotoBrainRewardCircuitry2010,
  title = {Brain Reward Circuitry beyond the Mesolimbic Dopamine System: {{A}} Neurobiological Theory},
  author = {Ikemoto, Satoshi},
  date = {2010},
  journaltitle = {Neuroscience and Biobehavioral Reviews},
  pages = {22},
  abstract = {Reductionist attempts to dissect complex mechanisms into simpler elements are necessary, but not sufficient for understanding how biological properties like reward emerge out of neuronal activity. Recent studies on intracranial self-administration of neurochemicals (drugs) found that rats learn to selfadminister various drugs into the mesolimbic dopamine structures—the posterior ventral tegmental area, medial shell nucleus accumbens and medial olfactory tubercle. In addition, studies found roles of non-dopaminergic mechanisms of the supramammillary, rostromedial tegmental and midbrain raphe nuclei in reward.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8Y9JN8K6/Ikemoto - 2010 - Brain reward circuitry beyond the mesolimbic dopam.pdf;/Users/alexten/Zotero/storage/KANMJS5Q/Ikemoto - 2010 - Brain reward circuitry beyond the mesolimbic dopam.pdf}
}

@article{inzlichtEffortParadoxEffort,
  title = {The {{Effort Paradox}}: {{Effort Is Both Costly}} and {{Valued}}},
  author = {Inzlicht, Michael},
  pages = {13},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KCM6L3JG/Inzlicht - The Effort Paradox Effort Is Both Costly and Valu.pdf}
}

@article{inzlichtEffortParadoxEfforta,
  title = {The {{Effort Paradox}}: {{Effort Is Both Costly}} and {{Valued}}},
  author = {Inzlicht, Michael},
  pages = {13},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9ZXS2SCB/Inzlicht - The Effort Paradox Effort Is Both Costly and Valu.pdf}
}

@article{inzlichtWhySelfcontrolSeems2014,
  title = {Why Self-Control Seems (but May Not Be) Limited},
  author = {Inzlicht, Michael},
  date = {2014},
  volume = {18},
  number = {3},
  pages = {7},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FGBZ55U8/Inzlicht - 2014 - Why self-control seems (but may not be) limited.pdf;/Users/alexten/Zotero/storage/UQY6RZZN/Inzlicht - 2014 - Why self-control seems (but may not be) limited.pdf}
}

@article{isikmanEffectsCuriosityEvokingEvents,
  title = {The {{Effects}} of {{Curiosity}}-{{Evoking Events}} on {{Activity Enjoyment}}},
  author = {Isikman, Elif and MacInnis, Deborah J and Ülkümen, Gülden and Cavanaugh, Lisa A},
  pages = {12},
  abstract = {Whereas prior literature has studied the positive effects of curiosity-evoking events that are integral to focal activities, we explore whether and how a curiosity-evoking event that is incidental to a focal activity induces negative outcomes for enjoyment. Four experiments and 1 field study demonstrate that curiosity about an event that is incidental to an activity in which individuals are engaged, significantly affects enjoyment of a concurrent activity. The reason why is that curiosity diverts attention away from the concurrent activity and focuses attention on the curiosity-evoking event. Thus, curiosity regarding an incidental event decreases enjoyment of a positive focal activity but increases enjoyment of a negative focal activity.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BMI6KPXK/Isikman et al. - The Effects of Curiosity-Evoking Events on Activit.pdf}
}

@article{isikmanEffectsCuriosityevokingEvents2016,
  title = {The Effects of Curiosity-Evoking Events on Activity Enjoyment.},
  author = {Isikman, Elif and MacInnis, Deborah J. and Ülkümen, Gülden and Cavanaugh, Lisa A.},
  date = {2016-09},
  journaltitle = {Journal of Experimental Psychology: Applied},
  shortjournal = {Journal of Experimental Psychology: Applied},
  volume = {22},
  number = {3},
  pages = {319--330},
  issn = {1939-2192, 1076-898X},
  doi = {10.1037/xap0000089},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xap0000089},
  urldate = {2021-01-22},
  abstract = {Whereas prior literature has studied the positive effects of curiosity-evoking events that are integral to focal activities, we explore whether and how a curiosity-evoking event that is incidental to a focal activity induces negative outcomes for enjoyment. Four experiments and 1 field study demonstrate that curiosity about an event that is incidental to an activity in which individuals are engaged, significantly affects enjoyment of a concurrent activity. The reason why is that curiosity diverts attention away from the concurrent activity and focuses attention on the curiosity-evoking event. Thus, curiosity regarding an incidental event decreases enjoyment of a positive focal activity but increases enjoyment of a negative focal activity.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CYWQ8U5A/Isikman et al. - 2016 - The effects of curiosity-evoking events on activit.pdf}
}

@article{itoMultipleRepresentationsAlgorithms2011,
  title = {Multiple Representations and Algorithms for Reinforcement Learning in the Cortico-Basal Ganglia Circuit},
  author = {Ito, Makoto},
  date = {2011},
  journaltitle = {Current Opinion in Neurobiology},
  pages = {6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2W9QHTDL/Ito - 2011 - Multiple representations and algorithms for reinfo.pdf}
}

@article{itoMultipleRepresentationsAlgorithms2011a,
  title = {Multiple Representations and Algorithms for Reinforcement Learning in the Cortico-Basal Ganglia Circuit},
  author = {Ito, Makoto},
  date = {2011},
  journaltitle = {Current Opinion in Neurobiology},
  pages = {6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/LS8KLL85/Ito - 2011 - Multiple representations and algorithms for reinfo.pdf}
}

@article{ittiBayesianSurpriseAttracts2009,
  title = {Bayesian Surprise Attracts Human Attention},
  author = {Itti, Laurent and Baldi, Pierre},
  date = {2009},
  journaltitle = {Vision Research},
  pages = {12},
  abstract = {We propose a formal Bayesian definition of surprise to capture subjective aspects of sensory information. Surprise measures how data affects an observer, in terms of differences between posterior and prior beliefs about the world. Only data observations which substantially affect the observer’s beliefs yield surprise, irrespectively of how rare or informative in Shannon’s sense these observations are. We test the framework by quantifying the extent to which humans may orient attention and gaze towards surprising events or items while watching television. To this end, we implement a simple computational model where a low-level, sensory form of surprise is computed by simple simulated early visual neurons. Bayesian surprise is a strong attractor of human attention, with 72\% of all gaze shifts directed towards locations more surprising than the average, a figure rising to 84\% when focusing the analysis onto regions simultaneously selected by all observers. The proposed theory of surprise is applicable across different spatiotemporal scales, modalities, and levels of abstraction.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Q8SCFR35/Itti and Baldi - 2009 - Bayesian surprise attracts human attention.pdf}
}

@article{jaakkolaBayesianParameterEstimation,
  title = {Bayesian Parameter Estimation via Variational Methods},
  author = {Jaakkola, Tommi S and Jordan, Michael I},
  pages = {13},
  abstract = {We consider a logistic regression model with a Gaussian prior distribution over the parameters. We show that an accurate variational transformation can be used to obtain a closed form approximation to the posterior distribution of the parameters thereby yielding an approximate posterior predictive model. This approach is readily extended to binary graphical model with complete observations. For graphical models with incomplete observations we utilize an additional variational transformation and again obtain a closed form approximation to the posterior. Finally, we show that the dual of the regression problem gives a latent variable density model, the variational formulation of which leads to exactly solvable EM updates.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/96PZ2X9X/Jaakkola and Jordan - Bayesian parameter estimation via variational meth.pdf}
}

@article{jaegerCategoricalDataAnalysis2008,
  title = {Categorical Data Analysis: {{Away}} from {{ANOVAs}} (Transformation or Not) and towards Logit Mixed Models},
  shorttitle = {Categorical Data Analysis},
  author = {Jaeger, T. Florian},
  date = {2008-11},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {59},
  number = {4},
  pages = {434--446},
  issn = {0749596X},
  doi = {10.1016/j.jml.2007.11.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X07001337},
  urldate = {2021-05-13},
  abstract = {This paper identifies several serious problems with the widespread use of ANOVAs for the analysis of categorical outcome variables such as forced-choice variables, question-answer accuracy, choice in production (e.g. in syntactic priming research), et cetera. I show that even after applying the arcsine-square-root transformation to proportional data, ANOVA can yield spurious results. I discuss conceptual issues underlying these problems and alternatives provided by modern statistics. Specifically, I introduce ordinary logit models (i.e. logistic regression), which are well-suited to analyze categorical data and offer many advantages over ANOVA. Unfortunately, ordinary logit models do not include random effect modeling. To address this issue, I describe mixed logit models (Generalized Linear Mixed Models for binomially distributed outcomes, Breslow and Clayton [Breslow, N. E. \& Clayton, D. G. (1993). Approximate inference in generalized linear mixed models. Journal of the American Statistical Society 88(421), 9–25]), which combine the advantages of ordinary logit models with the ability to account for random subject and item effects in one step of analysis. Throughout the paper, I use a psycholinguistic data set to compare the different statistical methods.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/S7QP4P9X/Jaeger - 2008 - Categorical data analysis Away from ANOVAs (trans.pdf}
}

@article{jamesDepartmentPsychologyUniversity1984,
  title = {Department of {{Psychology University}} of {{Georgia Athens}}, {{Georgia}} 30602},
  author = {James, W. T.},
  date = {1984-07},
  journaltitle = {The Journal of General Psychology},
  shortjournal = {The Journal of General Psychology},
  volume = {111},
  number = {1},
  pages = {131--152},
  issn = {0022-1309, 1940-0888},
  doi = {10.1080/00221309.1984.9921103},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00221309.1984.9921103},
  urldate = {2021-01-22},
  abstract = {The ability to reflect on one’s own mental processes, termed metacognition, is a defining feature of human existence [1, 2]. Consequently, a fundamental question in comparative cognition is whether nonhuman animals have knowledge of their own cognitive states [3]. Recent evidence suggests that people and nonhuman primates [4–8] but not less ‘‘cognitively sophisticated’’ species [3, 9, 10] are capable of metacognition. Here, we demonstrate for the first time that rats are capable of metacognition—i.e., they know when they do not know the answer in a duration-discrimination test. Before taking the duration test, rats were given the opportunity to decline the test. On other trials, they were not given the option to decline the test. Accurate performance on the duration test yielded a large reward, whereas inaccurate performance resulted in no reward. Declining a test yielded a small but guaranteed reward. If rats possess knowledge regarding whether they know the answer to the test, they would be expected to decline most frequently on difficult tests and show lowest accuracy on difficult tests that cannot be declined [4]. Our data provide evidence for both predictions and suggest that a nonprimate has knowledge of its own cognitive state.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/XSPCDZRZ/James - 1984 - Department of Psychology University of Georgia Ath.pdf}
}

@article{jemstedtWhatModeratesAccuracy,
  title = {What Moderates the Accuracy of Ease of Learning Judgments?},
  author = {Jemstedt, Andreas},
  pages = {19},
  abstract = {When people begin to study new material, they may first judge how difficult it will be to learn. Surprisingly, these ease of learning (EOL) judgments have received little attention by metacognitive researchers so far. The aim of this study was to systematically investigate how well EOL judgments can predict actual learning, and what factors may moderate their relative accuracy. In three experiments, undergraduate psychology students made EOL judgments on, then studied, and were tested on, lists of word-pairs (e.g., sun – warm). In Experiment 1, the Goodman-Kruskal gamma (G) correlations showed that EOL judgments were accurate (G = .74) when items varied enough in difficulty to allow for proper discrimination between them, but were less accurate (G = .21) when variation was smaller. Furthermore, in Experiment 1 and 3, we showed that the relative accuracy was reliably higher when the EOL judgments were correlated with a binary criterion (i.e., if an item was recalled or not on a test), compared with a trials-to-learn criterion (i.e., how many study and test trials were needed to recall an item). In addition, Experiments 2 and 3 indicate other factors to be non-influential for EOL accuracy, such as the task used to measure the EOL judgments, and whether items were judged sequentially (i.e., one item at a time in isolation from the other items) or simultaneously (i.e., each item was judged while having access to all other items). To conclude, EOL judgments can be highly accurate (G = .74) and may thus be of strategic importance for learning. Further avenues for research are discussed.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3N3YYBQB/Jemstedt - What moderates the accuracy of ease of learning ju.pdf;/Users/alexten/Zotero/storage/PMHDAHBG/Jemstedt - What moderates the accuracy of ease of learning ju.pdf}
}

@article{jepmaNeuralMechanismsUnderlying,
  title = {Neural Mechanisms Underlying the Induction and Relief of Perceptual Curiosity},
  author = {Jepma, Marieke},
  journaltitle = {Frontiers in Behavioral Neuroscience},
  pages = {9},
  abstract = {Curiosity is one of the most basic biological drives in both animals and humans, and has been identified as a key motive for learning and discovery. Despite the importance of curiosity and related behaviors, the topic has been largely neglected in human neuroscience; hence little is known about the neurobiological mechanisms underlying curiosity. We used functional magnetic resonance imaging (fMRI) to investigate what happens in our brain during the induction and subsequent relief of perceptual curiosity. Our core findings were that (1) the induction of perceptual curiosity, through the presentation of ambiguous visual input, activated the anterior insula and anterior cingulate cortex (ACC), brain regions sensitive to conflict and arousal; (2) the relief of perceptual curiosity, through visual disambiguation, activated regions of the striatum that have been related to reward processing; and (3) the relief of perceptual curiosity was associated with hippocampal activation and enhanced incidental memory. These findings provide the first demonstration of the neural basis of human perceptual curiosity. Our results provide neurobiological support for a classic psychological theory of curiosity, which holds that curiosity is an aversive condition of increased arousal whose termination is rewarding and facilitates memory.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/934DVRLK/Jepma - Neural mechanisms underlying the induction and rel.pdf}
}

@article{jepmaNeuralMechanismsUnderlyinga,
  title = {Neural Mechanisms Underlying the Induction and Relief of Perceptual Curiosity},
  author = {Jepma, Marieke},
  journaltitle = {Frontiers in Behavioral Neuroscience},
  pages = {9},
  abstract = {Curiosity is one of the most basic biological drives in both animals and humans, and has been identified as a key motive for learning and discovery. Despite the importance of curiosity and related behaviors, the topic has been largely neglected in human neuroscience; hence little is known about the neurobiological mechanisms underlying curiosity. We used functional magnetic resonance imaging (fMRI) to investigate what happens in our brain during the induction and subsequent relief of perceptual curiosity. Our core findings were that (1) the induction of perceptual curiosity, through the presentation of ambiguous visual input, activated the anterior insula and anterior cingulate cortex (ACC), brain regions sensitive to conflict and arousal; (2) the relief of perceptual curiosity, through visual disambiguation, activated regions of the striatum that have been related to reward processing; and (3) the relief of perceptual curiosity was associated with hippocampal activation and enhanced incidental memory. These findings provide the first demonstration of the neural basis of human perceptual curiosity. Our results provide neurobiological support for a classic psychological theory of curiosity, which holds that curiosity is an aversive condition of increased arousal whose termination is rewarding and facilitates memory.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IW3I84AK/Jepma - Neural mechanisms underlying the induction and rel.pdf}
}

@article{jepmaPupilDiameterPredicts,
  title = {Pupil {{Diameter Predicts Changes}} in the {{ExplorationExploitation Trade}}-off: {{Evidence}} for the {{Adaptive Gain Theory}}},
  author = {Jepma, Marieke and Nieuwenhuis, Sander},
  volume = {23},
  number = {7},
  pages = {10},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/RJVXRXG3/Jepma and Nieuwenhuis - Pupil Diameter Predicts Changes in the Exploration.pdf}
}

@article{jepmaPupilDiameterPredictsa,
  title = {Pupil {{Diameter Predicts Changes}} in the {{ExplorationExploitation Trade}}-off: {{Evidence}} for the {{Adaptive Gain Theory}}},
  author = {Jepma, Marieke and Nieuwenhuis, Sander},
  volume = {23},
  number = {7},
  pages = {10},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/LJ6M9XUU/Jepma and Nieuwenhuis - Pupil Diameter Predicts Changes in the Exploration.pdf}
}

@article{jersakovaUnderstandingMetacognitiveConfidence2017,
  title = {Understanding Metacognitive Confidence: {{Insights}} from Judgment-of-Learning Justifications},
  author = {Jersakova, Radka},
  date = {2017},
  journaltitle = {Journal of Memory and Language},
  pages = {21},
  abstract = {This study employed the delayed judgment-of-learning (JOL) paradigm to investigate the content of metacognitive judgments; after studying cue-target word-pairs, participants predicted their ability to remember targets on a future memory test (cued recognition in Experiments 1 and 2 and cued recall in Experiment 3). In Experiment 1 and the confidence JOL group of Experiment 3, participants used a commonly employed 6-point numeric confidence JOL scale (0–20–40–60–80–100\%). In Experiment 2 and the binary JOL group of Experiment 3 participants first made a binary yes/no JOL prediction followed by a 3-point verbal confidence judgment (sure-maybe-guess). In all experiments, on a subset of trials, participants gave a written justification of why they gave that specific JOL response. We used natural language processing techniques (latent semantic analysis and word frequency [n-gram] analysis) to characterize the content of the written justifications and to capture what types of evidence evaluation uniquely separate one JOL response type from others. We also used a machine learning classification algorithm (support vector machine [SVM]) to quantify the extent to which any two JOL responses differed from each other. We found that: (i) participants can justify and explain their JOLs; (ii) these justifications reference cue familiarity and target accessibility and so are particularly consistent with the two-stage metacognitive model; and (iii) JOL confidence judgements do not correspond to yes/no responses in the manner typically assumed within the literature (i.e. 0–40\% interpreted as no predictions).},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EQ5MDATV/Jersakova - 2017 - Understanding metacognitive confidence Insights f.pdf}
}

@article{jersakovaUnderstandingMetacognitiveConfidence2017a,
  title = {Understanding Metacognitive Confidence: {{Insights}} from Judgment-of-Learning Justifications},
  shorttitle = {Understanding Metacognitive Confidence},
  author = {Jersakova, Radka and Allen, Richard J. and Booth, Jonathan and Souchay, Céline and O'Connor, Akira R.},
  date = {2017-12},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {97},
  pages = {187--207},
  issn = {0749596X},
  doi = {10.1016/j.jml.2017.08.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X17300608},
  urldate = {2021-01-22},
  abstract = {This study employed the delayed judgment-of-learning (JOL) paradigm to investigate the content of metacognitive judgments; after studying cue-target word-pairs, participants predicted their ability to remember targets on a future memory test (cued recognition in Experiments 1 and 2 and cued recall in Experiment 3). In Experiment 1 and the confidence JOL group of Experiment 3, participants used a commonly employed 6-point numeric confidence JOL scale (0–20–40–60–80–100\%). In Experiment 2 and the binary JOL group of Experiment 3 participants first made a binary yes/no JOL prediction followed by a 3-point verbal confidence judgment (sure-maybe-guess). In all experiments, on a subset of trials, participants gave a written justification of why they gave that specific JOL response. We used natural language processing techniques (latent semantic analysis and word frequency [n-gram] analysis) to characterize the content of the written justifications and to capture what types of evidence evaluation uniquely separate one JOL response type from others. We also used a machine learning classification algorithm (support vector machine [SVM]) to quantify the extent to which any two JOL responses differed from each other. We found that: (i) participants can justify and explain their JOLs; (ii) these justifications reference cue familiarity and target accessibility and so are particularly consistent with the two-stage metacognitive model; and (iii) JOL confidence judgements do not correspond to yes/no responses in the manner typically assumed within the literature (i.e. 0–40\% interpreted as no predictions).},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DSXN23YS/Jersakova et al. - 2017 - Understanding metacognitive confidence Insights f.pdf}
}

@article{jiroutCuriosityDevelopmentQuestion,
  title = {Curiosity and the {{Development}} of {{Question Generation Skills}}},
  author = {Jirout, Jamie J},
  pages = {4},
  abstract = {The current study investigates the relationship between children’s curiosity and question asking ability. Generation of two types of questions was assessed: identification (yes/no questions asked to identify a target from an array) and understanding questions, asked to learn more about a topic. The latter was related to children’s curiosity, as was the ability to recognize the effectiveness of questions in solving a mystery. Training on asking identification questions was effective in improving children’s ability to ask that type of question, but did not transfer to the other task. Training on asking understanding questions was not successful. Children’s curiosity did not influence the effectiveness of the training.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GCNJ87AI/Jirout - Curiosity and the Development of Question Generati.pdf;/Users/alexten/Zotero/storage/MC47GV8J/Jirout - Curiosity and the Development of Question Generati.pdf}
}

@article{kableNeurobiologyDecisionConsensus,
  title = {The {{Neurobiology}} of {{Decision}}: {{Consensus}} and {{Controversy}}},
  author = {Kable, Joseph W and Glimcher, Paul W},
  pages = {13},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/X7MMZ7DS/Kable and Glimcher - The Neurobiology of Decision Consensus and Contro.pdf}
}

@article{kableNeurobiologyDecisionConsensus2009,
  title = {The {{Neurobiology}} of {{Decision}}: {{Consensus}} and {{Controversy}}},
  shorttitle = {The {{Neurobiology}} of {{Decision}}},
  author = {Kable, Joseph W. and Glimcher, Paul W.},
  date = {2009-09},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {63},
  number = {6},
  pages = {733--745},
  issn = {08966273},
  doi = {10.1016/j.neuron.2009.09.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627309006813},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2WUQVKYJ/Kable and Glimcher - 2009 - The Neurobiology of Decision Consensus and Contro.pdf}
}

@article{kahnemanCopyrightThisArticle,
  title = {The Copyright to This Article Is Held by the {{Econometric Society}}, {{http://www}}},
  author = {Kahneman, Daniel and Tversky, Amos},
  pages = {30},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DX8HUYXF/Kahneman and Tversky - The copyright to this article is held by the Econo.pdf}
}

@article{kakadeDopamineBonuses,
  title = {Dopamine {{Bonuses}}},
  author = {Kakade, Sham and Dayan, Peter},
  pages = {7},
  abstract = {Substantial data support a temporal difference (TO) model of dopamine (OA) neuron activity in which the cells provide a global error signal for reinforcement learning. However, in certain circumstances, OA activity seems anomalous under the TO model, responding to non-rewarding stimuli. We address these anomalies by suggesting that OA cells multiplex information about reward bonuses, including Sutton's exploration bonuses and Ng et al's non-distorting shaping bonuses. We interpret this additional role for OA in terms of the unconditional attentional and psychomotor effects of dopamine, having the computational role of guiding exploration.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4HFQ72ZX/Kakade and Dayan - Dopamine Bonuses.pdf;/Users/alexten/Zotero/storage/H7GC96KC/Kakade and Dayan - Dopamine Bonuses.pdf}
}

@article{kakadeDopamineGeneralizationBonuses2002,
  title = {Dopamine: Generalization and Bonuses},
  shorttitle = {Dopamine},
  author = {Kakade, Sham and Dayan, Peter},
  date = {2002-06},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {15},
  number = {4-6},
  pages = {549--559},
  issn = {08936080},
  doi = {10.1016/S0893-6080(02)00048-5},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608002000485},
  urldate = {2021-01-22},
  abstract = {In the temporal difference model of primate dopamine neurons, their phasic activity reports a prediction error for future reward. This model is supported by a wealth of experimental data. However, in certain circumstances, the activity of the dopamine cells seems anomalous under the model, as they respond in particular ways to stimuli that are not obviously related to predictions of reward. In this paper, we address two important sets of anomalies, those having to do with generalization and novelty. Generalization responses are treated as the natural consequence of partial information; novelty responses are treated by the suggestion that dopamine cells multiplex information about reward bonuses, including exploration bonuses and shaping bonuses. We interpret this additional role for dopamine in terms of the mechanistic attentional and psychomotor effects of dopamine, having the computational role of guiding exploration. q 2002 Published by Elsevier Science Ltd.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DECFRYYZ/Kakade and Dayan - 2002 - Dopamine generalization and bonuses.pdf;/Users/alexten/Zotero/storage/LVBTG9XZ/Kakade and Dayan - 2002 - Dopamine generalization and bonuses.pdf}
}

@article{kangWickCandleLearning,
  title = {The {{Wick}} in the {{Candle}} of {{Learning}}},
  author = {Kang, Min Jeong and Hsu, Ming and Krajbich, Ian M and Loewenstein, George and McClure, Samuel M and Wang, Joseph Tao-yi and Camerer, Colin F},
  journaltitle = {2009},
  volume = {20},
  number = {8},
  pages = {12},
  abstract = {Curiosity has been described as a desire for learning and knowledge, but its underlying mechanisms are not well understood. We scanned subjects with functional magnetic resonance imaging while they read trivia questions. The level of curiosity when reading questions was correlated with activity in caudate regions previously suggested to be involved in anticipated reward. This finding led to a behavioral study, which showed that subjects spent more scarce resources (either limited tokens or waiting time) to find out answers when they were more curious. The functional imaging also showed that curiosity increased activity in memory areas when subjects guessed incorrectly, which suggests that curiosity may enhance memory for surprising new information. This prediction about memory enhancement was confirmed in a behavioral study: Higher curiosity in an initial session was correlated with better recall of surprising answers 1 to 2 weeks later.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JTW5ACCT/Kang et al. - The Wick in the Candle of Learning.pdf}
}

@article{karmiloff-smithPrecisModularityDevelopmental1994,
  title = {Precis of {{Beyond}} Modularity: {{A}} Developmental Perspective on Cognitive Science},
  author = {Karmiloff-Smith, Annette},
  date = {1994},
  journaltitle = {BEHAVIORAL AND BRAIN SCIENCES},
  pages = {15},
  abstract = {Beyond modularity attempts a synthesis of Fodor's anticonstructivist nativism and Piaget's antinativist constructivism. Contra Fodor, I argue that: (1) the study of cognitive development is essential to cognitive science, (2) the module/central processing dichotomy is too rigid, and (3) the mind does not begin with prespecified modules; rather, development involves a gradual process of "modularization." Contra Piaget, I argue that: (1) development rarely involves stagelike domain-general change and (2) domainspecific predispositions give development a small but significant kickstart by focusing the infant's attention on proprietary inputs. Development does not stop at efficient learning. A fundamental aspect of human development ("representational redescription") is the hypothesized process by which information that is in a cognitive system becomes progressively explicit knowledge to that system. Development thus involves two complementary processes of progressive modularization and progressive "explicitation." Empirical findings on the child as linguist, physicist, mathematician, psychologist, and notator are discussed in support of the theoretical framework. Each chapter concentrates first on the initial state of the infant mind/brain and on subsequent domain-specific learning in infancy and early childhood. It then goes on to explore data on older children's problem solving and theory building, with particular focus on evolving cognitive flexibility. Emphasis is placed throughout on the status of representations underlying different capacities and on the multiple levels at which knowledge is stored and accessible. Finally, consideration is given to the need for more formal developmental models, and a comparison is made between representational redescription and connectionist simulations of development. In conclusion, I consider what is special about human cognition by speculating on the status of representations underlying the structure of behavior in other species.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/XB6WBSK7/Karmiloff-Smith - 1994 - Precis of Beyond modularity A developmental persp.pdf}
}

@article{katahiraRelationReinforcementLearning2015,
  title = {The Relation between Reinforcement Learning Parameters and the Influence of Reinforcement History on Choice Behavior},
  author = {Katahira, Kentaro},
  date = {2015},
  journaltitle = {Journal of Mathematical Psychology},
  pages = {11},
  abstract = {Reinforcement learning (RL) models have been widely used to analyze the choice behavior of humans and other animals in a broad range of fields, including psychology and neuroscience. Linear regressionbased models that explicitly represent how reward and choice history influences future choices have also been used to model choice behavior. While both approaches have been used independently, the relation between the two models has not been explicitly described. The aim of the present study is to describe this relation and investigate how the parameters in the RL model mediate the effects of reward and choice history on future choices. To achieve these aims, we performed analytical calculations and numerical simulations. First, we describe a special case in which the RL and regression models can provide equivalent predictions of future choices. The general properties of the RL model are discussed as a departure from this special case. We clarify the role of the RL-model parameters, specifically, the learning rate, inverse temperature, and outcome value (also referred to as the reward value, reward sensitivity, or motivational value), in the formation of history dependence.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9ABVHQKM/Katahira - 2015 - The relation between reinforcement learning parame.pdf}
}

@article{kesslerChoosingSwitchSpontaneous2009,
  title = {Choosing to Switch: {{Spontaneous}} Task Switching despite Associated Behavioral Costs},
  author = {Kessler, Yoav and Shencar, Yael and Meiran, Nachshon},
  date = {2009},
  journaltitle = {Acta Psychologica},
  pages = {9},
  abstract = {The literature shows that switching among simple cognitive tasks is difficult and involves a performance cost. Accordingly, cost-benefit considerations seem to predict that task switching would not occur spontaneously. Here we show that spontaneous task switching is a robust phenomenon, despite its costs. In Experiment 1, participants had to judge shapes according to one of three possible dimensions. Importantly, they were given the option to choose another relevant dimension or let the computer program change the dimension for them, but only if they wanted to do so. The results showed that spontaneous task switching was prevalent, despite robust switching costs. Experiment 2 extended this finding in showing spontaneous switching from an easy task to a more difficult task. The authors provide two possible explanations for the phenomenon that posit that spontaneous switching may be unpreventable or even advantageous.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/AAJHH6BH/Kessler et al. - 2009 - Choosing to switch Spontaneous task switching des.pdf;/Users/alexten/Zotero/storage/MWWTLJW3/Kessler et al. - 2009 - Choosing to switch Spontaneous task switching des.pdf}
}

@article{kianiRepresentationConfidenceAssociated2009,
  title = {Representation of {{Confidence Associated}} with a {{Decision}} by {{Neurons}} in the {{Parietal Cortex}}},
  author = {Kiani, Roozbeh and Shadlen, Michael N},
  date = {2009},
  volume = {324},
  pages = {17},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7HTQHJHP/Kiani and Shadlen - 2009 - Representation of Confidence Associated with a Dec.pdf}
}

@article{kiddGoldilocksEffectHuman2012a,
  title = {The {{Goldilocks Effect}}: {{Human Infants Allocate Attention}} to {{Visual Sequences That Are Neither Too Simple Nor Too Complex}}},
  shorttitle = {The {{Goldilocks Effect}}},
  author = {Kidd, Celeste and Piantadosi, Steven T. and Aslin, Richard N.},
  editor = {Rodriguez-Fornells, Antoni},
  date = {2012-05-23},
  journaltitle = {PLoS ONE},
  shortjournal = {PLoS ONE},
  volume = {7},
  number = {5},
  pages = {e36399},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0036399},
  url = {https://dx.plos.org/10.1371/journal.pone.0036399},
  urldate = {2021-01-22},
  abstract = {Human infants, like immature members of any species, must be highly selective in sampling information from their environment to learn efficiently. Failure to be selective would waste precious computational resources on material that is already known (too simple) or unknowable (too complex). In two experiments with 7- and 8-month-olds, we measure infants’ visual attention to sequences of events varying in complexity, as determined by an ideal learner model. Infants’ probability of looking away was greatest on stimulus items whose complexity (negative log probability) according to the model was either very low or very high. These results suggest a principle of infant attention that may have broad applicability: infants implicitly seek to maintain intermediate rates of information absorption and avoid wasting cognitive resources on overly simple or overly complex events.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9AQBTWGD/Kidd et al. - 2012 - The Goldilocks Effect Human Infants Allocate Atte.PDF}
}

@article{kiddPsychologyNeuroscienceCuriosity2015,
  title = {The {{Psychology}} and {{Neuroscience}} of {{Curiosity}}},
  author = {Kidd, Celeste and Hayden, Benjamin Y.},
  date = {2015-11},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {88},
  number = {3},
  pages = {449--460},
  issn = {08966273},
  doi = {10.1016/j.neuron.2015.09.010},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315007679},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CIXB536W/Kidd and Hayden - 2015 - The Psychology and Neuroscience of Curiosity.pdf}
}

@article{kileenStatisticalInferenceDecision2006,
  title = {Beyond Statistical Inference: {{A}} Decision Theory for Science},
  shorttitle = {Beyond Statistical Inference},
  author = {Kileen, Peter R.},
  date = {2006-08},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychonomic Bulletin \& Review},
  volume = {13},
  number = {4},
  pages = {549--562},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03193962},
  url = {http://link.springer.com/10.3758/BF03193962},
  urldate = {2021-01-22},
  abstract = {Traditional null hypothesis significance testing does not yield the probability of the null or its alternative and, therefore, cannot logically ground scientific decisions. The decision theory proposed here calculates the expected utility of an effect on the basis of (1) the probability of replicating it and (2) a utility function on its size. It takes significance tests—which place all value on the replicability of an effect and none on its magnitude—as a special case, one in which the cost of a false positive is revealed to be an order of magnitude greater than the value of a true positive. More realistic utility functions credit both replicability and effect size, integrating them for a single index of merit. The analysis incorporates opportunity cost and is consistent with alternate measures of effect size, such as r2 and information transmission, and with Bayesian model selection criteria. An alternate formulation is functionally equivalent to the formal theory, transparent, and easy to compute.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9RCTW4KA/Kileen - 2006 - Beyond statistical inference A decision theory fo.pdf}
}

@article{killeenStatisticalInferenceDecision2008,
  title = {Beyond Statistical Inference: {{A}} Decision Theory for Science},
  author = {Killeen, Peter R},
  date = {2008},
  pages = {27},
  abstract = {Traditional null hypothesis significance testing does not yield the probability of the null or its alternative and, therefore, cannot logically ground scientific decisions. The decision theory proposed here calculates the expected utility of an effect on the basis of (1) the probability of replicating it and (2) a utility function on its size. It takes significance tests—which place all value on the replicability of an effect and none on its magnitude—as a special case, one in which the cost of a false positive is revealed to be an order of magnitude greater than the value of a true positive. More realistic utility functions credit both replicability and effect size, integrating them for a single index of merit. The analysis incorporates opportunity cost and is consistent with alternate measures of effect size, such as r2 and information transmission, and with Bayesian model selection criteria. An alternate formulation is functionally equivalent to the formal theory, transparent, and easy to compute.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MFRR8WRV/Killeen - 2008 - Beyond statistical inference A decision theory fo.pdf}
}

@article{kimMobileGamerEpistemic2017a,
  title = {Mobile Gamer's Epistemic Curiosity Affecting Continuous Play Intention. {{Focused}} on Players' Switching Costs and Epistemic Curiosity},
  author = {Kim, Young-Berm and Lee, Sang-Ho},
  date = {2017-12},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {77},
  pages = {32--46},
  issn = {07475632},
  doi = {10.1016/j.chb.2017.08.023},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0747563217304880},
  urldate = {2021-01-22},
  abstract = {Thanks to the proliferation of smartphones, most people can access mobile game easily. But they play it very differently. This research focus on the gamer's attributes, not the game attributes as the cause of the behavioral difference. Authors suggested a research model in which perceptual game switching costs precede the continuous play intention, and personal attributes affect also the switching costs and the intention at the same time. To test the model and the research hypotheses, authors used the structural equation modeling method and multiple linear regression analysis. As results, the personal I-typed, and D-typed epistemic curiosity could account for gamers' perceptual switching costs and the play intent well. The continuity cost and the sunk cost positively affected the retention intent, but there was no significant effect from learning cost. Focusing the gamer into as the male gamer, the learning cost was significant but negatively to the intent. Gamer group in high I-typed and low D-typed curiosity showed the highest retention intent, and the lowest retention intent took place in the group of low I-typed and high D-typed. The combinations of epistemic curiosity gave new insights on the playing intent for mobile game. The personal epistemic curiosity is an effective instrument for building a consumer clustering framework for mobile gamer.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/W6V4VHDI/Kim and Lee - 2017 - Mobile gamer's epistemic curiosity affecting conti.pdf}
}

@article{kobayashiCommonNeuralCode,
  title = {Common Neural Code for Reward and Information Value},
  author = {Kobayashi, Kenji and Hsu, Ming},
  journaltitle = {COGNITIVE SCIENCES},
  pages = {6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4NY5BRSE/Kobayashi and Hsu - Common neural code for reward and information valu.pdf;/Users/alexten/Zotero/storage/MW4J38ZK/Kobayashi and Hsu - Common neural code for reward and information valu.pdf}
}

@article{kobayashiDiverseMotivesHuman,
  title = {Diverse Motives for Human Curiosity},
  author = {Kobayashi, Kenji and Ravaioli, Silvio and Baranès, Adrien and Woodford, Michael and Gottlieb, Jacqueline},
  journaltitle = {Nature Human Behaviour},
  pages = {12},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4TS3KH8A/Kobayashi et al. - Diverse motives for human curiosity.pdf}
}

@article{kolaricInformationSeekingBehavior2016,
  title = {Information Seeking Behavior for Decision Making in Everyday Life: A Pilot Study on Adolescents},
  author = {Kolarić, Alica and Stričević, Ivanka},
  date = {2016},
  pages = {34},
  abstract = {The pilot study investigates adolescents’ information-seeking behavior for decision-making purposes. The aim of the study is to explore adolescents’ information-seeking behavior in everyday life decision-making situations. In this research we use a survey method with a questionnaire comprised of hypothetical decision-making situations which allows respondents to elaborate on their answers. The research aims to reveal whether adolescents engage in deliberate information seeking when facing everyday life decisions and if so, which information sources they use. Moreover, the research explores the importance attached by adolescents to information in making decisions. In addition, the results will be used for developing a methodology for a large-scale research project.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9QYMIWMA/Kolarić and Stričević - 2016 - Information seeking behavior for decision making i.pdf;/Users/alexten/Zotero/storage/RMC6C3BU/Kolarić and Stričević - 2016 - Information seeking behavior for decision making i.pdf}
}

@article{koolLaborLeisureTradeoff,
  title = {A {{Labor}}/{{Leisure Tradeoff}} in {{Cognitive Control}}},
  author = {Kool, Wouter and Botvinick, Matthew},
  pages = {12},
  abstract = {Daily life frequently offers a choice between activities that are profitable but mentally demanding (cognitive labor) and activities that are undemanding but also unproductive (cognitive leisure). Although such decisions are often implicit, they help determine academic performance, career trajectories, and even health outcomes. Previous research has shed light both on the executive control functions that ultimately define cognitive labor and on a “default mode” of brain function that accompanies cognitive leisure. However, little is known about how labor/leisure decisions are actually made. Here, we identify a central principle guiding such decisions. Results from 3 economic-choice experiments indicate that the motivation underlying cognitive labor/leisure decision making is to strike an optimal balance between income and leisure, as given by a joint utility function. The results reported establish a new connection between microeconomics and research on executive function. They also suggest a new interpretation of so-called ego-depletion effects and a potential new approach to such phenomena as mind wandering and self-control failure.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PVM8LBX8/Kool and Botvinick - A LaborLeisure Tradeoff in Cognitive Control.pdf}
}

@article{koriatConstructionAttitudinalJudgments,
  title = {The {{Construction}} of {{Attitudinal Judgments}}: {{Evidence}} from {{Attitude Certainty}} and {{Response Latency}}},
  author = {Koriat, Asher and Adiv, Shiri},
  pages = {35},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7YLWU8V6/Koriat and Adiv - The Construction of Attitudinal Judgments Evidenc.pdf}
}

@article{koriatConstructionAttitudinalJudgments2011,
  title = {The {{Construction}} of {{Attitudinal Judgments}}: {{Evidence}} from {{Attitude Certainty}} and {{Response Latency}}},
  shorttitle = {The {{Construction}} of {{Attitudinal Judgments}}},
  author = {Koriat, Asher and Adiv, Shiri},
  date = {2011-10},
  journaltitle = {Social Cognition},
  shortjournal = {Social Cognition},
  volume = {29},
  number = {5},
  pages = {577--611},
  issn = {0278-016X},
  doi = {10.1521/soco.2011.29.5.577},
  url = {http://guilfordjournals.com/doi/10.1521/soco.2011.29.5.577},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FQSMJE6J/Koriat and Adiv - 2011 - The Construction of Attitudinal Judgments Evidenc.pdf}
}

@article{koriatConstructionCategoryMembership,
  title = {The {{Construction}} of {{Category Membership Judgments}}: {{Towards}} a {{Distributed Model}}},
  author = {Koriat, Asher and Sorka, Hila},
  pages = {22},
  abstract = {The classification of objects to natural categories displays a great deal of crossperson consensus and within-person consistency. At the same time, categorization also exhibits some degree of within-person instability and cross-person variability.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GQMJ4ZWZ/Koriat and Sorka - The Construction of Category Membership Judgments.pdf}
}

@incollection{koriatConstructionCategoryMembership2017,
  title = {The {{Construction}} of {{Category Membership Judgments}}},
  booktitle = {Handbook of {{Categorization}} in {{Cognitive Science}}},
  author = {Koriat, Asher and Sorka, Hila},
  date = {2017},
  pages = {773--794},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-08-101107-2.00031-2},
  url = {https://linkinghub.elsevier.com/retrieve/pii/B9780081011072000312},
  urldate = {2021-01-22},
  abstract = {The classification of objects to natural categories displays a great deal of crossperson consensus and within-person consistency. At the same time, categorization also exhibits some degree of within-person instability and cross-person variability.},
  isbn = {978-0-08-101107-2},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6KJDZZW7/Koriat and Sorka - 2017 - The Construction of Category Membership Judgments.pdf}
}

@article{koriatEVectsEncodingXuency2005,
  title = {The {{eVects}} of Encoding {{Xuency}} and Retrieval {{Xuency}} on Judgments of Learning ଝ},
  author = {Koriat, Asher and Ma’ayan, Hilit},
  date = {2005},
  journaltitle = {Journal of Memory and Language},
  pages = {15},
  abstract = {This study investigated the heuristic bases of judgments of learning (JOLs). JOLs were elicited either immediately after study or after a shorter or longer delay. In Experiment 1, the eVects of encoding Xuency (inferred from self-paced study time) on both JOLs and recall decreased with JOL delay, whereas those of retrieval Xuency (inferred from the success and latency of pre-JOL retrieval) increased. In this experiment, JOLs (as well as recall) decreased with increasing study time, presumably under the heuristic that items requiring more time to study are less likely to be recalled. In contrast, in Experiment 2, in which study time was experimentally manipulated, JOLs as well as recall actually increased with study time. In both experiments JOLs increased with retrieval Xuency. The results demonstrate that JOLs are based on the Xexible and adaptive utilization of diVerent mnemonic cues according to their relative validity in predicting memory performance.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6TB8ALK9/Koriat and Ma’ayan - 2005 - The eVects of encoding Xuency and retrieval Xuency.pdf}
}

@article{koriatEVectsEncodingXuency2005a,
  title = {The {{eVects}} of Encoding {{Xuency}} and Retrieval {{Xuency}} on Judgments of Learning ଝ},
  author = {Koriat, Asher and Ma’ayan, Hilit},
  date = {2005},
  journaltitle = {Journal of Memory and Language},
  pages = {15},
  abstract = {This study investigated the heuristic bases of judgments of learning (JOLs). JOLs were elicited either immediately after study or after a shorter or longer delay. In Experiment 1, the eVects of encoding Xuency (inferred from self-paced study time) on both JOLs and recall decreased with JOL delay, whereas those of retrieval Xuency (inferred from the success and latency of pre-JOL retrieval) increased. In this experiment, JOLs (as well as recall) decreased with increasing study time, presumably under the heuristic that items requiring more time to study are less likely to be recalled. In contrast, in Experiment 2, in which study time was experimentally manipulated, JOLs as well as recall actually increased with study time. In both experiments JOLs increased with retrieval Xuency. The results demonstrate that JOLs are based on the Xexible and adaptive utilization of diVerent mnemonic cues according to their relative validity in predicting memory performance.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3RCVP7NJ/Koriat and Ma’ayan - 2005 - The eVects of encoding Xuency and retrieval Xuency.pdf}
}

@article{koriatHowWeKnow,
  title = {How {{Do We Know That We Know}}? {{The Accessibility Model}} of the {{Feeling}} of {{Knowing}}},
  author = {Koriat, Asher},
  pages = {32},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QIBGD5RC/Koriat - How Do We Know That We Know The Accessibility Mod.pdf}
}

@incollection{koriatMetacognitionDecisionMaking2015,
  title = {Metacognition: {{Decision}} Making {{Processes}} in {{Self}}-Monitoring and {{Self}}-Regulation},
  shorttitle = {Metacognition},
  booktitle = {The {{Wiley Blackwell Handbook}} of {{Judgment}} and {{Decision Making}}},
  author = {Koriat, Asher},
  editor = {Keren, Gideon and Wu, George},
  date = {2015-12-18},
  pages = {356--379},
  publisher = {{John Wiley \& Sons, Ltd}},
  location = {{Chichester, UK}},
  doi = {10.1002/9781118468333.ch12},
  url = {http://doi.wiley.com/10.1002/9781118468333.ch12},
  urldate = {2021-01-22},
  isbn = {978-1-118-46833-3 978-1-118-46839-5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DH8XTLQS/Koriat - 2015 - Metacognition Decision making Processes in Self-m.pdf}
}

@article{koriatMetacognitionDecisionmakingProcesses,
  title = {Metacognition: {{Decision}}-Making Processes in Self-Monitoring},
  author = {Koriat, Asher},
  pages = {41},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/I5QEAZE6/Koriat - Metacognition Decision-making processes in self-m.pdf}
}

@article{koriatPredictingOneOwn,
  title = {Predicting {{One}}’s {{Own Forgetting}}: {{The Role}} of {{Experience}}-{{Based}} and {{Theory}}-{{Based Processes}}},
  author = {Koriat, Asher and Bjork, Robert A and Sheffer, Limor and Bar, Sarah K},
  pages = {14},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BDQLUSTJ/Koriat et al. - Predicting One’s Own Forgetting The Role of Exper.pdf}
}

@article{koriatPredictingOneOwna,
  title = {Predicting {{One}}’s {{Own Forgetting}}: {{The Role}} of {{Experience}}-{{Based}} and {{Theory}}-{{Based Processes}}},
  author = {Koriat, Asher and Bjork, Robert A and Sheffer, Limor and Bar, Sarah K},
  pages = {14},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8QS4UKC8/Koriat et al. - Predicting One’s Own Forgetting The Role of Exper.pdf}
}

@article{koriatSelfconsistencyModelSubjective2012,
  title = {The Self-Consistency Model of Subjective Confidence.},
  author = {Koriat, Asher},
  date = {2012-01},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {119},
  number = {1},
  pages = {80--113},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/a0025648},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0025648},
  urldate = {2021-01-22},
  abstract = {How do people monitor the correctness of their answers? A self-consistency model is proposed for the process underlying confidence judgments and their accuracy. In answering a 2-alternative question, participants are assumed to retrieve a sample of representations of the question and base their confidence on the consistency with which the chosen answer is supported across representations. Confidence is modeled by analogy to the calculation of statistical level of confidence (SLC) in testing hypotheses about a population and represents the participant’s assessment of the likelihood that a new sample will yield the same choice. Assuming that participants draw representations from a commonly shared item-specific population of representations, predictions were derived regarding the function relating confidence to inter-participant consensus and intra-participant consistency for the more preferred (majority) and the less preferred (minority) choices. The predicted pattern was confirmed for several different tasks. The confidence–accuracy relationship was shown to be a by-product of the consistency– correctness relationship: It is positive because the answers that are consistently chosen are generally correct, but negative when the wrong answers tend to be favored. The overconfidence bias stems from the reliability–validity discrepancy: Confidence monitors reliability (or self-consistency), but its accuracy is evaluated in calibration studies against correctness. Simulation and empirical results suggest that response speed is a frugal cue for self-consistency, and its validity depends on the validity of self-consistency in predicting performance. Another mnemonic cue—accessibility, which is the overall amount of information that comes to mind—makes an added, independent contribution. Self-consistency and accessibility may correspond to the 2 parameters that affect SLC: sample variance and sample size.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NEGSLK53/Koriat - 2012 - The self-consistency model of subjective confidenc.pdf}
}

@article{koriatSelfConsistencyModelSubjective2015,
  title = {The {{Self}}-{{Consistency Model}} of {{Subjective Confidence}}},
  author = {Koriat, Asher},
  date = {2015},
  pages = {34},
  abstract = {How do people monitor the correctness of their answers? A self-consistency model is proposed for the process underlying confidence judgments and their accuracy. In answering a 2-alternative question, participants are assumed to retrieve a sample of representations of the question and base their confidence on the consistency with which the chosen answer is supported across representations. Confidence is modeled by analogy to the calculation of statistical level of confidence (SLC) in testing hypotheses about a population and represents the participant’s assessment of the likelihood that a new sample will yield the same choice. Assuming that participants draw representations from a commonly shared item-specific population of representations, predictions were derived regarding the function relating confidence to inter-participant consensus and intra-participant consistency for the more preferred (majority) and the less preferred (minority) choices. The predicted pattern was confirmed for several different tasks. The confidence–accuracy relationship was shown to be a by-product of the consistency– correctness relationship: It is positive because the answers that are consistently chosen are generally correct, but negative when the wrong answers tend to be favored. The overconfidence bias stems from the reliability–validity discrepancy: Confidence monitors reliability (or self-consistency), but its accuracy is evaluated in calibration studies against correctness. Simulation and empirical results suggest that response speed is a frugal cue for self-consistency, and its validity depends on the validity of self-consistency in predicting performance. Another mnemonic cue—accessibility, which is the overall amount of information that comes to mind—makes an added, independent contribution. Self-consistency and accessibility may correspond to the 2 parameters that affect SLC: sample variance and sample size.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/L33J5254/Koriat - The Self-Consistency Model of Subjective Confidenc.pdf}
}

@book{koriatSelfConsistencyTheorySubjective2015,
  title = {The {{Self}}-{{Consistency Theory}} of {{Subjective Confidence}}},
  author = {Koriat, Asher and Adiv, Shiri},
  editor = {Dunlosky, John and Tauber, Sarah (Uma) K.},
  date = {2015-06-09},
  volume = {1},
  publisher = {{Oxford University Press}},
  doi = {10.1093/oxfordhb/9780199336746.013.18},
  url = {http://oxfordhandbooks.com/view/10.1093/oxfordhb/9780199336746.001.0001/oxfordhb-9780199336746-e-18},
  urldate = {2021-01-22},
  abstract = {Innumerable studies have yielded a positive correlation between subjective confidence and accuracy, suggesting that people are skillful in discriminating between correct and wrong answers. The chapter reviews evidence from different domains indicating that people’s subjective confidence in an answer is diagnostic of the consensuality of the answer rather than of its accuracy. A self-consistency model (SCM) was proposed to explain why the confidence-accuracy correlation is positive when the correct answer is the consensually chosen answer but is negative when the wrong answer is the consensual answer. Several results that were obtained across a variety of tasks provided support for the generality of the theoretical framework underlying SCM.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5DPHRF49/Koriat and Adiv - 2015 - The Self-Consistency Theory of Subjective Confiden.pdf}
}

@article{koriatSubjectiveConfidenceOne,
  title = {Subjective {{Confidence}} in {{One}}’s {{Answers}}: {{The Consensuality Principle}}},
  author = {Koriat, Asher},
  pages = {15},
  abstract = {In answering general-information questions, a within-person confidence–accuracy (C-A) correlation is typically observed, suggesting that people can monitor the correctness of their knowledge. However, because the correct answer is generally the consensual answer—the one endorsed by most participants—confidence judgment may actually monitor the consensuality of the answer rather than its correctness. Indeed, the C-A correlation was positive for items with a consensually correct answer but negative for items with a consensually wrong answer. Results suggest that the consensuality– confidence correlation may be mediated by 2 internal mnemonic cues that are correlated with consensuality: Consensual answers are reached faster and are selected more consistently by the same person on different occasions than nonconsensual answers. The results argue against a direct-access view of confidence judgments and suggest that such judgments will be accurate only as long as people’s responses are by and large correct across the sampled items, thus stressing the criticality of a representative design.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IFAFATX7/Koriat - Subjective Confidence in One’s Answers The Consen.pdf}
}

@article{kornellTransferMetacognitiveSkills,
  title = {Transfer of {{Metacognitive Skills}} and {{Hint Seeking}} in {{Monkeys}}},
  author = {Kornell, Nate and Son, Lisa K and Terrace, Herbert S},
  volume = {18},
  number = {1},
  pages = {8},
  abstract = {Metacognition is knowledge that can be expressed as confidence judgments about what one knows (monitoring) and by strategies for learning what one does not know (control). Although there is a substantial literature on cognitive processes in animals, little is known about their metacognitive abilities. Here we show that rhesus macaques, trained previously to make retrospective confidence judgments about their performance on perceptual tasks, transferred that ability immediately to a new perceptual task and to a working memory task. We also show that monkeys can learn to request ‘‘hints’’ when they are given problems that they would otherwise have to solve by trial and error. This study demonstrates, for the first time, that nonhuman primates share with humans the ability to monitor and transfer their metacognitive ability both within and between different cognitive tasks, and to seek new knowledge on a need-to-know basis.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Z9CAKP3F/Kornell et al. - Transfer of Metacognitive Skills and Hint Seeking .pdf}
}

@article{kornellTransferMetacognitiveSkills2007,
  title = {Transfer of {{Metacognitive Skills}} and {{Hint Seeking}} in {{Monkeys}}},
  author = {Kornell, Nate and Son, Lisa K. and Terrace, Herbert S.},
  date = {2007-01},
  journaltitle = {Psychological Science},
  shortjournal = {Psychol Sci},
  volume = {18},
  number = {1},
  pages = {64--71},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/j.1467-9280.2007.01850.x},
  url = {http://journals.sagepub.com/doi/10.1111/j.1467-9280.2007.01850.x},
  urldate = {2021-01-22},
  abstract = {Metacognition is knowledge that can be expressed as confidence judgments about what one knows (monitoring) and by strategies for learning what one does not know (control). Although there is a substantial literature on cognitive processes in animals, little is known about their metacognitive abilities. Here we show that rhesus macaques, trained previously to make retrospective confidence judgments about their performance on perceptual tasks, transferred that ability immediately to a new perceptual task and to a working memory task. We also show that monkeys can learn to request ‘‘hints’’ when they are given problems that they would otherwise have to solve by trial and error. This study demonstrates, for the first time, that nonhuman primates share with humans the ability to monitor and transfer their metacognitive ability both within and between different cognitive tasks, and to seek new knowledge on a need-to-know basis.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QLF7KF35/Kornell et al. - 2007 - Transfer of Metacognitive Skills and Hint Seeking .pdf}
}

@article{kornellWhereMetaAnimal,
  title = {Where {{Is}} the “{{Meta}}” in {{Animal Metacognition}}?},
  author = {Kornell, Nate},
  pages = {7},
  abstract = {Apes, dolphins, and some monkeys seem to have metacognitive abilities: They can accurately evaluate the likelihood that their response in cognitive task was (or will be) correct. These certainty judgments are seen as significant because they imply that animals can evaluate internal cognitive states, which may entail meaningful self-reflection. But little research has investigated what is being reflected upon: Researchers have assumed that when animals make metacognitive judgments they evaluate internal memory strength. Yet decades of research have demonstrated that humans cannot directly evaluate internal memory strength. Instead, they make certainty judgments by drawing inferences from cues they can evaluate, such as familiarity and ease of processing. It seems likely that animals do the same, but this hypothesis has not been tested. I suggest two strategies for investigating the internal cues that underlie animal metacognitive judgments. It is possible that animals, like humans, are capable of making certainty judgments based on internal cues without awareness or meaningful self-reflection.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MDAYHQV7/Kornell - Where Is the “Meta” in Animal Metacognition.pdf}
}

@article{kornellWhereMetaAnimala,
  title = {Where {{Is}} the “{{Meta}}” in {{Animal Metacognition}}?},
  author = {Kornell, Nate},
  pages = {7},
  abstract = {Apes, dolphins, and some monkeys seem to have metacognitive abilities: They can accurately evaluate the likelihood that their response in cognitive task was (or will be) correct. These certainty judgments are seen as significant because they imply that animals can evaluate internal cognitive states, which may entail meaningful self-reflection. But little research has investigated what is being reflected upon: Researchers have assumed that when animals make metacognitive judgments they evaluate internal memory strength. Yet decades of research have demonstrated that humans cannot directly evaluate internal memory strength. Instead, they make certainty judgments by drawing inferences from cues they can evaluate, such as familiarity and ease of processing. It seems likely that animals do the same, but this hypothesis has not been tested. I suggest two strategies for investigating the internal cues that underlie animal metacognitive judgments. It is possible that animals, like humans, are capable of making certainty judgments based on internal cues without awareness or meaningful self-reflection.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/T95LYTJ8/Kornell - Where Is the “Meta” in Animal Metacognition.pdf}
}

@article{kruschkeBayesianEstimationSupersedes,
  title = {Bayesian Estimation Supersedes the t Test},
  author = {Kruschke, John K},
  pages = {33},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6KUEGBUA/Kruschke - Bayesian estimation supersedes the t test.pdf;/Users/alexten/Zotero/storage/CD7DWVMP/Kruschke - Bayesian estimation supersedes the t test.pdf}
}

@article{kuhbandnerProvidingExtrinsicReward2016,
  title = {Providing {{Extrinsic Reward}} for {{Test Performance Undermines Long}}-{{Term Memory Acquisition}}},
  author = {Kuhbandner, Christof},
  date = {2016},
  journaltitle = {Frontiers in Psychology},
  volume = {7},
  pages = {6},
  abstract = {Based on numerous studies showing that testing studied material can improve longterm retention more than restudying the same material, it is often suggested that the number of tests in education should be increased to enhance knowledge acquisition. However, testing in real-life educational settings often entails a high degree of extrinsic motivation of learners due to the common practice of placing important consequences on the outcome of a test. Such an effect on the motivation of learners may undermine the beneficial effects of testing on long-term memory because it has been shown that extrinsic motivation can reduce the quality of learning. To examine this issue, participants learned foreign language vocabulary words, followed by an immediate test in which one-third of the words were tested and one-third restudied. To manipulate extrinsic motivation during immediate testing, participants received either monetary reward contingent on test performance or no reward. After 1 week, memory for all words was tested. In the immediate test, reward reduced correct recall and increased commission errors, indicating that reward reduced the number of items that can benefit from successful retrieval. The results in the delayed test revealed that reward additionally reduced the gain received from successful retrieval because memory for initially successfully retrieved words was lower in the reward condition. However, testing was still more effective than restudying under reward conditions because reward undermined long-term memory for concurrently restudied material as well. These findings indicate that providing performance–contingent reward in a test can undermine long-term knowledge acquisition.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JAKW65F9/Kuhbandner - 2016 - Providing Extrinsic Reward for Test Performance Un.pdf}
}

@article{kuhbandnerProvidingExtrinsicReward2016a,
  title = {Providing {{Extrinsic Reward}} for {{Test Performance Undermines Long}}-{{Term Memory Acquisition}}},
  author = {Kuhbandner, Christof},
  date = {2016},
  journaltitle = {Frontiers in Psychology},
  volume = {7},
  pages = {6},
  abstract = {Based on numerous studies showing that testing studied material can improve longterm retention more than restudying the same material, it is often suggested that the number of tests in education should be increased to enhance knowledge acquisition. However, testing in real-life educational settings often entails a high degree of extrinsic motivation of learners due to the common practice of placing important consequences on the outcome of a test. Such an effect on the motivation of learners may undermine the beneficial effects of testing on long-term memory because it has been shown that extrinsic motivation can reduce the quality of learning. To examine this issue, participants learned foreign language vocabulary words, followed by an immediate test in which one-third of the words were tested and one-third restudied. To manipulate extrinsic motivation during immediate testing, participants received either monetary reward contingent on test performance or no reward. After 1 week, memory for all words was tested. In the immediate test, reward reduced correct recall and increased commission errors, indicating that reward reduced the number of items that can benefit from successful retrieval. The results in the delayed test revealed that reward additionally reduced the gain received from successful retrieval because memory for initially successfully retrieved words was lower in the reward condition. However, testing was still more effective than restudying under reward conditions because reward undermined long-term memory for concurrently restudied material as well. These findings indicate that providing performance–contingent reward in a test can undermine long-term knowledge acquisition.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EJDPELHU/Kuhbandner - 2016 - Providing Extrinsic Reward for Test Performance Un.pdf}
}

@article{kulaWhyItDifficult2020,
  title = {Why Is It Difficult to Understand Statistical Inference? {{Reflections}} on the Opposing Directions of Construction and Application of Inference Framework},
  shorttitle = {Why Is It Difficult to Understand Statistical Inference?},
  author = {Kula, Fulya and Koçer, Rüya Gökhan},
  date = {2020-11-24},
  journaltitle = {Teaching Mathematics and its Applications: An International Journal of the IMA},
  volume = {39},
  number = {4},
  pages = {248--265},
  issn = {0268-3679, 1471-6976},
  doi = {10.1093/teamat/hrz014},
  url = {https://academic.oup.com/teamat/article/39/4/248/5703601},
  urldate = {2021-05-31},
  abstract = {Difficulties in learning (and thus teaching) statistical inference are well reported in the literature. We argue the problem emanates not only from the way in which statistical inference is taught but also from what exactly is taught as statistical inference. What makes statistical inference difficult to understand is that it contains two logics that operate in opposite directions. There is a certain logic in the construction of the inference framework, and there is another in its application. The logic of construction commences from the population, reaches the sample through some steps and then comes back to the population by building and using the sampling distribution. The logic of application, on the other hand, starts from the sample and reaches the population by making use of the sampling distribution. The main problem in teaching statistical inference in our view is that students are taught the logic of application while the fundamental steps in the direction of construction are often overlooked. In this study, we examine and compare these two logics and argue that introductory statistical courses would benefit from using the direction of construction, which ensures that students internalize the way in which inference framework makes sense, rather than that of application.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/TDIW9DNL/Kula and Koçer - 2020 - Why is it difficult to understand statistical infe.pdf}
}

@article{kumaranWhatLearningSystems,
  title = {What {{Learning Systems}} Do {{Intelligent Agents Need}}? {{Complementary Learning Systems Theory Updated}}},
  author = {Kumaran, Dharshan},
  pages = {23},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Q5DG93KE/Kumaran - What Learning Systems do Intelligent Agents Need .pdf}
}

@article{kumaranWhatLearningSystems2016,
  title = {What {{Learning Systems}} Do {{Intelligent Agents Need}}? {{Complementary Learning Systems Theory Updated}}},
  shorttitle = {What {{Learning Systems}} Do {{Intelligent Agents Need}}?},
  author = {Kumaran, Dharshan and Hassabis, Demis and McClelland, James L.},
  date = {2016-07},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {20},
  number = {7},
  pages = {512--534},
  issn = {13646613},
  doi = {10.1016/j.tics.2016.05.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661316300432},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9ZLR2B24/Kumaran et al. - 2016 - What Learning Systems do Intelligent Agents Need .pdf}
}

@article{kunimotoConfidenceAccuracyNearThreshold,
  title = {Confidence and {{Accuracy}} of {{Near}}-{{Threshold Discrimination Responses}}},
  author = {Kunimoto, Craig and Miller, Jeff},
  pages = {47},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IGM3WQGH/Kunimoto and Miller - Confidence and Accuracy of Near-Threshold Discrimi.pdf;/Users/alexten/Zotero/storage/JSBBY2EU/Kunimoto and Miller - Confidence and Accuracy of Near-Threshold Discrimi.pdf}
}

@article{kurzbanOpportunityCostModel2013,
  title = {An Opportunity Cost Model of Subjective Effort and Task Performance},
  author = {Kurzban, Robert and Duckworth, Angela and Kable, Joseph W and Myers, Justus},
  date = {2013},
  journaltitle = {BEHAVIORAL AND BRAIN SCIENCES},
  pages = {66},
  abstract = {Why does performing certain tasks cause the aversive experience of mental effort and concomitant deterioration in task performance? One explanation posits a physical resource that is depleted over time. We propose an alternative explanation that centers on mental representations of the costs and benefits associated with task performance. Specifically, certain computational mechanisms, especially those associated with executive function, can be deployed for only a limited number of simultaneous tasks at any given moment. Consequently, the deployment of these computational mechanisms carries an opportunity cost – that is, the next-best use to which these systems might be put. We argue that the phenomenology of effort can be understood as the felt output of these cost/benefit computations. In turn, the subjective experience of effort motivates reduced deployment of these computational mechanisms in the service of the present task. These opportunity cost representations, then, together with other cost/benefit calculations, determine effort expended and, everything else equal, result in performance reductions. In making our case for this position, we review alternative explanations for both the phenomenology of effort associated with these tasks and for performance reductions over time. Likewise, we review the broad range of relevant empirical results from across sub-disciplines, especially psychology and neuroscience. We hope that our proposal will help to build links among the diverse fields that have been addressing similar questions from different perspectives, and we emphasize ways in which alternative models might be empirically distinguished.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3GEHRPR9/Kurzban et al. - 2013 - An opportunity cost model of subjective effort and.pdf}
}

@online{lakeBuildingMachinesThat2016,
  title = {Building {{Machines That Learn}} and {{Think Like People}}},
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  date = {2016-11-02},
  eprint = {1604.00289},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1604.00289},
  urldate = {2021-01-22},
  abstract = {Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/PZAKLYGJ/Lake et al. - 2016 - Building Machines That Learn and Think Like People.pdf}
}

@article{lakensCalculatingReportingEffect2013,
  title = {Calculating and Reporting Effect Sizes to Facilitate Cumulative Science: A Practical Primer for t-Tests and {{ANOVAs}}},
  shorttitle = {Calculating and Reporting Effect Sizes to Facilitate Cumulative Science},
  author = {Lakens, Daniël},
  date = {2013},
  journaltitle = {Frontiers in Psychology},
  shortjournal = {Front. Psychol.},
  volume = {4},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00863},
  url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00863/abstract},
  urldate = {2021-05-23},
  abstract = {Effect sizes are the most important outcome of empirical studies. Most articles on effect sizes highlight their importance to communicate the practical significance of results. For scientists themselves, effect sizes are most useful because they facilitate cumulative science. Effect sizes can be used to determine the sample size for follow-up studies, or examining effects across studies. This article aims to provide a practical primer on how to calculate and report effect sizes for t-tests and ANOVA’s such that effect sizes can be used in a-priori power analyses and meta-analyses. Whereas many articles about effect sizes focus on between-subjects designs and address within-subjects designs only briefly, I provide a detailed overview of the similarities and differences between withinand between-subjects designs. I suggest that some research questions in experimental psychology examine inherently intra-individual effects, which makes effect sizes that incorporate the correlation between measures the best summary of the results. Finally, a supplementary spreadsheet is provided to make it as easy as possible for researchers to incorporate effect size calculations into their workflow.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/L8LBNYJL/Lakens - 2013 - Calculating and reporting effect sizes to facilita.pdf}
}

@article{lakensEquivalenceTestsPractical2017,
  title = {Equivalence {{Tests}}: {{A Practical Primer}} for t {{Tests}}, {{Correlations}}, and {{Meta}}-{{Analyses}}},
  shorttitle = {Equivalence {{Tests}}},
  author = {Lakens, Daniël},
  date = {2017-05},
  journaltitle = {Social Psychological and Personality Science},
  shortjournal = {Social Psychological and Personality Science},
  volume = {8},
  number = {4},
  pages = {355--362},
  issn = {1948-5506, 1948-5514},
  doi = {10.1177/1948550617697177},
  url = {http://journals.sagepub.com/doi/10.1177/1948550617697177},
  urldate = {2021-05-31},
  abstract = {Scientists should be able to provide support for the absence of a meaningful effect. Currently, researchers often incorrectly conclude an effect is absent based a nonsignificant result. A widely recommended approach within a frequentist framework is to test for equivalence. In equivalence tests, such as the two one-sided tests (TOST) procedure discussed in this article, an upper and lower equivalence bound is specified based on the smallest effect size of interest. The TOST procedure can be used to statistically reject the presence of effects large enough to be considered worthwhile. This practical primer with accompanying spreadsheet and R package enables psychologists to easily perform equivalence tests (and power analyses) by setting equivalence bounds based on standardized effect sizes and provides recommendations to prespecify equivalence bounds. Extending your statistical tool kit with equivalence tests is an easy way to improve your statistical and theoretical inferences.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/THVWSG3Q/Lakens - 2017 - Equivalence Tests A Practical Primer for t.pdf}
}

@article{lampinenAnalogiesEmergeLearning,
  title = {Analogies {{Emerge}} from {{Learning Dyamics}} in {{Neural Networks}}},
  author = {Lampinen, Andrew and Hsu, Shaw and McClelland, James L},
  pages = {6},
  abstract = {When a neural network is trained on multiple analogous tasks, previous research has shown that it will often generate representations that reflect the analogy. This may explain the value of multi-task training, and also may underlie the power of human analogical reasoning – awareness of analogies may emerge naturally from gradient-based learning in neural networks. We explore this issue by generalizing linear analysis techniques to explore two sets of analogous tasks, show that analogical structure is commonly extracted, and address some potential implications.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/RG72RRLQ/Lampinen et al. - Analogies Emerge from Learning Dyamics in Neural N.pdf}
}

@article{lampinenONESHOTFEWSHOTLEARNING2018,
  title = {{{ONE}}-{{SHOT AND FEW}}-{{SHOT LEARNING OF WORD EM}}- {{BEDDINGS}}},
  author = {Lampinen, Andrew K and McClelland, James L},
  date = {2018},
  pages = {16},
  abstract = {Standard deep learning systems require thousands or millions of examples to learn a concept, and cannot integrate new concepts easily. By contrast, humans have an incredible ability to do one-shot or few-shot learning. For instance, from just hearing a word used in a sentence, humans can infer a great deal about it, by leveraging what the syntax and semantics of the surrounding words tells us. Here, we draw inspiration from this to highlight a simple technique by which deep recurrent networks can similarly exploit their prior knowledge to learn a useful representation for a new word from little data. This could make natural language processing systems much more flexible, by allowing them to learn continually from the new words they encounter.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SLBRAK3X/Lampinen and McClelland - 2018 - ONE-SHOT AND FEW-SHOT LEARNING OF WORD EM- BEDDING.pdf}
}

@article{lampinenONESHOTFEWSHOTLEARNING2018a,
  title = {{{ONE}}-{{SHOT AND FEW}}-{{SHOT LEARNING OF WORD EM}}- {{BEDDINGS}}},
  author = {Lampinen, Andrew K and McClelland, James L},
  date = {2018},
  pages = {16},
  abstract = {Standard deep learning systems require thousands or millions of examples to learn a concept, and cannot integrate new concepts easily. By contrast, humans have an incredible ability to do one-shot or few-shot learning. For instance, from just hearing a word used in a sentence, humans can infer a great deal about it, by leveraging what the syntax and semantics of the surrounding words tells us. Here, we draw inspiration from this to highlight a simple technique by which deep recurrent networks can similarly exploit their prior knowledge to learn a useful representation for a new word from little data. This could make natural language processing systems much more flexible, by allowing them to learn continually from the new words they encounter.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3A87M7IG/Lampinen and McClelland - 2018 - ONE-SHOT AND FEW-SHOT LEARNING OF WORD EM- BEDDING.pdf}
}

@article{langleySymposiumProblemSolving,
  title = {Symposium on {{Problem Solving}} and {{Goal}}-{{Directed Sequential Activity}}},
  author = {Langley, Pat and Cooper, Richard P},
  pages = {3},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ZSYZVJA2/Langley and Cooper - Symposium on Problem Solving and Goal-Directed Seq.pdf}
}

@article{langleySymposiumProblemSolvinga,
  title = {Symposium on {{Problem Solving}} and {{Goal}}-{{Directed Sequential Activity}}},
  author = {Langley, Pat and Cooper, Richard P},
  pages = {3},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MYMNJZFJ/Langley and Cooper - Symposium on Problem Solving and Goal-Directed Seq.pdf}
}

@online{laversanne-finotCuriosityDrivenExploration2018,
  title = {Curiosity {{Driven Exploration}} of {{Learned Disentangled Goal Spaces}}},
  author = {Laversanne-Finot, Adrien and Péré, Alexandre and Oudeyer, Pierre-Yves},
  date = {2018-11-04},
  eprint = {1807.01521},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1807.01521},
  urldate = {2021-01-22},
  abstract = {Intrinsically motivated goal exploration processes enable agents to autonomously sample goals to explore efficiently complex environments with highdimensional continuous actions. They have been applied successfully to real world robots to discover repertoires of policies producing a wide diversity of effects. Often these algorithms relied on engineered goal spaces but it was recently shown that one can use deep representation learning algorithms to learn an adequate goal space in simple environments. However, in the case of more complex environments containing multiple objects or distractors, an efficient exploration requires that the structure of the goal space reflects the one of the environment. In this paper we show that using a disentangled goal space leads to better exploration performances than an entangled goal space. We further show that when the representation is disentangled, one can leverage it by sampling goals that maximize learning progress in a modular manner. Finally, we show that the measure of learning progress, used to drive curiosity-driven exploration, can be used simultaneously to discover abstract independently controllable features of the environment. The code used in the experiments is available at https://github.com/flowersteam/ Unsupervised\_Goal\_Space\_Learning.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Robotics,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/LJZTJ2VK/Laversanne-Finot et al. - 2018 - Curiosity Driven Exploration of Learned Disentangl.pdf}
}

@article{leeGuideWritingMathematics,
  title = {A {{Guide}} to {{Writing Mathematics}}},
  author = {Lee, Dr Kevin P},
  pages = {17},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DUUZ28RY/Lee - A Guide to Writing Mathematics.pdf;/Users/alexten/Zotero/storage/RFQVRRAW/Lee - A Guide to Writing Mathematics.pdf}
}

@article{leeIdentifyingNeuralSubstrates2017,
  title = {Identifying the Neural Substrates of Intrinsic Motivation during Task Performance},
  author = {Lee, Woogul},
  date = {2017},
  journaltitle = {Cogn Affect Behav Neurosci},
  pages = {15},
  abstract = {Intrinsic motivation is the inherent tendency to seek out novelty and challenge, to explore and investigate, and to stretch and extend one’s capacities. When people imagine performing intrinsically motivating tasks, they show heightened anterior insular cortex (AIC) activity. To fully explain the neural system of intrinsic motivation, however, requires assessing neural activity while people actually perform intrinsically motivating tasks (i.e., while answering curiosity-inducing questions or solving competence-enabling anagrams). Using event-related functional magnetic resonance imaging, we found that the neural system of intrinsic motivation involves not only AIC activity, but also striatum activity and, further, AIC–striatum functional interactions. These findings suggest that subjective feelings of intrinsic satisfaction (associated with AIC activations), reward processing (associated with striatum activations), and their interactions underlie the actual experience of intrinsic motivation. These neural findings are consistent with the conceptualization of intrinsic motivation as the pursuit and satisfaction of subjective feelings (interest and enjoyment) as intrinsic rewards.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/W5HJAP4V/Lee - 2017 - Identifying the neural substrates of intrinsic mot.pdf;/Users/alexten/Zotero/storage/ZYFYUAUJ/Lee - 2017 - Identifying the neural substrates of intrinsic mot.pdf}
}

@article{leggCollectionDefinitionsIntelligence,
  title = {A {{Collection}} of {{Deﬁnitions}} of {{Intelligence}}},
  author = {Legg, Shane and Hutter, Marcus},
  pages = {11},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EHYYIAFW/Legg and Hutter - A Collection of Deﬁnitions of Intelligence.pdf}
}

@article{leibowitzExponentialLearningEquation2010,
  title = {The Exponential Learning Equation as a Function of Successful Trials Results in Sigmoid Performance},
  author = {Leibowitz, Nathaniel and Baum, Barak and Enden, Giora and Karniel, Amir},
  date = {2010-06},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {54},
  number = {3},
  pages = {338--340},
  issn = {00222496},
  doi = {10.1016/j.jmp.2010.01.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249610000179},
  urldate = {2021-03-15},
  abstract = {While the exponential learning equation, indicating a gradually diminishing improvement, is one of the standard equations to describe learning, a sigmoid behavior with initially increasing then decreasing improvement has also been suggested. Here we show that the sigmoid behavior is mathematically derived from the standard exponential equation when the independent variable of the equation is restricted to the successful trials alone. It is suggested that for tasks promoting success-based learning, performance is better described by the derived sigmoid curve.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6KVBKIUX/Leibowitz et al. - 2010 - The exponential learning equation as a function of.pdf}
}

@article{leonesioDifferentMetamemoryJudgments,
  title = {Do {{Different Metamemory Judgments Tap}} the {{Same Underlying Aspects}} of {{Memory}}?},
  author = {Leonesio, R Jacob and Nelson, Thomas O},
  pages = {7},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EJNCERV4/Leonesio and Nelson - Do Different Metamemory Judgments Tap the Same Und.pdf;/Users/alexten/Zotero/storage/UA8DLX8M/Leonesio and Nelson - Do Different Metamemory Judgments Tap the Same Und.pdf}
}

@article{leongDynamicInteractionReinforcement,
  title = {Dynamic {{Interaction}} between {{Reinforcement Learning}} and {{Attention}} in {{Multidimensional Environments}}},
  author = {Leong, Yuan Chang},
  pages = {28},
  abstract = {Little is known about the relationship between attention and learning during decision making. Using eye tracking and multivariate pattern analysis of fMRI data, we measured participants’ dimensional attention as they performed a trial-and-error learning task in which only one of three stimulus dimensions was relevant for reward at any given time. Analysis of participants’ choices revealed that attention biased both value computation during choice and value update during learning. Value signals in the ventromedial prefrontal cortex and prediction errors in the striatum were similarly biased by attention. In turn, participants’ focus of attention was dynamically modulated by ongoing learning. Attentional switches across dimensions correlated with activity in a frontoparietal attention network, which showed enhanced connectivity with the ventromedial prefrontal cortex between switches. Our results suggest a bidirectional interaction between attention and learning: attention constrains learning to relevant dimensions of the environment, while we learn what to attend to via trial and error.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WE2M6P7J/Leong - Dynamic Interaction between Reinforcement Learning.pdf}
}

@article{lichtensteinCalibrationProbabilitiesState,
  title = {Calibration of {{Probabilities}}: {{The State}} of the {{Art}} to 1980},
  author = {Lichtenstein, Sarah and Fischhoff, Baruch},
  pages = {69},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/W7LDSYX6/Lichtenstein and Fischhoff - Calibration of Probabilities The State of the Art.pdf}
}

@article{ligneulReliefSurpriseDual2018,
  title = {From Relief to Surprise: {{Dual}} Control of Epistemic Curiosity in the Human Brain},
  author = {Ligneul, Romain},
  date = {2018},
  pages = {11},
  abstract = {Epistemic curiosity (EC) is a cornerstone of human cognition that contributes to the actualization of our cognitive potential by stimulating a myriad of informationseeking behaviors. Yet, its fundamental relationship with uncertainty remains poorly understood, which limits our ability to predict within- and between-individual variability in the willingness to acquire knowledge. Here, a two-step stochastic trivia quiz designed to induce curiosity and manipulate answer uncertainty provided behavioral and neural evidence for an integrative model of EC inspired from predictive coding. More precisely, our behavioral data indicated an inverse relationship between average surprise elicited by previous trivia items and EC levels, which depended upon hemodynamic activity in the rostrolateral prefrontal cortex from one trial to another and from one individual to another. Complementary, the relief of acute curiosity recruited the ventral striatum when knowledge delivery was unpredictable. Taken together, our results account for the temporal evolution of EC over time, as well as for the interplay of EC, prior knowledge and surprise in controlling memory gain.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/RYLCDZ4T/Ligneul - 2018 - From relief to surprise Dual control of epistemic.pdf;/Users/alexten/Zotero/storage/WXEAFIKA/Ligneul - 2018 - From relief to surprise Dual control of epistemic.pdf}
}

@article{lindleyAnalysisExperimentalData1993,
  title = {The {{Analysis}} of {{Experimental Data}}: {{The Appreciation}} of {{Tea}} and {{Wine}}},
  shorttitle = {The {{Analysis}} of {{Experimental Data}}},
  author = {Lindley, Dennis V},
  date = {1993-03},
  journaltitle = {Teaching Statistics},
  shortjournal = {Teaching Statistics},
  volume = {15},
  number = {1},
  pages = {22--25},
  issn = {0141-982X, 1467-9639},
  doi = {10.1111/j.1467-9639.1993.tb00252.x},
  url = {http://doi.wiley.com/10.1111/j.1467-9639.1993.tb00252.x},
  urldate = {2021-01-22},
  abstract = {A classical experiment on the tasting of tea is used to show that many standard methods of analysis of the resulting data are unsatisfactory. A similar experiment with wine is used to show how a more sensible method may be developed.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NRYLNA3C/Lindley - 1993 - The Analysis of Experimental Data The Appreciatio.pdf}
}

@article{lomasDifficultyOverratedEffects2017,
  title = {Is {{Difficulty Overrated}}? {{The Effects}} of {{Choice}}, {{Novelty}} and {{Suspense}} on {{Intrinsic Motivation}} in {{Educational Games}}},
  author = {Lomas, J Derek and Koedinger, Ken and Patel, Nirmal and Shodhan, Sharan and Poonwala, Nikhil and Forlizzi, Jodi L},
  date = {2017},
  pages = {12},
  abstract = {Many game designers aim to optimize difficulty to make games that are “not too hard, not too easy.” However, recent experiments have shown that even moderate difficulty can reduce player engagement. The present work investigates other design factors that may account for the purported benefits of difficulty, such as choice, novelty and suspense. These factors were manipulated in three design experiments involving over 20,000 play sessions of an online educational game.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/E7AQ3W2N/Lomas et al. - 2017 - Is Difficulty Overrated The Effects of Choice, No.pdf}
}

@article{lopesStrategicStudentApproacha,
  title = {The {{Strategic Student Approach}} for {{Life}}-{{Long Exploration}} and {{Learning}}},
  author = {Lopes, Manuel and Oudeyer, Pierre-Yves},
  pages = {8},
  abstract = {This article introduces and formalizes a general class of learning problems for which a developmental learning strategy is shown to be optimal. This class of problems can be explained using the strategic student metaphor: a student has to learn a number of topics (or tasks) to maximize its mean score, and has to choose strategically how to allocate its time among the topics and/or which learning method to use for a given topic. We show that if the performance curves are sub-modular, then a strategy where time allocation or learning method are chosen in a developmental manner is optimal. We argue that this optimal developmental trajectory can be automatically generated by greedy maximization of learning progress. This optimal strategy amounts to creating a structured developmental exploration where typically easy tasks are first explored, and then progressively more complicated ones are explored. Furthermore, this result holds independently of the nature of the topics and the learning methods used. Then, we show an algorithm, based on multi-armed bandit techniques, that allows empirical online evaluation of learning progress and approximates the optimal solution. Finally, we show that the strategic student problem formulation allows to view in a common framework many previous approaches to active and developmental learning.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/YBHYL5RP/Lopes and Oudeyer - The Strategic Student Approach for Life-Long Explo.pdf}
}

@article{luttinenBayesPyVariationalBayesian,
  title = {{{BayesPy}}: {{Variational Bayesian Inference}} in {{Python}}},
  author = {Luttinen, Jaakko},
  pages = {6},
  abstract = {BayesPy is an open-source Python software package for performing variational Bayesian inference. It is based on the variational message passing framework and supports conjugate exponential family models. By removing the tedious task of implementing the variational Bayesian update equations, the user can construct models faster and in a less error-prone way. Simple syntax, flexible model construction and efficient inference make BayesPy suitable for both average and expert Bayesian users. It also supports some advanced methods such as stochastic and collapsed variational inference.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/72DTD2BG/Luttinen - BayesPy Variational Bayesian Inference in Python.pdf;/Users/alexten/Zotero/storage/FYCVXTKY/Luttinen - BayesPy Variational Bayesian Inference in Python.pdf}
}

@incollection{lynchCovarianceRegressionCorrelation1998,
  title = {Covariance, Regression, and Correlation},
  booktitle = {Genetics and {{Analysis}} of {{Quantitative Traits}}},
  author = {Lynch, Michael and Walsh, Bruce},
  date = {1998},
  edition = {1},
  volume = {1},
  publisher = {{Sinauer}},
  isbn = {978-0-87893-481-2},
  volumes = {2},
  file = {/Users/alexten/Zotero/storage/8HYUWCW3/Covariance, regression, and correlation.pdf}
}

@article{mandlerSpatialFoundationsConceptual2012,
  title = {On the {{Spatial Foundations}} of the {{Conceptual System}} and {{Its Enrichment}}},
  author = {Mandler, Jean M},
  date = {2012},
  journaltitle = {Cognitive Science},
  pages = {31},
  abstract = {A theory of how concept formation begins is presented that accounts for conceptual activity in the first year of life, shows how increasing conceptual complexity comes about, and predicts the order in which new types of information accrue to the conceptual system. In a compromise between nativist and empiricist views, it offers a single domain-general mechanism that redescribes attended spatiotemporal information into an iconic form. The outputs of this mechanism consist of types of spatial information that we know infants attend to in the first months of life. These primitives form the initial basis of concept formation, allow explicit preverbal thought, such as recall, inferences, and simple mental problem solving, and support early language learning. The theory details how spatial concepts become associated with bodily feelings of force and trying. It also explains why concepts of emotions, sensory concepts such as color, and theory of mind concepts are necessarily later acquisitions because they lack contact with spatial descriptions to interpret unstructured internal experiences. Finally, commonalities between the concepts of preverbal infants and nonhuman primates are discussed.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/93KM228Y/Mandler - 2012 - On the Spatial Foundations of the Conceptual Syste.pdf}
}

@article{mandlerSpatialFoundationsConceptual2012a,
  title = {On the {{Spatial Foundations}} of the {{Conceptual System}} and {{Its Enrichment}}},
  author = {Mandler, Jean M},
  date = {2012},
  journaltitle = {Cognitive Science},
  pages = {31},
  abstract = {A theory of how concept formation begins is presented that accounts for conceptual activity in the first year of life, shows how increasing conceptual complexity comes about, and predicts the order in which new types of information accrue to the conceptual system. In a compromise between nativist and empiricist views, it offers a single domain-general mechanism that redescribes attended spatiotemporal information into an iconic form. The outputs of this mechanism consist of types of spatial information that we know infants attend to in the first months of life. These primitives form the initial basis of concept formation, allow explicit preverbal thought, such as recall, inferences, and simple mental problem solving, and support early language learning. The theory details how spatial concepts become associated with bodily feelings of force and trying. It also explains why concepts of emotions, sensory concepts such as color, and theory of mind concepts are necessarily later acquisitions because they lack contact with spatial descriptions to interpret unstructured internal experiences. Finally, commonalities between the concepts of preverbal infants and nonhuman primates are discussed.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5FMN4BY7/Mandler - 2012 - On the Spatial Foundations of the Conceptual Syste.pdf}
}

@article{maniscalcoSignalDetectionTheoretic2012,
  title = {A Signal Detection Theoretic Approach for Estimating Metacognitive Sensitivity from Confidence Ratings},
  author = {Maniscalco, Brian and Lau, Hakwan},
  date = {2012-03},
  journaltitle = {Consciousness and Cognition},
  shortjournal = {Consciousness and Cognition},
  volume = {21},
  number = {1},
  pages = {422--430},
  issn = {10538100},
  doi = {10.1016/j.concog.2011.09.021},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053810011002303},
  urldate = {2021-01-22},
  abstract = {How should we measure metacognitive (‘‘type 2’’) sensitivity, i.e. the efficacy with which observers’ confidence ratings discriminate between their own correct and incorrect stimulus classifications? We argue that currently available methods are inadequate because they are influenced by factors such as response bias and type 1 sensitivity (i.e. ability to distinguish stimuli). Extending the signal detection theory (SDT) approach of Galvin, Podd, Drga, and Whitmore (2003), we propose a method of measuring type 2 sensitivity that is free from these confounds. We call our measure meta-d0, which reflects how much information, in signal-to-noise units, is available for metacognition. Applying this novel method in a 2interval forced choice visual task, we found that subjects’ metacognitive sensitivity was close to, but significantly below, optimality. We discuss the theoretical implications of these findings, as well as related computational issues of the method. We also provide free Matlab code for implementing the analysis.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/HSYGPD3T/Maniscalco - 2012 - A signal detection theoretic approach for estimati.pdf;/Users/alexten/Zotero/storage/P23F5KGE/Maniscalco - 2012 - A signal detection theoretic approach for estimati.pdf;/Users/alexten/Zotero/storage/R6S2ZDYC/Maniscalco - 2012 - A signal detection theoretic approach for estimati.pdf;/Users/alexten/Zotero/storage/X5T9JAPN/Maniscalco and Lau - 2012 - A signal detection theoretic approach for estimati.pdf}
}

@article{maniscalcoSignalDetectionTheory,
  title = {Signal {{Detection Theory Analysis}} of {{Type}} 1 and {{Type}} 2 {{Data}}: {{Meta}}-D0, {{Response}}- {{Speciﬁc Meta}}-D0, and the {{Unequal Variance SDT Model}}},
  author = {Maniscalco, Brian and Lau, Hakwan},
  pages = {42},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7HQUPXX6/Maniscalco and Lau - Signal Detection Theory Analysis of Type 1 and Typ.pdf}
}

@article{maniscalcoSignalDetectionTheorya,
  title = {Signal {{Detection Theory Analysis}} of {{Type}} 1 and {{Type}} 2 {{Data}}: {{Meta}}-D0, {{Response}}- {{Speciﬁc Meta}}-D0, and the {{Unequal Variance SDT Model}}},
  author = {Maniscalco, Brian and Lau, Hakwan},
  pages = {42},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UISYJJWG/Maniscalco and Lau - Signal Detection Theory Analysis of Type 1 and Typ.pdf}
}

@article{mannellaGoalDirectedBehaviorInstrumental2016,
  title = {Goal-{{Directed Behavior}} and {{Instrumental Devaluation}}: {{A Neural System}}-{{Level Computational Model}}},
  shorttitle = {Goal-{{Directed Behavior}} and {{Instrumental Devaluation}}},
  author = {Mannella, Francesco and Mirolli, Marco and Baldassarre, Gianluca},
  date = {2016-10-18},
  journaltitle = {Frontiers in Behavioral Neuroscience},
  shortjournal = {Front. Behav. Neurosci.},
  volume = {10},
  issn = {1662-5153},
  doi = {10.3389/fnbeh.2016.00181},
  url = {http://journal.frontiersin.org/article/10.3389/fnbeh.2016.00181/full},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2G8Y9SEB/Mannella et al. - 2016 - Goal-Directed Behavior and Instrumental Devaluatio.pdf;/Users/alexten/Zotero/storage/XF3MJQ2Y/Baldassarre - 2016 - Goal-Directed Behavior and Instrumental Devaluatio.pdf}
}

@article{markantSelfDirectedLearning2016,
  title = {Self‐{{Directed Learning Favors Local}}, {{Rather Than Global}}, {{Uncertainty}}},
  author = {Markant, Douglas B and Settles, Burr and Gureckis, Todd M},
  date = {2016},
  journaltitle = {Cognitive Science},
  pages = {21},
  abstract = {Collecting (or “sampling”) information that one expects to be useful is a powerful way to facilitate learning. However, relatively little is known about how people decide which information is worth sampling over the course of learning. We describe several alternative models of how people might decide to collect a piece of information inspired by “active learning” research in machine learning. We additionally provide a theoretical analysis demonstrating the situations under which these models are empirically distinguishable, and we report a novel empirical study that exploits these insights. Our model-based analysis of participants’ information gathering decisions reveals that people prefer to select items which resolve uncertainty between two possibilities at a time rather than items that have high uncertainty across all relevant possibilities simultaneously. Rather than adhering to strictly normative or confirmatory conceptions of information search, people appear to prefer a “local” sampling strategy, which may reflect cognitive constraints on the process of information gathering.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NNF2L6JY/Markant et al. - 2016 - Self‐Directed Learning Favors Local, Rather Than G.pdf}
}

@article{markusDynamicSelfConceptSocial,
  title = {The {{Dynamic Self}}-{{Concept}}: {{A Social Psychological Perspective}}},
  author = {Markus, H and Wurf, E},
  pages = {39},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/RACZCZFX/Markus and Wurf - The Dynamic Self-Concept A Social Psychological P.pdf}
}

@article{marshBreakingDoubleEdgedSword,
  title = {Breaking the {{Double}}-{{Edged Sword}} of {{Effort}}/{{Trying Hard}}: {{Developmental Equilibrium}} and {{Longitudinal Relations Among Effort}}, {{Achievement}}, and {{Academic Self}}-{{Concept}}},
  author = {Marsh, Herbert W and Lichtenfeld, Stephanie and Arens, A Katrin and Pekrun, Reinhard and Guo, Jiesi and Murayama, Kou},
  pages = {18},
  abstract = {Ever since the classic research of Nicholls (1976) and others, effort has been recognized as a double-edged sword: while it might enhance achievement, it undermines academic self-concept (ASC). However, there has not been a thorough evaluation of the longitudinal reciprocal effects of effort, ASC, and achievement, in the context of modern self-concept theory and statistical methodology. Nor have there been developmental equilibrium tests of whether these effects are consistent across the potentially volatile early-to-middle adolescence. Hence, focusing on mathematics, we evaluate reciprocal effects models (REMs) over the first 4 years of secondary school (grades 5– 8), relating effort, achievement (test scores and school grades), ASC, and ASC ϫ Effort interactions for a representative sample of 3,144 German students (Mage ϭ 11.75 years at Wave 1). ASC, effort, and achievement were positively correlated at each wave, and there was a clear pattern of positive reciprocal positive effects among ASC, test scores, and school grades— each contributing to the other, after controlling for the prior effects of all others. There was an asymmetrical pattern of effects for effort that is consistent with the double-edged sword premise: prior school grades had positive effects on subsequent effort, but prior effort had nonsignificant or negative effects on subsequent grades and ASC. However, on the basis of a synergistic application of new theory and methodology, we predicted and found a significant ASC ϫ Effort interaction, such that prior effort had more positive effects on subsequent ASC and school grades when prior ASC was high—thus providing a key to breaking the double-edged sword.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GMZ6QQE8/Marsh et al. - 2016 - Breaking the double-edged sword of efforttrying h.pdf}
}

@article{marshIntegratedModelAcademic,
  title = {An {{Integrated Model}} of {{Academic Self}}-{{Concept Development}}: {{Academic Self}}-{{Concept}}, {{Grades}}, {{Test Scores}}, and {{Tracking Over}} 6 {{Years}}},
  author = {Marsh, Herbert W and Pekrun, Reinhard and Murayama, Kou and Arens, A Katrin and Parker, Philip D and Guo, Jiesi and Dicke, Theresa},
  pages = {18},
  abstract = {Our newly proposed integrated academic self-concept model integrates 3 major theories of academic self-concept formation and developmental perspectives into a unified conceptual and methodological framework. Relations among math self-concept (MSC), school grades, test scores, and school-level contextual effects over 6 years, from the end of primary school through the first 5 years of secondary school (a representative sample of 3,370 German students, 42 secondary schools, 50\% male, M age at grade 5 ϭ 11.75) support the (1) internal/external frame of reference model: Math school grades had positive effects on MSC, but the effects of German grades were negative; (2) reciprocal effects (longitudinal panel) model: MSC was predictive of and predicted by math test scores and school grades; (3) big-fish-little-pond effect: The effects on MSC were negative for school-average achievement based on 4 indicators (primary school grades in math and German, school-track prior to the start of secondary school, math test scores in the first year of secondary school). Results for all 3 theoretical models were consistent across the 5 secondary school years: This supports the prediction of developmental equilibrium. This integration highlights the robustness of support over the potentially volatile early to middle adolescent period; the interconnectedness and complementarity of 3 ASC models; their counterbalancing strengths and weaknesses; and new theoretical, developmental, and substantive implications at their intersections.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8M4BW9EZ/Marsh et al. - An Integrated Model of Academic Self-Concept Devel.pdf}
}

@article{martiCertaintyPrimarilyDetermined,
  title = {Certainty {{Is Primarily Determined}} by {{Past Performance During Concept Learning}}},
  author = {Martí, Louis},
  journaltitle = {OPEN MIND},
  pages = {14},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9VUNZQB8/Martí - Certainty Is Primarily Determined by Past Performa.pdf;/Users/alexten/Zotero/storage/X7BHGBBW/Martí et al. - 2018 - Certainty Is Primarily Determined by Past Performa.pdf}
}

@article{mathysBayesianFoundationIndividual,
  title = {A {{Bayesian}} Foundation for Individual Learning under Uncertainty},
  author = {Mathys, Christoph},
  journaltitle = {Frontiers in Human Neuroscience},
  pages = {20},
  abstract = {Computational learning models are critical for understanding mechanisms of adaptive behavior. However, the two major current frameworks, reinforcement learning (RL) and Bayesian learning, both have certain limitations. For example, many Bayesian models are agnostic of inter-individual variability and involve complicated integrals, making online learning difficult. Here, we introduce a generic hierarchical Bayesian framework for individual learning under multiple forms of uncertainty (e.g., environmental volatility and perceptual uncertainty). The model assumes Gaussian random walks of states at all but the first level, with the step size determined by the next highest level. The coupling between levels is controlled by parameters that shape the influence of uncertainty on learning in a subject-specific fashion. Using variational Bayes under a mean-field approximation and a novel approximation to the posterior energy function, we derive trial-by-trial update equations which (i) are analytical and extremely efficient, enabling real-time learning, (ii) have a natural interpretation in terms of RL, and (iii) contain parameters representing processes which play a key role in current theories of learning, e.g., precisionweighting of prediction error.These parameters allow for the expression of individual differences in learning and may relate to specific neuromodulatory mechanisms in the brain. Our model is very general: it can deal with both discrete and continuous states and equally accounts for deterministic and probabilistic relations between environmental events and perceptual states (i.e., situations with and without perceptual uncertainty). These properties are illustrated by simulations and analyses of empirical time series. Overall, our framework provides a novel foundation for understanding normal and pathological learning that contextualizes RL within a generic Bayesian scheme and thus connects it to principles of optimality from probability theory.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7F9VSPPF/Mathys - A Bayesian foundation for individual learning unde.pdf}
}

@article{mattesonTimeSeriesModelsDynamic2011,
  title = {Time-{{Series Models}} of {{Dynamic Volatility}} and {{Correlation}}},
  author = {Matteson, David and Ruppert, David},
  date = {2011-09},
  journaltitle = {IEEE Signal Processing Magazine},
  shortjournal = {IEEE Signal Process. Mag.},
  volume = {28},
  number = {5},
  pages = {72--82},
  issn = {1053-5888},
  doi = {10.1109/MSP.2011.941553},
  url = {http://ieeexplore.ieee.org/document/5999582/},
  urldate = {2021-07-04},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EJFBHIPJ/Matteson and Ruppert - 2011 - Time-Series Models of Dynamic Volatility and Corre.pdf}
}

@article{mcclellandCamegieMellonUniversity,
  title = {Camegie {{Mellon University}} and {{University}} of {{Pittsburgh}}},
  author = {McCLELLAND, JAMES L},
  pages = {31},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KQLRRBMH/McCLELLAND - Camegie Mellon University and University of Pittsb.pdf;/Users/alexten/Zotero/storage/YDQ38A9D/McCLELLAND - Camegie Mellon University and University of Pittsb.pdf}
}

@article{mcclellandCritiquePureHierarchy,
  title = {A {{Critique}} of {{Pure Hierarchy}}: {{Uncovering Cross}}-{{Cutting Structure}} in a {{Natural Dataset}}},
  author = {McClelland, J L and Sadeghi, Z and Saxe, A M},
  pages = {18},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/AXAK4KQN/McClelland et al. - 2016 - A Critique of Pure Hierarchy Uncovering Cross-Cut.pdf;/Users/alexten/Zotero/storage/FABMVETZ/McClelland et al. - A Critique of Pure Hierarchy Uncovering Cross-Cut.pdf}
}

@article{mcclellandIncorporatingRapidNeocortical,
  title = {Incorporating {{Rapid Neocortical Learning}} of {{New Schema}}-{{Consistent Information Into Complementary Learning Systems Theory}}},
  author = {McClelland, James L},
  pages = {22},
  abstract = {The complementary learning systems theory of the roles of hippocampus and neocortex (McClelland, McNaughton, \& O’Reilly, 1995) holds that the rapid integration of arbitrary new information into neocortical structures is avoided to prevent catastrophic interference with structured knowledge representations stored in synaptic connections among neocortical neurons. Recent studies (Tse et al., 2007, 2011) showed that neocortical circuits can rapidly acquire new associations that are consistent with prior knowledge. The findings challenge the complementary learning systems theory as previously presented. However, new simulations extending those reported in McClelland et al. (1995) show that new information that is consistent with knowledge previously acquired by a putatively cortexlike artificial neural network can be learned rapidly and without interfering with existing knowledge; it is when inconsistent new knowledge is acquired quickly that catastrophic interference ensues. Several important features of the findings of Tse et al. (2007, 2011) are captured in these simulations, indicating that the neural network model used in McClelland et al. has characteristics in common with neocortical learning mechanisms. An additional simulation generalizes beyond the network model previously used, showing how the rate of change of cortical connections can depend on prior knowledge in an arguably more biologically plausible network architecture. In sum, the findings of Tse et al. are fully consistent with the idea that hippocampus and neocortex are complementary learning systems. Taken together, these findings and the simulations reported here advance our knowledge by bringing out the role of consistency of new experience with existing knowledge and demonstrating that the rate of change of connections in real and artificial neural networks can be strongly prior-knowledge dependent.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/C3RJS72X/McClelland - Incorporating Rapid Neocortical Learning of New Sc.pdf;/Users/alexten/Zotero/storage/CL5VC68G/McClelland - Incorporating Rapid Neocortical Learning of New Sc.pdf}
}

@article{mcclellandIntegratingProbabilisticModels,
  title = {Integrating Probabilistic Models of Perception and Interactive Neural Networks: A Historical and Tutorial Review},
  author = {McClelland, James L},
  journaltitle = {Frontiers in Psychology},
  pages = {25},
  abstract = {This article seeks to establish a rapprochement between explicitly Bayesian models of contextual effects in perception and neural network models of such effects, particularly the connectionist interactive activation (IA) model of perception. The article is in part an historical review and in part a tutorial, reviewing the probabilistic Bayesian approach to understanding perception and how it may be shaped by context, and also reviewing ideas about how such probabilistic computations may be carried out in neural networks, focusing on the role of context in interactive neural networks, in which both bottom-up and top-down signals affect the interpretation of sensory inputs. It is pointed out that connectionist units that use the logistic or softmax activation functions can exactly compute Bayesian posterior probabilities when the bias terms and connection weights affecting such units are set to the logarithms of appropriate probabilistic quantities. Bayesian concepts such the prior, likelihood, (joint and marginal) posterior, probability matching and maximizing, and calculating vs. sampling from the posterior are all reviewed and linked to neural network computations. Probabilistic and neural network models are explicitly linked to the concept of a probabilistic generative model that describes the relationship between the underlying target of perception (e.g., the word intended by a speaker or other source of sensory stimuli) and the sensory input that reaches the perceiver for use in inferring the underlying target. It is shown how a new version of the IA model called the multinomial interactive activation (MIA) model can sample correctly from the joint posterior of a proposed generative model for perception of letters in words, indicating that interactive processing is fully consistent with principled probabilistic computation. Ways in which these computations might be realized in real neural systems are also considered.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8YSAAXAD/McClelland - 2013 - Integrating probabilistic models of perception and.pdf;/Users/alexten/Zotero/storage/KSJ5MNUG/McClelland - Integrating probabilistic models of perception and.pdf}
}

@article{mcclellandInteractiveActivationMutual2014,
  title = {Interactive {{Activation}} and {{Mutual Constraint Satisfaction}} in {{Perception}} and {{Cognition}}},
  author = {McClelland, James L and Mirman, Daniel and Bolger, Donald J and Khaitan, Pranav},
  date = {2014},
  journaltitle = {Cognitive Science},
  pages = {51},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EHPBIDSE/McClelland et al. - 2014 - Interactive Activation and Mutual Constraint Satis.pdf;/Users/alexten/Zotero/storage/QNHEQUME/McClelland et al. - 2014 - Interactive Activation and Mutual Constraint Satis.pdf}
}

@article{mcclellandLettingStructureEmerge,
  title = {Letting Structure Emerge: Connectionist and Dynamical Systems Approaches to Cognition},
  author = {McClelland, James L and Botvinick, Matthew M and Noelle, David C and Plaut, David C and Rogers, Timothy T and Seidenberg, Mark S and Smith, Linda B},
  pages = {9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JCJPZT68/McClelland et al. - Letting structure emerge connectionist and dynami.pdf}
}

@article{mcclellandLettingStructureEmerge2010,
  title = {Letting Structure Emerge: Connectionist and Dynamical Systems Approaches to Cognition},
  shorttitle = {Letting Structure Emerge},
  author = {McClelland, James L. and Botvinick, Matthew M. and Noelle, David C. and Plaut, David C. and Rogers, Timothy T. and Seidenberg, Mark S. and Smith, Linda B.},
  date = {2010-08},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {14},
  number = {8},
  pages = {348--356},
  issn = {13646613},
  doi = {10.1016/j.tics.2010.06.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661310001245},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/33RKP4FQ/McClelland et al. - 2010 - Letting structure emerge connectionist and dynami.pdf}
}

@article{mcclellandPlaceModelingCognitive2009,
  title = {The {{Place}} of {{Modeling}} in {{Cognitive Science}}},
  author = {McClelland, James L},
  date = {2009},
  journaltitle = {Topics in Cognitive Science},
  pages = {28},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KVCE8STV/McClelland - 2009 - The Place of Modeling in Cognitive Science.pdf}
}

@article{mcclellandPlaceModelingCognitive2009a,
  title = {The {{Place}} of {{Modeling}} in {{Cognitive Science}}},
  author = {McClelland, James L.},
  date = {2009-01},
  journaltitle = {Topics in Cognitive Science},
  volume = {1},
  number = {1},
  pages = {11--38},
  issn = {17568757, 17568765},
  doi = {10.1111/j.1756-8765.2008.01003.x},
  url = {http://doi.wiley.com/10.1111/j.1756-8765.2008.01003.x},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NDP7I9LN/McClelland - 2009 - The Place of Modeling in Cognitive Science.pdf}
}

@article{mcclellandWhyThereAre,
  title = {Why {{There Are Complementary Learning Systems}} in the {{Hippocampus}} and {{Neocortex}}:{{InsightsFrom}} the {{Successesand Failuresof Connectionist Models}} of {{Learning}} and {{Memory}}},
  author = {McClelland, James L and O'Reilly, Randall C},
  pages = {39},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WZJBQJCY/McClelland and O'Reilly - Why There Are Complementary Learning Systems in th.pdf}
}

@article{mcclellandWhyThereArea,
  title = {Why {{There Are Complementary Learning Systems}} in the {{Hippocampus}} and {{Neocortex}}:{{InsightsFrom}} the {{Successesand Failuresof Connectionist Models}} of {{Learning}} and {{Memory}}},
  author = {McClelland, James L and O'Reilly, Randall C},
  pages = {39},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/28K9GIVQ/McClelland and O'Reilly - Why There Are Complementary Learning Systems in th.pdf}
}

@article{mcgillivrayThirstKnowledgeEffects,
  title = {Thirst for {{Knowledge}}: {{The Effects}} of {{Curiosity}} and {{Interest}} on {{Memory}} in {{Younger}} and {{Older Adults}}},
  author = {McGillivray, Shannon and Murayama, Kou and Castel, Alan D},
  pages = {7},
  abstract = {Given age-related memory impairments, one’s level of curiosity or interest could enhance memory for certain information. In the current study, younger and older adults read trivia questions, rated how curious they were to learn each answer, provided confidence and interest ratings, and judgments of learning after learning the answer. No age-related differences in memory were found. Analyses indicated that curiosity and interest contributed to the formation of judgments of learning. Additionally, interest had a unique increasing relationship with older, but not younger, adults’ memory performance after a one-week delay. The results suggest that subjective interest may serve to enhance older adults’ memory.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FTSV3UXR/McGillivray et al. - Thirst for Knowledge The Effects of Curiosity and.pdf}
}

@article{mcgillivrayThirstKnowledgeEffects2015,
  title = {Thirst for Knowledge: {{The}} Effects of Curiosity and Interest on Memory in Younger and Older Adults.},
  shorttitle = {Thirst for Knowledge},
  author = {McGillivray, Shannon and Murayama, Kou and Castel, Alan D.},
  date = {2015-12},
  journaltitle = {Psychology and Aging},
  shortjournal = {Psychology and Aging},
  volume = {30},
  number = {4},
  pages = {835--841},
  issn = {1939-1498, 0882-7974},
  doi = {10.1037/a0039801},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0039801},
  urldate = {2021-01-22},
  abstract = {Given age-related memory impairments, one’s level of curiosity or interest could enhance memory for certain information. In the current study, younger and older adults read trivia questions, rated how curious they were to learn each answer, provided confidence and interest ratings, and judgments of learning after learning the answer. No age-related differences in memory were found. Analyses indicated that curiosity and interest contributed to the formation of judgments of learning. Additionally, interest had a unique increasing relationship with older, but not younger, adults’ memory performance after a one-week delay. The results suggest that subjective interest may serve to enhance older adults’ memory.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Q29CDI2D/McGillivray et al. - 2015 - Thirst for knowledge The effects of curiosity and.pdf}
}

@article{mckayDelusionalInference2012,
  title = {Delusional {{Inference}}},
  author = {Mckay, Ryan},
  date = {2012-06},
  journaltitle = {Mind \& Language},
  volume = {27},
  number = {3},
  pages = {330--355},
  issn = {02681064},
  doi = {10.1111/j.1468-0017.2012.01447.x},
  url = {http://doi.wiley.com/10.1111/j.1468-0017.2012.01447.x},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PXDWE9XI/Mckay - 2012 - Delusional Inference.pdf}
}

@online{mehtaActiveDomainRandomization2019,
  title = {Active {{Domain Randomization}}},
  author = {Mehta, Bhairav and Diaz, Manfred and Golemo, Florian and Pal, Christopher J. and Paull, Liam},
  date = {2019-07-10},
  eprint = {1904.04762},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1904.04762},
  urldate = {2021-01-22},
  abstract = {Domain randomization is a popular technique for improving domain transfer, often used in a zero-shot setting when the target domain is unknown or cannot easily be used for training. In this work, we empirically examine the effects of domain randomization on agent generalization. Our experiments show that domain randomization may lead to suboptimal, high-variance policies, which we attribute to the uniform sampling of environment parameters. We propose Active Domain Randomization, a novel algorithm that learns a parameter sampling strategy. Our method looks for the most informative environment variations within the given randomization ranges by leveraging the discrepancies of policy rollouts in randomized and reference environment instances. We find that training more frequently on these instances leads to better overall agent generalization. Our experiments across various physics-based simulated and real-robot tasks show that this enhancement leads to more robust, consistent policies.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/alexten/Zotero/storage/9VAG8EES/Mehta et al. - 2019 - Active Domain Randomization.pdf;/Users/alexten/Zotero/storage/HMUFRMUS/Mehta et al. - 2019 - Active Domain Randomization.pdf}
}

@article{meltzoffInterventionObservationImitation,
  title = {Intervention, {{Observation}}, {{Imitation}}},
  author = {Meltzoff, Andrew N},
  pages = {11},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4V39W45F/Meltzoff - Intervention, Observation, Imitation.pdf}
}

@article{mengBeingEagerProve2017,
  title = {Being {{Eager}} to {{Prove Oneself}}: {{U}}-{{Shaped Relationship}} between {{Competence Frustration}} and {{Intrinsic Motivation}} in {{Another Activity}}},
  author = {Meng, Liang},
  date = {2017},
  journaltitle = {Frontiers in Psychology},
  volume = {8},
  pages = {8},
  abstract = {Competence frustration has been consistently found to undermine one’s intrinsic motivation in the same activity. However, the relationship between competence frustration in a preceding activity and one’s intrinsic motivation in a subsequent one remains unclear. In order to explore this relationship, self-reported data were collected from 617 undergraduate students of a large comprehensive university in southern China, who took varied courses immediately before taking a less-demanding one. Results suggested a U-shaped relationship between students’ competence frustration in a preceding course and intrinsic motivation in a subsequent one. To be specific, for students whose competence frustration reached the inflection point, a restoration process would be activated if the current course would help restore their competence. Importantly, these students’ competence frustration in a preceding course was found to positively predict their intrinsic motivation level in a subsequent course. As far as we are concerned, this is the first study to reveal a potential positive effect of need frustration outside of its primary thwarting context, which complements and extends existing literatures on the dynamics between need frustration and intrinsic motivation.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/LVUEQYPD/Meng - 2017 - Being Eager to Prove Oneself U-Shaped Relationshi.pdf;/Users/alexten/Zotero/storage/QTUJNABV/Meng - 2017 - Being Eager to Prove Oneself U-Shaped Relationshi.pdf}
}

@article{merdesFormalModelsSource,
  title = {Formal Models of Source Reliability},
  author = {Merdes, Christoph},
  pages = {29},
  abstract = {The paper introduces, compares and contrasts formal models of source reliability proposed in the epistemology literature, in particular the prominent models of Bovens and Hartmann (2003) and Olsson (2011). All are Bayesian models seeking to provide normative guidance, yet they differ subtly in assumptions and resulting behavior. Models are evaluated both on conceptual grounds and through simulations, and the relationship between models is clarified. The simulations both show surprising similarities and highlight relevant differences between these models. Most importantly, however, our evaluations reveal that important normative concerns arguably remain unresolved. The philosophical implications of this for testimony are discussed.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CJ2U3WE5/Merdes - Formal models of source reliability.pdf;/Users/alexten/Zotero/storage/SFKJ4LTS/Merdes - Formal models of source reliability.pdf}
}

@incollection{metcalfeAnoeticNoeticAutonoetic2012,
  title = {Anoetic, Noetic, and Autonoetic Metacognition},
  booktitle = {Foundations of {{Metacognition}}},
  author = {Metcalfe, Janet and Son, Lisa K.},
  editor = {Beran, Michael J. and Brandl, Johannes and Perner, Josef and Proust, Joëlle},
  date = {2012-09-06},
  pages = {289--301},
  publisher = {{Oxford University Press}},
  doi = {10.1093/acprof:oso/9780199646739.003.0019},
  url = {https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780199646739.001.0001/acprof-9780199646739-chapter-018},
  urldate = {2021-01-22},
  isbn = {978-0-19-964673-9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/82FFDCWE/Metcalfe and Son - 2012 - Anoetic, noetic, and autonoetic metacognition.pdf}
}

@article{metcalfeDynamicsLearningAllocation2003,
  title = {The {{Dynamics}} of {{Learning}} and {{Allocation}} of {{Study Time}} to a {{Region}} of {{Proximal Learning}}.},
  author = {Metcalfe, Janet and Kornell, Nate},
  date = {2003},
  journaltitle = {Journal of Experimental Psychology: General},
  shortjournal = {Journal of Experimental Psychology: General},
  volume = {132},
  number = {4},
  pages = {530--542},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/0096-3445.132.4.530},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-3445.132.4.530},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ZWVEWBQN/Metcalfe and Kornell - 2003 - The Dynamics of Learning and Allocation of Study T.pdf}
}

@article{metcalfeDynamicsLearningAllocation2003a,
  title = {The {{Dynamics}} of {{Learning}} and {{Allocation}} of {{Study Time}} to a {{Region}} of {{Proximal Learning}}.},
  author = {Metcalfe, Janet and Kornell, Nate},
  date = {2003},
  journaltitle = {Journal of Experimental Psychology: General},
  shortjournal = {Journal of Experimental Psychology: General},
  volume = {132},
  number = {4},
  pages = {530--542},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/0096-3445.132.4.530},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-3445.132.4.530},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QDYK8MR7/Metcalfe and Kornell - 2003 - The Dynamics of Learning and Allocation of Study T.pdf}
}

@incollection{metcalfeEvolutionMetacognition2014,
  title = {Evolution of {{Metacognition}}},
  booktitle = {Handbook of {{Metamemory}} and {{Memory}}},
  author = {Metcalfe, Janet},
  date = {2014-02-18},
  publisher = {{Routledge}},
  doi = {10.4324/9780203805503.ch3},
  url = {https://www.taylorfrancis.com/books/9780203805503},
  urldate = {2021-01-22},
  abstract = {The importance of metacognition, in the evolution of human consciousness, has been emphasized by thinkers going back hundreds of years. While it is clear that people have metacognition, even when it is strictly defined as it is here, whether any other animals share this capability is the topic of this chapter. The empirical data on nonhuman metacognition are reviewed. It is concluded that three monkeys have now shown evidence of metacognition. Even in these primates, however, the capabilities are limited. Despite claims that rats have metacognition, the data can be explained in terms of mere conditioning contingencies. No other species have been shown to have metacognition. Thus, metacognition appears to be a very recently evolved capability. It is one that may confer on humans an ability to escape from being stimulus bound, and allow self control of their learning, and actions.},
  isbn = {978-0-203-80550-3 978-1-136-64855-7 978-0-8058-6214-0},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CDH4DEBX/Metcalfe - 2014 - Evolution of Metacognition.pdf}
}

@article{metcalfeFamiliarityRetrievalProcesses,
  title = {Familiarity and {{Retrieval Processes}} in {{Delayed Judgments}} of {{Learning}}},
  author = {Metcalfe, Janet and Finn, Bridgid},
  pages = {14},
  abstract = {Two processes are postulated to underlie delayed judgments of learning (JOLs)— cue familiarity and target retrievability. The two processes are distinguishable because the familiarity-based judgments are thought to be faster than the retrieval-based processes, because only retrieval-based JOLs should enhance the relative accuracy of the correlations between the JOLs and criterion test performance, and because only retrieval-based judgments should enhance memory. To test these predictions, in three experiments, the authors either speeded people’s JOLs or allowed them to be unspeeded. The relative accuracy of the JOLs in predicting performance on the criterion test was higher for the unspeeded JOLs than for the speeded JOLs, as predicted. The unspeeded JOL conditions showed enhanced memory as compared with the speeded JOL conditions, as predicted. Finally, the unspeeded JOLs were sensitive to manipulations that modified recallability of the target, whereas the speeded JOLs were selectively sensitive to experimental variations in the familiarity of the cues. Thus, all three of the predictions about the consequences of the two processes potentially underlying delayed JOLs were borne out. A model of the processes underlying delayed JOLs based on these and earlier results is presented.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2ABLVHEC/Metcalfe and Finn - Familiarity and Retrieval Processes in Delayed Jud.pdf;/Users/alexten/Zotero/storage/DVDWEWMH/Metcalfe and Finn - Familiarity and Retrieval Processes in Delayed Jud.pdf}
}

@article{metcalfeLearningErrors2017,
  title = {Learning from {{Errors}}},
  author = {Metcalfe, Janet},
  date = {2017-01-03},
  journaltitle = {Annual Review of Psychology},
  shortjournal = {Annu. Rev. Psychol.},
  volume = {68},
  number = {1},
  pages = {465--489},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev-psych-010416-044022},
  url = {http://www.annualreviews.org/doi/10.1146/annurev-psych-010416-044022},
  urldate = {2021-01-22},
  abstract = {Although error avoidance during learning appears to be the rule in American classrooms, laboratory studies suggest that it may be a counterproductive strategy, at least for neurologically typical students. Experimental investigations indicate that errorful learning followed by corrective feedback is beneficial to learning. Interestingly, the beneficial effects are particularly salient when individuals strongly believe that their error is correct: Errors committed with high confidence are corrected more readily than low-confidence errors. Corrective feedback, including analysis of the reasoning leading up to the mistake, is crucial. Aside from the direct benefit to learners, teachers gain valuable information from errors, and error tolerance encourages students’ active, exploratory, generative engagement. If the goal is optimal performance in high-stakes situations, it may be worthwhile to allow and even encourage students to commit and correct errors while they are in low-stakes learning situations rather than to assiduously avoid errors at all costs.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8VNYWHN3/Metcalfe - 2017 - Learning from Errors.pdf}
}

@article{metcalfeLearningOneOwn,
  title = {Learning from One’s Own Errors and Those of Others},
  author = {Metcalfe, Janet},
  journaltitle = {Psychon Bull Rev},
  pages = {7},
  abstract = {Three experiments investigated the effects of making errors oneself, as compared to just hearing the correct answer without error generation, hearing another person make an error, or being Bon-the-hook,\^ that is, possibly but not necessarily being the person who would be Bcalled-on\^ to give a response. In all three experiments, generating either an error of commission or generating the correct response, oneself, out loud, compared to being a person who heard another's commission errors (or correct responses), was beneficial for later recall of the correct answer. Experiment 1 suggested that the decrement in recall from self- to other-generation could be partially offset by being Bon-the-hook.\^ However, this benefit was fragile and did not hold up either at a delay or when the presence of the other participants was downplayed. The beneficial effect of self-generation, both of correct responses and of errors of commission is consistent with reconsolidation theory. That theory holds that retrieval has a special status as a memory process that renders the retrieved traces labile. If the person was correct, reconsolidating the correct trace results in strengthening. If wrong, the malleability of the retrieved trace implied by reconsolidation theory makes it open to enhanced modification and correction. If the person was not the agent who retrieved, though, such as when someone else retrieves information, or when nothing is retrieved as is the case with omission errors (which we argue is truly how the term Bunsuccessful retrieval\^ should be used), the benefit conferred by the special malleability entailed by the postulated reconsolidation process does not obtain.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3R97HJSF/Metcalfe - Learning from one’s own errors and those of others.pdf}
}

@article{metcalfeLearningOneOwn2018,
  title = {Learning from One’s Own Errors and Those of Others},
  author = {Metcalfe, Janet and Xu, Judy},
  date = {2018-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {1},
  pages = {402--408},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-017-1287-7},
  url = {http://link.springer.com/10.3758/s13423-017-1287-7},
  urldate = {2021-01-22},
  abstract = {Three experiments investigated the effects of making errors oneself, as compared to just hearing the correct answer without error generation, hearing another person make an error, or being Bon-the-hook,\^ that is, possibly but not necessarily being the person who would be Bcalled-on\^ to give a response. In all three experiments, generating either an error of commission or generating the correct response, oneself, out loud, compared to being a person who heard another's commission errors (or correct responses), was beneficial for later recall of the correct answer. Experiment 1 suggested that the decrement in recall from self- to other-generation could be partially offset by being Bon-the-hook.\^ However, this benefit was fragile and did not hold up either at a delay or when the presence of the other participants was downplayed. The beneficial effect of self-generation, both of correct responses and of errors of commission is consistent with reconsolidation theory. That theory holds that retrieval has a special status as a memory process that renders the retrieved traces labile. If the person was correct, reconsolidating the correct trace results in strengthening. If wrong, the malleability of the retrieved trace implied by reconsolidation theory makes it open to enhanced modification and correction. If the person was not the agent who retrieved, though, such as when someone else retrieves information, or when nothing is retrieved as is the case with omission errors (which we argue is truly how the term Bunsuccessful retrieval\^ should be used), the benefit conferred by the special malleability entailed by the postulated reconsolidation process does not obtain.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9UJTPKHZ/Metcalfe and Xu - 2018 - Learning from one’s own errors and those of others.pdf}
}

@book{metcalfeMetacognitionKnowingKnowing1994,
  title = {Metacognition: Knowing about Knowing},
  shorttitle = {Metacognition},
  editor = {Metcalfe, Janet and Shimamura, Arthur P.},
  date = {1994},
  publisher = {{MIT Press}},
  location = {{Cambridge, Mass}},
  isbn = {978-0-262-13298-5},
  pagetotal = {334},
  keywords = {Cognition,Metacognition},
  file = {/Users/alexten/Zotero/storage/48QSGWH5/Metcalfe and Shimamura - 1994 - Metacognition knowing about knowing.pdf}
}

@book{metcalfeMetacognitionKnowingKnowing1994a,
  title = {Metacognition: Knowing about Knowing},
  shorttitle = {Metacognition},
  editor = {Metcalfe, Janet and Shimamura, Arthur P.},
  date = {1994},
  publisher = {{MIT Press}},
  location = {{Cambridge, Mass}},
  isbn = {978-0-262-13298-5},
  pagetotal = {334},
  keywords = {Cognition,Metacognition},
  file = {/Users/alexten/Zotero/storage/38HNNZX6/Metcalfe and Shimamura - 1994 - Metacognition knowing about knowing.pdf}
}

@article{metcalfeMetacognitiveJudgmentsControl,
  title = {Metacognitive {{Judgments}} and {{Control}} of {{Study}}},
  author = {Metcalfe, Janet},
  volume = {18},
  number = {3},
  pages = {5},
  abstract = {Recent evidence indicates that people’s judgments of their own learning are causally related to their study behavior and not epiphenomenal. I argue here that people use these metacognitions in an effort to selectively study material in their own region of proximal learning. First they attempt to eliminate materials that are already well learned. Then they progress successively from studying easier to more difficult materials. Successful implementation of this metacognitively guided strategy enhances learning. The necessary components are, first, that the metacognitions be accurate, and second, that the appropriate choices are implemented for study. With these parts in place, the individual is in position to effectively take control of his or her own learning.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SLCN2NBC/Metcalfe - Metacognitive Judgments and Control of Study.pdf}
}

@article{metcalfeMetacognitiveJudgmentsControl2009,
  title = {Metacognitive {{Judgments}} and {{Control}} of {{Study}}},
  author = {Metcalfe, Janet},
  date = {2009-06},
  journaltitle = {Current Directions in Psychological Science},
  shortjournal = {Curr Dir Psychol Sci},
  volume = {18},
  number = {3},
  pages = {159--163},
  issn = {0963-7214, 1467-8721},
  doi = {10.1111/j.1467-8721.2009.01628.x},
  url = {http://journals.sagepub.com/doi/10.1111/j.1467-8721.2009.01628.x},
  urldate = {2021-01-22},
  abstract = {Recent evidence indicates that people’s judgments of their own learning are causally related to their study behavior and not epiphenomenal. I argue here that people use these metacognitions in an effort to selectively study material in their own region of proximal learning. First they attempt to eliminate materials that are already well learned. Then they progress successively from studying easier to more difficult materials. Successful implementation of this metacognitively guided strategy enhances learning. The necessary components are, first, that the metacognitions be accurate, and second, that the appropriate choices are implemented for study. With these parts in place, the individual is in position to effectively take control of his or her own learning.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/M57PT8LU/Metcalfe - 2009 - Metacognitive Judgments and Control of Study.pdf}
}

@article{metcalfePeopleStudyTime2010,
  title = {People's Study Time Allocation and Its Relation to Animal Foraging},
  author = {Metcalfe, Janet and Jacobs, W. Jake},
  date = {2010-02},
  journaltitle = {Behavioural Processes},
  shortjournal = {Behavioural Processes},
  volume = {83},
  number = {2},
  pages = {213--221},
  issn = {03766357},
  doi = {10.1016/j.beproc.2009.12.011},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0376635709002575},
  urldate = {2021-01-22},
  abstract = {In this article we suggest a relation between people’s metacognitively guided study time allocation strategies and animal foraging. These two domains are similar insofar as people use specific metacognitive cues to assist their study time allocation just as other species use cues, such as scent marking. People decline to study items that they know they already know, just as other species use a win-shift strategy – avoiding already visited and depleted patches – in foraging. People selectively study the easiest as-yet-unlearned items first, before turning to more difficult items just as other species take the ‘just right’ size and challenge of prey—the so-called Goldilocks principle. People use a stop rule by which they give up on one item and turn to another when the returns diminish just as others species use a stop rule that guides shifting from one patch to another. The value that each item is assigned on the criterion test, if known during study, influences which items people choose to study and how long they study them just as knowledge of the nutritional or energy value of the food influences choices and perseverance in foraging. Finally, study time allocation strategies can differ in their effectiveness depending upon the expertise of the student just as some species forage close to optimally while others do not.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FY4H58ZW/Metcalfe and Jacobs - 2010 - People's study time allocation and its relation to.pdf}
}

@article{metcalfePeopleStudyTime2010a,
  title = {People’s Study Time Allocation and Its Relation to Animal Foraging},
  author = {Metcalfe, Janet and Jacobs, W Jake},
  date = {2010},
  journaltitle = {Behavioural Processes},
  pages = {9},
  abstract = {In this article we suggest a relation between people’s metacognitively guided study time allocation strategies and animal foraging. These two domains are similar insofar as people use specific metacognitive cues to assist their study time allocation just as other species use cues, such as scent marking. People decline to study items that they know they already know, just as other species use a win-shift strategy – avoiding already visited and depleted patches – in foraging. People selectively study the easiest as-yet-unlearned items first, before turning to more difficult items just as other species take the ‘just right’ size and challenge of prey—the so-called Goldilocks principle. People use a stop rule by which they give up on one item and turn to another when the returns diminish just as others species use a stop rule that guides shifting from one patch to another. The value that each item is assigned on the criterion test, if known during study, influences which items people choose to study and how long they study them just as knowledge of the nutritional or energy value of the food influences choices and perseverance in foraging. Finally, study time allocation strategies can differ in their effectiveness depending upon the expertise of the student just as some species forage close to optimally while others do not.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7RU943R2/Metcalfe and Jacobs - 2010 - People’s study time allocation and its relation to.pdf}
}

@article{metcalfeRegionProximalLearning2005,
  title = {A {{Region}} of {{Proximal Learning}} Model of Study Time Allocation},
  author = {Metcalfe, Janet and Kornell, Nate},
  date = {2005-05},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {52},
  number = {4},
  pages = {463--477},
  issn = {0749596X},
  doi = {10.1016/j.jml.2004.12.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X04001330},
  urldate = {2021-01-22},
  abstract = {A Region of Proximal Learning model is proposed emphasizing two components to peopleÕs study time allocation, controlled by different metacognitive indices. The first component is choice, which is further segmented into two stages: (1) a decision of whether to study or not and (2) the order of priority of items chosen. If the peopleÕs Judgments of Learning (JOLs) are sufficiently high that they believe they know the items already, they will choose to not study. If they do choose to study, the order is from that which they believe is almost known to that which they believe is more difficult (high JOL to low JOL). The second component is perseverance, with emphasis on the rule for stopping studying once study has begun on an item. We propose that people use a previously unexplored process-oriented metacognitive marker: their judgments of the rate of learning (jROLs), to decide when to stop. When learning is proceeding quickly and the jROL value is high they continue studying. When the jROL approaches zero, and their subjective assessment indicates learning is at a standstill they stop. The extant literature bearing on this model is reviewed, and eight new experiments, all of which support the model, are presented.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/LTDZY63D/Metcalfe and Kornell - 2005 - A Region of Proximal Learning model of study time .pdf}
}

@article{metcalfeRegionProximalLearning2005a,
  title = {A {{Region}} of {{Proximal Learning}} Model of Study Time Allocationq},
  author = {Metcalfe, Janet and Kornell, Nate},
  date = {2005},
  journaltitle = {Journal of Memory and Language},
  pages = {16},
  abstract = {A Region of Proximal Learning model is proposed emphasizing two components to peopleÕs study time allocation, controlled by different metacognitive indices. The first component is choice, which is further segmented into two stages: (1) a decision of whether to study or not and (2) the order of priority of items chosen. If the peopleÕs Judgments of Learning (JOLs) are sufficiently high that they believe they know the items already, they will choose to not study. If they do choose to study, the order is from that which they believe is almost known to that which they believe is more difficult (high JOL to low JOL). The second component is perseverance, with emphasis on the rule for stopping studying once study has begun on an item. We propose that people use a previously unexplored process-oriented metacognitive marker: their judgments of the rate of learning (jROLs), to decide when to stop. When learning is proceeding quickly and the jROL value is high they continue studying. When the jROL approaches zero, and their subjective assessment indicates learning is at a standstill they stop. The extant literature bearing on this model is reviewed, and eight new experiments, all of which support the model, are presented.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/P5FFNSUM/Metcalfe and Kornell - 2005 - A Region of Proximal Learning model of study time .pdf}
}

@article{metcalfeStudyTimeAllocated,
  title = {Is {{Study Time Allocated Selectively}} to a {{Region}} of {{Proximal Learning}}?},
  author = {Metcalfe, Janet},
  pages = {15},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BTJEW48N/Metcalfe - 2002 - Is study time allocated selectively to a region of.pdf;/Users/alexten/Zotero/storage/QHCP2ZED/Metcalfe - Is Study Time Allocated Selectively to a Region of.pdf}
}

@article{metcalfeTipofthetongueStateCuriosity2017,
  title = {The Tip-of-the-Tongue State and Curiosity},
  author = {Metcalfe, Janet and Schwartz, Bennett L. and Bloom, Paul A.},
  date = {2017-12},
  journaltitle = {Cognitive Research: Principles and Implications},
  shortjournal = {Cogn. Research},
  volume = {2},
  number = {1},
  pages = {31},
  issn = {2365-7464},
  doi = {10.1186/s41235-017-0065-4},
  url = {https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-017-0065-4},
  urldate = {2021-01-22},
  abstract = {Theories of study time allocation and of curiosity suggest that people are most engaged with and want to devote their time to materials that are not completely mastered but also are not so difficult that they might be impossible. Their curiosity is thought to be triggered by items that are almost known, or are in what is sometimes called the region of proximal learning. Answers that are on the tip-of-the-tongue (TOT)—not immediately recallable but nevertheless evoking a feeling of imminent recall—seem, intuitively, to be materials that have this characteristic of being almost, but not quite, fully known. We therefore, hypothesized that people would be particularly curious to see the answers to questions for which the answers were on the tips of their tongues. To test the TOT curiosity hypothesis, we gave participants 82 general information questions and quickly asked whether the answers were or were not on the tips of their tongues and whether they wanted to see the answers later. Overwhelmingly, items that were accompanied by a TOT feeling were those which evoked participants’ curiosity, regardless of whether the feeling occurred in conjunction with an error of commission, an error of omission, or even with the correct answer.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/B64BLRVE/Metcalfe et al. - 2017 - The tip-of-the-tongue state and curiosity.pdf}
}

@article{metcalfeTipofthetongueStateCuriosity2017a,
  title = {The Tip-of-the-Tongue State and Curiosity},
  author = {Metcalfe, Janet and Schwartz, Bennett L. and Bloom, Paul A.},
  date = {2017-12},
  journaltitle = {Cognitive Research: Principles and Implications},
  shortjournal = {Cogn. Research},
  volume = {2},
  number = {1},
  pages = {31},
  issn = {2365-7464},
  doi = {10.1186/s41235-017-0065-4},
  url = {https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-017-0065-4},
  urldate = {2021-01-22},
  abstract = {Theories of study time allocation and of curiosity suggest that people are most engaged with and want to devote their time to materials that are not completely mastered but also are not so difficult that they might be impossible. Their curiosity is thought to be triggered by items that are almost known, or are in what is sometimes called the region of proximal learning. Answers that are on the tip-of-the-tongue (TOT)—not immediately recallable but nevertheless evoking a feeling of imminent recall—seem, intuitively, to be materials that have this characteristic of being almost, but not quite, fully known. We therefore, hypothesized that people would be particularly curious to see the answers to questions for which the answers were on the tips of their tongues. To test the TOT curiosity hypothesis, we gave participants 82 general information questions and quickly asked whether the answers were or were not on the tips of their tongues and whether they wanted to see the answers later. Overwhelmingly, items that were accompanied by a TOT feeling were those which evoked participants’ curiosity, regardless of whether the feeling occurred in conjunction with an error of commission, an error of omission, or even with the correct answer.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WQI4VU3K/Metcalfe et al. - 2017 - The tip-of-the-tongue state and curiosity.pdf}
}

@article{meynielConfidenceBayesianProbability,
  title = {Confidence as {{Bayesian Probability}}: {{From Neural Origins}} to {{Behavior}}},
  author = {Meyniel, Florent},
  pages = {15},
  abstract = {Confidence from Distributions the notion of readout: a process that extracts summary statistics from distributional representations.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DS2QXQ2F/Meyniel - Confidence as Bayesian Probability From Neural Or.pdf;/Users/alexten/Zotero/storage/IFIYK5P4/Meyniel et al. - 2015 - Confidence as Bayesian Probability From Neural Or.pdf}
}

@article{middlebrooksTestExpectancyMemory2017,
  title = {Test Expectancy and Memory for Important Information.},
  author = {Middlebrooks, Catherine D. and Murayama, Kou and Castel, Alan D.},
  date = {2017-06},
  journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  shortjournal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {43},
  number = {6},
  pages = {972--985},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/xlm0000360},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xlm0000360},
  urldate = {2021-01-22},
  abstract = {Prior research suggests that learners study and remember information differently depending upon the type of test they expect to later receive. The current experiments investigate how testing expectations impact the study of and memory for valuable information. Participants studied lists of words ranging in value from 1–10 points with the goal being to maximize their score on a later memory test. Half of the participants were told to expect a recognition test after each list, while the other half were told to expect a recall test. After several lists of receiving tests congruent with expectations, participants studying for a recognition test instead received an unexpected recall test. In Experiment 1, participants who had studied for a recognition test recalled less of the valuable information than participants anticipating the recall format. These participants continued to attend less to item value on future (expected) recall tests than participants who had only ever experienced recall testing. When the recognition tests were made more demanding in Experiment 2, valuebased recall improved relative to Experiment 1: though memory for the valuable information remained superior when participants studied with the expectation of having to recall the information, there were no longer significant differences after accounting for recall testing experience. Thus, recall-based testing encouraged strategic, value-based encoding and enhanced retrieval of important information, while recognition testing in some cases limited value-based study and memory. These results extend prior work concerning the impact of testing expectations on memory, offering further insight into how people study important information.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/C6ESKHXJ/Middlebrooks et al. - 2017 - Test expectancy and memory for important informati.pdf}
}

@article{middlebrooksTestExpectancyMemory2017a,
  title = {Test Expectancy and Memory for Important Information.},
  author = {Middlebrooks, Catherine D. and Murayama, Kou and Castel, Alan D.},
  date = {2017-06},
  journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  shortjournal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {43},
  number = {6},
  pages = {972--985},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/xlm0000360},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xlm0000360},
  urldate = {2021-01-22},
  abstract = {Prior research suggests that learners study and remember information differently depending upon the type of test they expect to later receive. The current experiments investigate how testing expectations impact the study of and memory for valuable information. Participants studied lists of words ranging in value from 1–10 points with the goal being to maximize their score on a later memory test. Half of the participants were told to expect a recognition test after each list, while the other half were told to expect a recall test. After several lists of receiving tests congruent with expectations, participants studying for a recognition test instead received an unexpected recall test. In Experiment 1, participants who had studied for a recognition test recalled less of the valuable information than participants anticipating the recall format. These participants continued to attend less to item value on future (expected) recall tests than participants who had only ever experienced recall testing. When the recognition tests were made more demanding in Experiment 2, valuebased recall improved relative to Experiment 1: though memory for the valuable information remained superior when participants studied with the expectation of having to recall the information, there were no longer significant differences after accounting for recall testing experience. Thus, recall-based testing encouraged strategic, value-based encoding and enhanced retrieval of important information, while recognition testing in some cases limited value-based study and memory. These results extend prior work concerning the impact of testing expectations on memory, offering further insight into how people study important information.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FBUETLKD/Middlebrooks et al. - 2017 - Test expectancy and memory for important informati.pdf}
}

@article{mieleMotivatedComprehensionRegulation,
  title = {Motivated Comprehension Regulation: {{Vigilant}} versus Eager Metacognitive Control},
  author = {Miele, David B and Molden, Daniel C and Gardner, Wendi L},
  pages = {18},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BXMZE6ET/Miele et al. - Motivated comprehension regulation Vigilant versu.pdf}
}

@article{mieleMotivatedComprehensionRegulation2009,
  title = {Motivated Comprehension Regulation: {{Vigilant}} versus Eager Metacognitive Control},
  shorttitle = {Motivated Comprehension Regulation},
  author = {Miele, David B. and Molden, Daniel C. and Gardner, Wendi L.},
  date = {2009-09},
  journaltitle = {Memory \& Cognition},
  shortjournal = {Memory \& Cognition},
  volume = {37},
  number = {6},
  pages = {779--795},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/MC.37.6.779},
  url = {http://link.springer.com/10.3758/MC.37.6.779},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WQSMSEDP/Miele et al. - 2009 - Motivated comprehension regulation Vigilant versu.pdf}
}

@article{mildnerSpontaneousThoughtUnconstrained,
  title = {Spontaneous {{Thought}} as an {{Unconstrained Memory Process}}},
  author = {Mildner, Judith N},
  journaltitle = {Trends in Neurosciences},
  pages = {15},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2ZRDAFY5/Mildner - Spontaneous Thought as an Unconstrained Memory Pro.pdf}
}

@article{mildnerSpontaneousThoughtUnconstrained2019,
  title = {Spontaneous {{Thought}} as an {{Unconstrained Memory Process}}},
  author = {Mildner, Judith N. and Tamir, Diana I.},
  date = {2019-11},
  journaltitle = {Trends in Neurosciences},
  shortjournal = {Trends in Neurosciences},
  volume = {42},
  number = {11},
  pages = {763--777},
  issn = {01662236},
  doi = {10.1016/j.tins.2019.09.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166223619301626},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/K7XXHD42/Mildner and Tamir - 2019 - Spontaneous Thought as an Unconstrained Memory Pro.pdf}
}

@article{millerMeasurementTheoryCurrent,
  title = {Measurement, {{Theory}}, and {{Current Issues}} in {{Metacognition}}: {{An Overview}}},
  author = {Miller, Tyler M},
  pages = {15},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CLQCDHC2/Miller - Measurement, Theory, and Current Issues in Metacog.pdf}
}

@incollection{millerMeasurementTheoryCurrent2017,
  title = {Measurement, {{Theory}}, and {{Current Issues}} in {{Metacognition}}: {{An Overview}}},
  shorttitle = {Measurement, {{Theory}}, and {{Current Issues}} in {{Metacognition}}},
  booktitle = {{{ACS Symposium Series}}},
  author = {Miller, Tyler M.},
  editor = {Daubenmire, Patrick L.},
  date = {2017-01},
  volume = {1269},
  pages = {1--15},
  publisher = {{American Chemical Society}},
  location = {{Washington, DC}},
  doi = {10.1021/bk-2017-1269.ch001},
  url = {https://pubs.acs.org/doi/abs/10.1021/bk-2017-1269.ch001},
  urldate = {2021-01-22},
  isbn = {978-0-8412-3270-9 978-0-8412-3269-3},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WUZLZ88F/Miller - 2017 - Measurement, Theory, and Current Issues in Metacog.pdf}
}

@report{millidgeCombiningActiveInference2019,
  type = {preprint},
  title = {Combining {{Active Inference}} and {{Hierarchical Predictive Coding}}: {{A Tutorial Introduction}} and {{Case Study}}},
  shorttitle = {Combining {{Active Inference}} and {{Hierarchical Predictive Coding}}},
  author = {Millidge, Beren},
  date = {2019-03-11},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/kf6wc},
  url = {https://osf.io/kf6wc},
  urldate = {2021-03-12},
  abstract = {This paper combines the active inference formulation of action (Friston et al., 2009) with hierarchical predictive coding models (Friston, 2003) to provide a proof-of-concept implementation of an active inference agent able to solve a common reinforcement learning baseline – the cart-pole environment in OpenAI gym. It demonstrates empirically that predictive coding and active inference approaches can be successfully scaled up to tasks more challenging than the mountain car (Friston et al., 2009, 2012). We show that hierarchical predictive coding models can be learned from scratch during the task, and can successfully drive action selection via active inference. To our knowledge, it is the first implemented active inference agent to combine active inference with a hierarchical predictive coding perceptual model. We also provide a tutorial walk-through of the free-energy principle, hierarchical predictive coding, and active inference, including an in-depth derivation of our agent.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NJGI5LP2/Millidge - 2019 - Combining Active Inference and Hierarchical Predic.pdf}
}

@article{mirolliFunctionsMechanismsIntrinsic,
  title = {Functions and {{Mechanisms}} of {{Intrinsic Motivations}}},
  author = {Mirolli, Marco and Baldassarre, Gianluca},
  pages = {24},
  abstract = {Mammals, and humans in particular, are endowed with an exceptional capacity for cumulative learning. This capacity crucially depends on the presence of intrinsic motivations, that is, motivations that are directly related not to an organism’s survival and reproduction but rather to its ability to learn. Recently, there have been a number of attempts to model and reproduce intrinsic motivations in artificial systems. Different kinds of intrinsic motivations have been proposed both in psychology and in machine learning and robotics: some are based on the knowledge of the learning system, while others are based on its competence. In this contribution, we discuss the distinction between knowledge-based and competence-based intrinsic motivations with respect to both the functional roles that motivations play in learning and the mechanisms by which those functions are implemented. In particular, after arguing that the principal function of intrinsic motivations consists in allowing the development of a repertoire of skills (rather than of knowledge), we suggest that at least two different sub-functions can be identified: (a) discovering which skills might be acquired and (b) deciding which skill to train when. We propose that in biological organisms, knowledge-based intrinsic motivation mechanisms might implement the former function, whereas competencebased mechanisms might underlie the latter one.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GVPVSW9W/Mirolli and Baldassarre - Functions and Mechanisms of Intrinsic Motivations.pdf}
}

@inproceedings{misraLearningAskingQuestions2018,
  title = {Learning by {{Asking Questions}}},
  booktitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Misra, Ishan and Girshick, Ross and Fergus, Rob and Hebert, Martial and Gupta, Abhinav and van der Maaten, Laurens},
  options = {useprefix=true},
  date = {2018-06},
  pages = {11--20},
  publisher = {{IEEE}},
  location = {{Salt Lake City, UT, USA}},
  doi = {10.1109/CVPR.2018.00009},
  url = {https://ieeexplore.ieee.org/document/8578107/},
  urldate = {2021-01-22},
  abstract = {We introduce an interactive learning framework for the development and testing of intelligent visual systems, called learning-by-asking (LBA). We explore LBA in context of the Visual Question Answering (VQA) task. LBA differs from standard VQA training in that most questions are not observed during training time, and the learner must ask questions it wants answers to. Thus, LBA more closely mimics natural learning and has the potential to be more dataefficient than the traditional VQA setting. We present a model that performs LBA on the CLEVR dataset, and show that it automatically discovers an easy-to-hard curriculum when learning interactively from an oracle. Our LBA generated data consistently matches or outperforms the CLEVR train data and is more sample efficient. We also show that our model asks questions that generalize to state-of-the-art VQA models and to novel test time distributions.},
  eventtitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-6420-9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BXSJSQ9E/Misra et al. - 2018 - Learning by Asking Questions.pdf}
}

@inproceedings{misraLearningAskingQuestions2018a,
  title = {Learning by {{Asking Questions}}},
  booktitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Misra, Ishan and Girshick, Ross and Fergus, Rob and Hebert, Martial and Gupta, Abhinav and van der Maaten, Laurens},
  options = {useprefix=true},
  date = {2018-06},
  pages = {11--20},
  publisher = {{IEEE}},
  location = {{Salt Lake City, UT, USA}},
  doi = {10.1109/CVPR.2018.00009},
  url = {https://ieeexplore.ieee.org/document/8578107/},
  urldate = {2021-01-22},
  abstract = {We introduce an interactive learning framework for the development and testing of intelligent visual systems, called learning-by-asking (LBA). We explore LBA in context of the Visual Question Answering (VQA) task. LBA differs from standard VQA training in that most questions are not observed during training time, and the learner must ask questions it wants answers to. Thus, LBA more closely mimics natural learning and has the potential to be more dataefficient than the traditional VQA setting. We present a model that performs LBA on the CLEVR dataset, and show that it automatically discovers an easy-to-hard curriculum when learning interactively from an oracle. Our LBA generated data consistently matches or outperforms the CLEVR train data and is more sample efficient. We also show that our model asks questions that generalize to state-of-the-art VQA models and to novel test time distributions.},
  eventtitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-6420-9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/YLAV29WG/Misra et al. - 2018 - Learning by Asking Questions.pdf}
}

@article{moldenCATEGORIZATIONUNCERTAINTYRESOLVING,
  title = {{{CATEGORIZATION UNDER UNCERTAINTY}}: {{RESOLVING VAGUENESS AND AMBIGUITY WITH EAGER VERSUS VIGILANT STRATEGIES}}},
  author = {Molden, Daniel C and Higgins, E Tory},
  pages = {32},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DI3PCMWH/Molden and Higgins - CATEGORIZATION UNDER UNCERTAINTY RESOLVING VAGUEN.pdf;/Users/alexten/Zotero/storage/HSS5MX3D/Molden and Higgins - CATEGORIZATION UNDER UNCERTAINTY RESOLVING VAGUEN.pdf}
}

@article{moreyFallacyPlacingConfidence,
  title = {The Fallacy of Placing Confidence in Confidence Intervals},
  author = {Morey, Richard D},
  journaltitle = {Psychon Bull Rev},
  pages = {21},
  abstract = {Interval estimates – estimates of parameters that include an allowance for sampling uncertainty – have long been touted as a key component of statistical analyses. There are several kinds of interval estimates, but the most popular are confidence intervals (CIs): intervals that contain the true parameter value in some known proportion of repeated samples, on average. The width of confidence intervals is thought to index the precision of an estimate; CIs are thought to be a guide to which parameter values are plausible or reasonable; and the confidence coefficient of the interval (e.g., 95 \%) is thought to index the plausibility that the true parameter is included in the interval. We show in a number of examples that CIs do not necessarily have any of these properties, and can lead to unjustified or arbitrary inferences. For this reason, we caution against relying upon confidence interval theory to justify interval estimates, and suggest that other theories of interval estimation should be used instead.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MERS7MVZ/Morey - The fallacy of placing confidence in confidence in.pdf}
}

@article{moreyFallacyPlacingConfidence2016,
  title = {The Fallacy of Placing Confidence in Confidence Intervals},
  author = {Morey, Richard D and Hoekstra, Rink and Rouder, Jeffrey N and Lee, Michael D and Wagenmakers, Eric-Jan},
  date = {2016},
  journaltitle = {Psychon Bull Rev},
  pages = {21},
  abstract = {Interval estimates – estimates of parameters that include an allowance for sampling uncertainty – have long been touted as a key component of statistical analyses. There are several kinds of interval estimates, but the most popular are confidence intervals (CIs): intervals that contain the true parameter value in some known proportion of repeated samples, on average. The width of confidence intervals is thought to index the precision of an estimate; CIs are thought to be a guide to which parameter values are plausible or reasonable; and the confidence coefficient of the interval (e.g., 95 \%) is thought to index the plausibility that the true parameter is included in the interval. We show in a number of examples that CIs do not necessarily have any of these properties, and can lead to unjustified or arbitrary inferences. For this reason, we caution against relying upon confidence interval theory to justify interval estimates, and suggest that other theories of interval estimation should be used instead.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/VJ48F6VQ/Morey et al. - 2016 - The fallacy of placing confidence in confidence in.pdf}
}

@article{moreyFallacyPlacingConfidence2016a,
  title = {The Fallacy of Placing Confidence in Confidence Intervals},
  author = {Morey, Richard D and Hoekstra, Rink and Rouder, Jeffrey N and Lee, Michael D and Wagenmakers, Eric-Jan},
  date = {2016},
  journaltitle = {Psychon Bull Rev},
  pages = {21},
  abstract = {Interval estimates – estimates of parameters that include an allowance for sampling uncertainty – have long been touted as a key component of statistical analyses. There are several kinds of interval estimates, but the most popular are confidence intervals (CIs): intervals that contain the true parameter value in some known proportion of repeated samples, on average. The width of confidence intervals is thought to index the precision of an estimate; CIs are thought to be a guide to which parameter values are plausible or reasonable; and the confidence coefficient of the interval (e.g., 95 \%) is thought to index the plausibility that the true parameter is included in the interval. We show in a number of examples that CIs do not necessarily have any of these properties, and can lead to unjustified or arbitrary inferences. For this reason, we caution against relying upon confidence interval theory to justify interval estimates, and suggest that other theories of interval estimation should be used instead.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2KUIGWRN/Morey et al. - 2016 - The fallacy of placing confidence in confidence in.pdf}
}

@article{moreyFallacyPlacingConfidencea,
  title = {The Fallacy of Placing Confidence in Confidence Intervals},
  author = {Morey, Richard D},
  journaltitle = {Psychon Bull Rev},
  pages = {21},
  abstract = {Interval estimates – estimates of parameters that include an allowance for sampling uncertainty – have long been touted as a key component of statistical analyses. There are several kinds of interval estimates, but the most popular are confidence intervals (CIs): intervals that contain the true parameter value in some known proportion of repeated samples, on average. The width of confidence intervals is thought to index the precision of an estimate; CIs are thought to be a guide to which parameter values are plausible or reasonable; and the confidence coefficient of the interval (e.g., 95 \%) is thought to index the plausibility that the true parameter is included in the interval. We show in a number of examples that CIs do not necessarily have any of these properties, and can lead to unjustified or arbitrary inferences. For this reason, we caution against relying upon confidence interval theory to justify interval estimates, and suggest that other theories of interval estimation should be used instead.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/LLFZDSF3/Morey - The fallacy of placing confidence in confidence in.pdf}
}

@article{murayamaDonAimToo,
  title = {Don’t {{Aim Too High}} for {{Your Kids}}: {{Parental Overaspiration Undermines Students}}’ {{Learning}} in {{Mathematics}}},
  author = {Murayama, Kou and Pekrun, Reinhard and Suzuki, Masayuki and Marsh, Herbert W and Lichtenfeld, Stephanie},
  pages = {14},
  abstract = {Previous research has suggested that parents’ aspirations for their children’s academic attainment can have a positive influence on children’s actual academic performance. Possible negative effects of parental overaspiration, however, have found little attention in the psychological literature. Employing a dualchange score model with longitudinal data from a representative sample of German school children and their parents (N ϭ 3,530; Grades 5 to 10), we showed that parental aspiration and children’s mathematical achievement were linked by positive reciprocal relations over time. Importantly, we also found that parental aspiration that exceeded their expectation (i.e., overaspiration) had negative reciprocal relations with children’s mathematical achievement. These results were fairly robust after controlling for a variety of demographic and cognitive variables such as children’s gender, age, intelligence, school type, and family socioeconomic status. The results were also replicated with an independent sample of U.S. parents and their children. These findings suggest that unrealistically high parental aspiration can be detrimental for children’s achievement.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Q2GAFJJV/Murayama et al. - Don’t Aim Too High for Your Kids Parental Overasp.pdf}
}

@article{murayamaHowSelfDeterminedChoice,
  title = {How {{Self}}-{{Determined Choice Facilitates Performance}}: {{A Key Role}} of the {{Ventromedial Prefrontal Cortex}}},
  author = {Murayama, Kou and Matsumoto, Madoka and Izuma, Keise and Sugiura, Ayaka and Ryan, Richard M and Deci, Edward L and Matsumoto, Kenji},
  pages = {12},
  abstract = {Recent studies have documented that self-determined choice does indeed enhance performance. However, the precise neural mechanisms underlying this effect are not well understood. We examined the neural correlates of the facilitative effects of self-determined choice using functional magnetic resonance imaging (fMRI). Participants played a game-like task involving a stopwatch with either a stopwatch they selected (self-determined-choice condition) or one they were assigned without choice (forced-choice condition). Our results showed that self-determined choice enhanced performance on the stopwatch task, despite the fact that the choices were clearly irrelevant to task difficulty. Neuroimaging results showed that failure feedback, compared with success feedback, elicited a drop in the vmPFC activation in the forced-choice condition, but not in the selfdetermined-choice condition, indicating that negative reward value associated with the failure feedback vanished in the self-determinedchoice condition. Moreover, the vmPFC resilience to failure in the self-determined-choice condition was significantly correlated with the increased performance. Striatal responses to failure and success feedback were not modulated by the choice condition, indicating the dissociation between the vmPFC and striatal activation pattern. These findings suggest that the vmPFC plays a unique and critical role in the facilitative effects of self-determined choice on performance.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ICUPXCST/Murayama et al. - How Self-Determined Choice Facilitates Performance.pdf}
}

@article{murayamaNeuralBasisUndermining2010,
  title = {Neural Basis of the Undermining Effect of Monetary Reward on Intrinsic Motivation},
  author = {Murayama, K. and Matsumoto, M. and Izuma, K. and Matsumoto, K.},
  date = {2010-12-07},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proceedings of the National Academy of Sciences},
  volume = {107},
  number = {49},
  pages = {20911--20916},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1013305107},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1013305107},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5SY4G3IW/Murayama et al. - 2010 - Neural basis of the undermining effect of monetary.pdf}
}

@article{murayamaNeuralBasisUndermining2010a,
  title = {Neural Basis of the Undermining Effect of Monetary Reward on Intrinsic Motivation},
  author = {Murayama, K. and Matsumoto, M. and Izuma, K. and Matsumoto, K.},
  date = {2010-12-07},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proceedings of the National Academy of Sciences},
  volume = {107},
  number = {49},
  pages = {20911--20916},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1013305107},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1013305107},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/C9X278NT/Murayama et al. - 2010 - Neural basis of the undermining effect of monetary.pdf}
}

@article{murayamaPeopleNaiveteHow,
  title = {People’s {{Naiveté About How Extrinsic Rewards Inﬂuence Intrinsic Motivation}}},
  author = {Murayama, Kou and Tanaka, Ayumi and Kitagami, Shinji},
  pages = {5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/E52TCRUK/Murayama et al. - People’s Naiveté About How Extrinsic Rewards Inﬂue.pdf}
}

@article{murayamaPeopleNaiveteHowa,
  title = {People’s {{Naiveté About How Extrinsic Rewards Inﬂuence Intrinsic Motivation}}},
  author = {Murayama, Kou and Tanaka, Ayumi and Kitagami, Shinji},
  pages = {5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ILFNX6XB/Murayama et al. - People’s Naiveté About How Extrinsic Rewards Inﬂue.pdf}
}

@article{murayamaProcessAccountCuriosity,
  title = {Process {{Account}} of {{Curiosity}} and {{Interest}}: {{A Reward}}-{{Learning Perspective}}},
  author = {Murayama, Kou and FitzGibbon, Lily and Sakaki, Michiko},
  journaltitle = {Educational Psychology Review},
  pages = {21},
  abstract = {Previous studies suggested roles for curiosity and interest in knowledge acquisition and exploration, but there has been a long-standing debate about how to define these concepts and whether they are related or different. In this paper, we address the definition issue by arguing that there is inherent difficulty in defining curiosity and interest, because both curiosity and interest are naïve concepts, which are not supposed to have a priori scientific definitions. We present a reward-learning framework of autonomous knowledge acquisition and use this framework to illustrate the importance of process account as an alternative to advance our understanding of curiosity and interest without being troubled by their definitions. The framework centers on the role of rewarding experience associated with knowledge acquisition and learning and posits that the acquisition of new knowledge strengthens the value of further information. Critically, we argue that curiosity and interest are the concepts that they subjectively construe through this knowledge-acquisition process. Finally, we discuss the implications of the reward-learning framework for education and empirical research in educational psychology.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/F8VI4Y9F/Murayama et al. - Process Account of Curiosity and Interest A Rewar.pdf}
}

@article{myungTutorialAdaptiveDesign2013,
  title = {A Tutorial on Adaptive Design Optimization},
  author = {Myung, Jay I. and Cavagnaro, Daniel R. and Pitt, Mark A.},
  date = {2013-06},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {57},
  number = {3-4},
  pages = {53--67},
  issn = {00222496},
  doi = {10.1016/j.jmp.2013.05.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249613000503},
  urldate = {2021-01-22},
  abstract = {Experimentation is ubiquitous in the field of psychology and fundamental to the advancement of its science, and one of the biggest challenges for researchers is designing experiments that can conclusively discriminate the theoretical hypotheses or models under investigation. The recognition of this challenge has led to the development of sophisticated statistical methods that aid in the design of experiments and that are within the reach of everyday experimental scientists. This tutorial paper introduces the reader to an implementable experimentation methodology, dubbed Adaptive Design Optimization, that can help scientists to conduct “smart” experiments that are maximally informative and highly efficient, which in turn should accelerate scientific discovery in psychology and beyond.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CJM28BJ7/Myung et al. - 2013 - A tutorial on adaptive design optimization.pdf;/Users/alexten/Zotero/storage/DMNWR5DN/Myung et al. - 2013 - A tutorial on adaptive design optimization.pdf}
}

@article{myungTutorialMaximumLikelihood2003,
  title = {Tutorial on Maximum Likelihood Estimation},
  author = {Myung, In Jae},
  date = {2003-02},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {47},
  number = {1},
  pages = {90--100},
  issn = {00222496},
  doi = {10.1016/S0022-2496(02)00028-7},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249602000287},
  urldate = {2021-01-22},
  abstract = {In this paper, I provide a tutorial exposition on maximum likelihood estimation (MLE). The intended audience of this tutorial are researchers who practice mathematical modeling of cognition but are unfamiliar with the estimation method. Unlike least-squares estimation which is primarily a descriptive tool, MLE is a preferred method of parameter estimation in statistics and is an indispensable tool for many statistical modeling techniques, in particular in non-linear modeling with non-normal data. The purpose of this paper is to provide a good conceptual explanation of the method with illustrative examples so the reader can have a grasp of some of the basic principles.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6K4UIV5D/Myung - 2003 - Tutorial on maximum likelihood estimation.pdf}
}

@article{myungTutorialMaximumLikelihood2003a,
  title = {Tutorial on Maximum Likelihood Estimation},
  author = {Myung, In Jae},
  date = {2003-02},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {47},
  number = {1},
  pages = {90--100},
  issn = {00222496},
  doi = {10.1016/S0022-2496(02)00028-7},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249602000287},
  urldate = {2021-01-22},
  abstract = {In this paper, I provide a tutorial exposition on maximum likelihood estimation (MLE). The intended audience of this tutorial are researchers who practice mathematical modeling of cognition but are unfamiliar with the estimation method. Unlike least-squares estimation which is primarily a descriptive tool, MLE is a preferred method of parameter estimation in statistics and is an indispensable tool for many statistical modeling techniques, in particular in non-linear modeling with non-normal data. The purpose of this paper is to provide a good conceptual explanation of the method with illustrative examples so the reader can have a grasp of some of the basic principles.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UKD9M8BY/Myung - 2003 - Tutorial on maximum likelihood estimation.pdf}
}

@article{naselarisCognitiveComputationalNeuroscience,
  title = {Cognitive {{Computational Neuroscience}}: {{A New Conference}} for an {{Emerging Discipline}}},
  author = {Naselaris, Thomas and Bassett, Danielle S and Fletcher, Alyson K and Kording, Konrad and Kriegeskorte, Nikolaus and Nienborg, Hendrikje and Poldrack, Russell A and Shohamy, Daphna and Kay, Kendrick},
  pages = {3},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/XU2HL4T5/Naselaris et al. - Cognitive Computational Neuroscience A New Confer.pdf;/Users/alexten/Zotero/storage/YXG487ZK/Naselaris et al. - Cognitive Computational Neuroscience A New Confer.pdf}
}

@article{navajasIdiosyncraticNatureConfidence2017,
  title = {The Idiosyncratic Nature of Confidence},
  author = {Navajas, Joaquin and Hindocha, Chandni and Foda, Hebah and Keramati, Mehdi and Latham, Peter E. and Bahrami, Bahador},
  date = {2017-11},
  journaltitle = {Nature Human Behaviour},
  shortjournal = {Nat Hum Behav},
  volume = {1},
  number = {11},
  pages = {810--818},
  issn = {2397-3374},
  doi = {10.1038/s41562-017-0215-1},
  url = {http://www.nature.com/articles/s41562-017-0215-1},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/82GVJR5C/Navajas et al. - 2017 - The idiosyncratic nature of confidence.pdf}
}

@incollection{nelsonMetamemoryTheoreticalFramework1990,
  title = {Metamemory: {{A Theoretical Framework}} and {{New Findings}}},
  shorttitle = {Metamemory},
  booktitle = {Psychology of {{Learning}} and {{Motivation}}},
  author = {Nelson, Thomas O. and Narens, Louis},
  date = {1990},
  volume = {26},
  pages = {125--173},
  publisher = {{Elsevier}},
  doi = {10.1016/S0079-7421(08)60053-5},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0079742108600535},
  urldate = {2021-01-22},
  abstract = {Although there has been excellent research by many investigators on the topic of metamemory, here we will focus on our own research program. This article will begin with a description of a theoretical framework that has evolved out of metamemory research, followed by a few remarks about our methodology, and will end with a review of our previously unpublished findings. (Our published findings will not be systematically reviewed here; instead, they will be mentioned only when necessary for continuity).},
  isbn = {978-0-12-543326-6},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MCLEV6YA/Nelson - 1990 - Metamemory A Theoretical Framework and New Findin.pdf}
}

@article{nichollsAchievementMotivationConceptions,
  title = {Achievement {{Motivation}}: {{Conceptions}} of {{Ability}}, {{Subjective Experience}}, {{Task Choice}}, and {{Performance}}},
  author = {Nicholls, John G},
  journaltitle = {ACHIEVEMENT MOTIVATION},
  pages = {19},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FWFE4K7B/Nicholls - Achievement Motivation Conceptions of Ability, Su.pdf;/Users/alexten/Zotero/storage/JGWD8DSF/Nicholls - Achievement Motivation Conceptions of Ability, Su.pdf}
}

@article{nieminenStandardisedRegressionCoefficient2013,
  title = {Standardised Regression Coefficient as an Effect Size Index in Summarising the Reported Findings between Quantitative Exposure and Response Variables in Epidemiological Studies},
  author = {Nieminen, Pentti and Lehtiniemi, Heli and Vähäkangas, Kirsi and Huusko, Antti and Rautio, Arja},
  date = {2013-09-02},
  journaltitle = {Epidemiology, Biostatistics and Public Health},
  issn = {22820930},
  doi = {10.2427/8854},
  url = {https://doi.org/10.2427/8854},
  urldate = {2021-01-22},
  abstract = {Background: a major problem in evaluating and reviewing the published findings of studies on the association between a quantitative explanatory variable and a quantitative dependent variable is that the results are analysed and reported in many different ways. To achieve an effective review of different studies, a consistent presentation of the results is necessary. This paper aims to exemplify the main topics related to summarising and pooling research findings from multivariable models with a quantitative response variable. Methods: we outline the complexities involved in synthesising associations. We describe a method by which it is possible to transform the findings into a common effect size index which is based on standardised regression coefficients. To describe the approach we searched original research articles published before January 2012 for findings of the relationship between polychlorinated biphenyls (PCBs) and birth weight of new-borns. Studies with maternal PCB measurements and birth weight as a continuous variable were included. Results: the evaluation of 24 included articles reveled that there was variation in variable measurement methods, transformations, descriptive statistics and inference methods. Research syntheses were performed summarizing regression coefficients to estimate the effect of PCBs on birth weight. A birth weight decline related to increase in PCB level was found. ConclusionS: the proposed method can be useful in quantitatively reviewing published studies when different exposure measurement methods are used or differential control of potential confounding factors is not an issue.},
  issue = {Authors' Manuscripts},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GYI8X77J/Nieminen et al. - 2013 - Standardised regression coefficient as an effect s.pdf}
}

@article{nivDopamineUncertaintyTD2005,
  title = {Dopamine, Uncertainty and {{TD}} Learning},
  author = {Niv, Yael and Duff, Michael O and Dayan, Peter},
  date = {2005},
  journaltitle = {Behavioral and Brain Functions},
  pages = {9},
  abstract = {Substantial evidence suggests that the phasic activities of dopaminergic neurons in the primate midbrain represent a temporal difference (TD) error in predictions of future reward, with increases above and decreases below baseline consequent on positive and negative prediction errors, respectively. However, dopamine cells have very low baseline activity, which implies that the representation of these two sorts of error is asymmetric. We explore the implications of this seemingly innocuous asymmetry for the interpretation of dopaminergic firing patterns in experiments with probabilistic rewards which bring about persistent prediction errors. In particular, we show that when averaging the non-stationary prediction errors across trials, a ramping in the activity of the dopamine neurons should be apparent, whose magnitude is dependent on the learning rate. This exact phenomenon was observed in a recent experiment, though being interpreted there in antipodal terms as a within-trial encoding of uncertainty.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/AB5TF42D/Niv et al. - 2005 - Dopamine, uncertainty and TD learning.pdf;/Users/alexten/Zotero/storage/W4KN8CS5/Niv et al. - 2005 - Dopamine, uncertainty and TD learning.pdf}
}

@article{noguchiAttractionCompromiseSimilarity2014,
  title = {In the Attraction, Compromise, and Similarity Effects, Alternatives Are Repeatedly Compared in Pairs on Single Dimensions},
  author = {Noguchi, Takao},
  date = {2014},
  pages = {13},
  abstract = {In multi-alternative choice, the attraction, compromise, and similarity effects demonstrate that the value of an alternative is not independent of the other alternatives in the choiceset. Rather, these effects suggest that a choice is reached through the comparison of alternatives. We investigated exactly how alternatives are compared against each other using eye-movement data. The results indicate that a series of comparisons is made in each choice, with a pair of alternatives compared on a single attribute dimension in each comparison. We conclude that psychological models of choice should be based on these singleattribute pairwise comparisons.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5WD4F3S4/Noguchi - 2014 - In the attraction, compromise, and similarity effe.pdf;/Users/alexten/Zotero/storage/YG6FHBJD/Noguchi - 2014 - In the attraction, compromise, and similarity effe.pdf}
}

@article{noordewierCuriosityTimeNot2017,
  title = {Curiosity and Time: From Not Knowing to Almost Knowing},
  shorttitle = {Curiosity and Time},
  author = {Noordewier, Marret K. and van Dijk, Eric},
  options = {useprefix=true},
  date = {2017-04-03},
  journaltitle = {Cognition and Emotion},
  shortjournal = {Cognition and Emotion},
  volume = {31},
  number = {3},
  pages = {411--421},
  issn = {0269-9931, 1464-0600},
  doi = {10.1080/02699931.2015.1122577},
  url = {https://www.tandfonline.com/doi/full/10.1080/02699931.2015.1122577},
  urldate = {2021-01-22},
  abstract = {How does it feel to be curious? We reasoned that there are two sides to curiosity: not knowing something (i.e. information-gap) and almost knowing something (i.e. anticipation of resolution). In three experiments, we showed that time affects the relative impact of these two components: When people did not expect to close their information-gap soon (long time-to-resolution) not knowing affected the subjective experience of curiosity more strongly than when they expected to close their information-gap quickly (short time-to-resolution). As such, people experienced less positive affect, more discomfort, and more annoyance with lack of information in a long than a short time-to-resolution situation. Moreover, when time in the long time-to-resolution setting passed, the anticipation of the resolution became stronger, positive affect increased, and discomfort and annoyance with lack of information decreased. Time is thus a key factor in the experience of curiosity.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/57N7Q3MJ/Noordewier and van Dijk - 2017 - Curiosity and time from not knowing to almost kno.pdf;/Users/alexten/Zotero/storage/TSTKK7L4/Noordewier - Curiosity and time from not knowing to almost kno.pdf}
}

@article{noordewierInterestComplexNovelty2016,
  title = {Interest in {{Complex Novelty}}},
  author = {Noordewier, Marret K. and van Dijk, Eric},
  options = {useprefix=true},
  date = {2016-03-03},
  journaltitle = {Basic and Applied Social Psychology},
  shortjournal = {Basic and Applied Social Psychology},
  volume = {38},
  number = {2},
  pages = {98--110},
  issn = {0197-3533, 1532-4834},
  doi = {10.1080/01973533.2016.1153474},
  url = {https://www.tandfonline.com/doi/full/10.1080/01973533.2016.1153474},
  urldate = {2021-01-22},
  abstract = {Complex novelty like new technologies can be exciting in terms of promising possibilities, but people might also feel that they do not exactly grasp its meaning or purpose. We argue that to become interested in complex novelty, it is key that people have a sense that they can cope with it. In three experiments we showed that people who have relatively high coping potential are more interested in complex novelty than people who have relatively low coping potential. Specifically, interest in complex novel products and inventions increased after increasing product-specific understanding (Experiments 1 and 2) and after inducing a more general state in which people can tolerate complex novelty (Experiment 3). Theoretical and practical implications are discussed.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3SAQQAYY/Noordewier and van Dijk - 2016 - Interest in Complex Novelty.pdf;/Users/alexten/Zotero/storage/4B74QJ5X/Noordewier and van Dijk - 2016 - Interest in Complex Novelty.pdf}
}

@incollection{noweGentleIntroductionReinforcement2016,
  title = {A {{Gentle Introduction}} to {{Reinforcement Learning}}},
  booktitle = {Scalable {{Uncertainty Management}}},
  author = {Nowé, Ann and Brys, Tim},
  editor = {Schockaert, Steven and Senellart, Pierre},
  date = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {9858},
  pages = {18--32},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-45856-4_2},
  url = {http://link.springer.com/10.1007/978-3-319-45856-4_2},
  urldate = {2021-03-12},
  abstract = {This paper provides a gentle introduction to some of the basics of reinforcement learning, as well as pointers to more advanced topics within the field.},
  isbn = {978-3-319-45855-7 978-3-319-45856-4},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3RGYEKNA/Nowé and Brys - 2016 - A Gentle Introduction to Reinforcement Learning.pdf}
}

@article{oreillyMakingPredictionsChanging2013,
  title = {Making Predictions in a Changing World—Inference, Uncertainty, and Learning},
  author = {O'Reilly, Jill X.},
  date = {2013},
  journaltitle = {Frontiers in Neuroscience},
  shortjournal = {Front. Neurosci.},
  volume = {7},
  issn = {1662-453X},
  doi = {10.3389/fnins.2013.00105},
  url = {http://journal.frontiersin.org/article/10.3389/fnins.2013.00105/abstract},
  urldate = {2021-01-22},
  abstract = {To function effectively, brains need to make predictions about their environment based on past experience, i.e., they need to learn about their environment. The algorithms by which learning occurs are of interest to neuroscientists, both in their own right (because they exist in the brain) and as a tool to model participants’ incomplete knowledge of task parameters and hence, to better understand their behavior. This review focusses on a particular challenge for learning algorithms—how to match the rate at which they learn to the rate of change in the environment, so that they use as much observed data as possible whilst disregarding irrelevant, old observations. To do this algorithms must evaluate whether the environment is changing. We discuss the concepts of likelihood, priors and transition functions, and how these relate to change detection. We review expected and estimation uncertainty, and how these relate to change detection and learning rate. Finally, we consider the neural correlates of uncertainty and learning. We argue that the neural correlates of uncertainty bear a resemblance to neural systems that are active when agents actively explore their environments, suggesting that the mechanisms by which the rate of learning is set may be subject to top down control (in circumstances when agents actively seek new information) as well as bottom up control (by observations that imply change in the environment).},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SYAUSFYK/O'Reilly - 2013 - Making predictions in a changing world—inference, .pdf}
}

@article{oreillyMakingPredictionsChanging2013a,
  title = {Making Predictions in a Changing World—Inference, Uncertainty, and Learning},
  author = {O'Reilly, Jill X.},
  date = {2013},
  journaltitle = {Frontiers in Neuroscience},
  shortjournal = {Front. Neurosci.},
  volume = {7},
  issn = {1662-453X},
  doi = {10.3389/fnins.2013.00105},
  url = {http://journal.frontiersin.org/article/10.3389/fnins.2013.00105/abstract},
  urldate = {2021-01-22},
  abstract = {To function effectively, brains need to make predictions about their environment based on past experience, i.e., they need to learn about their environment. The algorithms by which learning occurs are of interest to neuroscientists, both in their own right (because they exist in the brain) and as a tool to model participants’ incomplete knowledge of task parameters and hence, to better understand their behavior. This review focusses on a particular challenge for learning algorithms—how to match the rate at which they learn to the rate of change in the environment, so that they use as much observed data as possible whilst disregarding irrelevant, old observations. To do this algorithms must evaluate whether the environment is changing. We discuss the concepts of likelihood, priors and transition functions, and how these relate to change detection. We review expected and estimation uncertainty, and how these relate to change detection and learning rate. Finally, we consider the neural correlates of uncertainty and learning. We argue that the neural correlates of uncertainty bear a resemblance to neural systems that are active when agents actively explore their environments, suggesting that the mechanisms by which the rate of learning is set may be subject to top down control (in circumstances when agents actively seek new information) as well as bottom up control (by observations that imply change in the environment).},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/AIXXRIHJ/O'Reilly - 2013 - Making predictions in a changing world—inference, .pdf}
}

@online{oudeyerComputationalTheoriesCuriosityDriven2018,
  title = {Computational {{Theories}} of {{Curiosity}}-{{Driven Learning}}},
  author = {Oudeyer, Pierre-Yves},
  date = {2018-06-18},
  eprint = {1802.10546},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1802.10546},
  urldate = {2021-01-22},
  abstract = {What are the functions of curiosity? What are the mechanisms of curiosity-driven learning? We approach these questions about the living using concepts and tools from machine learning and developmental robotics. We argue that curiosity-driven learning enables organisms to make discoveries to solve complex problems with rare or deceptive rewards. By fostering exploration and discovery of a diversity of behavioural skills, and ignoring these rewards, curiosity can be efficient to bootstrap learning when there is no information, or deceptive information, about local improvement towards these problems. We also explain the key role of curiosity for efficient learning of world models. We review both normative and heuristic computational frameworks used to understand the mechanisms of curiosity in humans, conceptualizing the child as a sense-making organism. These frameworks enable us to discuss the bi-directional causal links between curiosity and learning, and to provide new hypotheses about the fundamental role of curiosity in self-organizing developmental structures through curriculum learning. We present various developmental robotics experiments that study these mechanisms in action, both supporting these hypotheses to understand better curiosity in humans and opening new research avenues in machine learning and artificial intelligence. Finally, we discuss challenges for the design of experimental paradigms for studying curiosity in psychology and cognitive neuroscience.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/alexten/Zotero/storage/JXL9JAUQ/Oudeyer - 2018 - Computational Theories of Curiosity-Driven Learnin.pdf;/Users/alexten/Zotero/storage/LM8SI9RN/Oudeyer - 2018 - Computational Theories of Curiosity-Driven Learnin.pdf}
}

@article{oudeyerHowEvolutionMay2016,
  title = {How {{Evolution May Work Through Curiosity}}-{{Driven Developmental Process}}},
  author = {Oudeyer, Pierre-Yves and Smith, Linda B},
  date = {2016},
  journaltitle = {Topics in Cognitive Science},
  pages = {11},
  abstract = {Infants’ own activities create and actively select their learning experiences. Here we review recent models of embodied information seeking and curiosity-driven learning and show that these mechanisms have deep implications for development and evolution. We discuss how these mechanisms yield self-organized epigenesis with emergent ordered behavioral and cognitive developmental stages. We describe a robotic experiment that explored the hypothesis that progress in learning, in and for itself, generates intrinsic rewards: The robot learners probabilistically selected experiences according to their potential for reducing uncertainty. In these experiments, curiositydriven learning led the robot learner to successively discover object affordances and vocal interaction with its peers. We explain how a learning curriculum adapted to the current constraints of the learning system automatically formed, constraining learning and shaping the developmental trajectory. The observed trajectories in the robot experiment share many properties with those in infant development, including a mixture of regularities and diversities in the developmental patterns. Finally, we argue that such emergent developmental structures can guide and constrain evolution, in particular with regard to the origins of language.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/H8KEBJ2E/Oudeyer and Smith - 2016 - How Evolution May Work Through Curiosity-Driven De.pdf;/Users/alexten/Zotero/storage/UQNMSD2Z/Oudeyer and Smith - 2016 - How Evolution May Work Through Curiosity-Driven De.pdf}
}

@article{oudeyerIntrinsicMotivationSystems2007,
  title = {Intrinsic {{Motivation Systems}} for {{Autonomous Mental Development}}},
  author = {Oudeyer, Pierre-Yves and Kaplan, Frdric and Hafner, Verena V.},
  date = {2007-04},
  journaltitle = {IEEE Transactions on Evolutionary Computation},
  shortjournal = {IEEE Trans. Evol. Computat.},
  volume = {11},
  number = {2},
  pages = {265--286},
  issn = {1089-778X},
  doi = {10.1109/TEVC.2006.890271},
  url = {http://ieeexplore.ieee.org/document/4141061/},
  urldate = {2021-01-22},
  abstract = {Exploratory activities seem to be intrinsically rewarding for children and crucial for their cognitive development. Can a machine be endowed with such an intrinsic motivation system? This is the question we study in this paper, presenting a number of computational systems that try to capture this drive towards novel or curious situations. After discussing related research coming from developmental psychology, neuroscience, developmental robotics, and active learning, this paper presents the mechanism of Intelligent Adaptive Curiosity, an intrinsic motivation system which pushes a robot towards situations in which it maximizes its learning progress. This drive makes the robot focus on situations which are neither too predictable nor too unpredictable, thus permitting autonomous mental development. The complexity of the robot’s activities autonomously increases and complex developmental sequences self-organize without being constructed in a supervised manner. Two experiments are presented illustrating the stage-like organization emerging with this mechanism. In one of them, a physical robot is placed on a baby play mat with objects that it can learn to manipulate. Experimental results show that the robot first spends time in situations which are easy to learn, then shifts its attention progressively to situations of increasing difficulty, avoiding situations in which nothing can be learned. Finally, these various results are discussed in relation to more complex forms of behavioral organization and data coming from developmental psychology.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/H3ZRGH5Y/Oudeyer et al. - 2007 - Intrinsic Motivation Systems for Autonomous Mental.pdf;/Users/alexten/Zotero/storage/KJ7HD9V2/Oudeyer et al. - 2007 - Intrinsic Motivation Systems for Autonomous Mental.pdf}
}

@article{oudeyerWhatIntrinsicMotivation2007,
  title = {What Is Intrinsic Motivation? {{A}} Typology of Computational Approaches},
  author = {Oudeyer, Pierre-Yves and Kaplan, Frederic},
  date = {2007},
  journaltitle = {Frontiers in Neurorobotics},
  volume = {1},
  pages = {14},
  abstract = {Intrinsic motivation, centrally involved in spontaneous exploration and curiosity, is a crucial concept in developmental psychology. It has been argued to be a crucial mechanism for open-ended cognitive development in humans, and as such has gathered a growing interest from developmental roboticists in the recent years. The goal of this paper is threefold. First, it provides a synthesis of the different approaches of intrinsic motivation in psychology. Second, by interpreting these approaches in a computational reinforcement learning framework, we argue that they are not operational and even sometimes inconsistent. Third, we set the ground for a systematic operational study of intrinsic motivation by presenting a formal typology of possible computational approaches. This typology is partly based on existing computational models, but also presents new ways of conceptualizing intrinsic motivation. We argue that this kind of computational typology might be useful for opening new avenues for research both in psychology and developmental robotics.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2ZYIT3Z4/Oudeyer - 2007 - What is intrinsic motivation A typology of comput.pdf;/Users/alexten/Zotero/storage/XLI6KY8X/Oudeyer and Kaplan - 2007 - What is intrinsic motivation A typology of comput.pdf}
}

@article{palmerEssentialismSelectionismCognitive1992,
  title = {Essentialism and {{Selectionism}} in {{Cognitive Science}} and {{Behavior Analysis}}},
  author = {Palmer, David C and College, Smith and Donahoe, John W},
  date = {1992},
  journaltitle = {American Psychologist},
  pages = {16},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/VE4M4VRN/Palmer et al. - 1992 - Essentialism and Selectionism in Cognitive Science.pdf;/Users/alexten/Zotero/storage/YVKKW8NX/Palmer et al. - 1992 - Essentialism and Selectionism in Cognitive Science.pdf}
}

@article{palminteriImportanceFalsificationComputational,
  title = {The {{Importance}} of {{Falsification}} in {{Computational Cognitive Modeling}}},
  author = {Palminteri, Stefano},
  pages = {9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CVAEPUYE/Palminteri - The Importance of Falsification in Computational C.pdf}
}

@article{palminteriImportanceFalsificationComputational2017,
  title = {The {{Importance}} of {{Falsification}} in {{Computational Cognitive Modeling}}},
  author = {Palminteri, Stefano and Wyart, Valentin and Koechlin, Etienne},
  date = {2017-06},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {21},
  number = {6},
  pages = {425--433},
  issn = {13646613},
  doi = {10.1016/j.tics.2017.03.011},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661317300542},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2U58AWMB/Palminteri et al. - 2017 - The Importance of Falsification in Computational C.pdf}
}

@article{parrAttentionSalience2019,
  title = {Attention or Salience?},
  author = {Parr, Thomas},
  date = {2019},
  journaltitle = {Current Opinion in Psychology},
  pages = {5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/R2U4E7JS/Parr - 2019 - Attention or salience.pdf}
}

@article{pasqualiKnowThyselfMetacognitive2010,
  title = {Know Thyself: {{Metacognitive}} Networks and Measures of Consciousness},
  shorttitle = {Know Thyself},
  author = {Pasquali, Antoine and Timmermans, Bert and Cleeremans, Axel},
  date = {2010-11},
  journaltitle = {Cognition},
  shortjournal = {Cognition},
  volume = {117},
  number = {2},
  pages = {182--190},
  issn = {00100277},
  doi = {10.1016/j.cognition.2010.08.010},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027710001794},
  urldate = {2021-01-22},
  abstract = {Subjective measures of awareness rest on the assumption that conscious knowledge is knowledge that participants know they possess. Post-Decision Wagering (PDW), recently proposed as a new measure of awareness, requires participants to place a high or a low wager on their decisions. Whereas advantageous wagering indicates awareness of the knowledge on which the decisions are based, cases in which participants fail to optimize their wagers suggest performance without awareness. Here, we hypothesize that wagering and other subjective measures of awareness reflect metacognitive capacities subtended by self-developed metarepresentations that inform an agent about its own internal states. To support this idea, we present three simulations in which neural networks learn to wager on their own responses. The simulations illustrate essential properties that are required for such metarepresentations to influence PDW as a measure of awareness. Results demonstrate a good fit to human data. We discuss the implications of this modeling work for our understanding of consciousness and its measures.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QMH2SGML/Pasquali et al. - 2010 - Know thyself Metacognitive networks and measures .pdf}
}

@article{pasqualiKnowThyselfMetacognitive2010a,
  title = {Know Thyself: {{Metacognitive}} Networks and Measures of Consciousness},
  author = {Pasquali, Antoine},
  date = {2010},
  pages = {9},
  abstract = {Subjective measures of awareness rest on the assumption that conscious knowledge is knowledge that participants know they possess. Post-Decision Wagering (PDW), recently proposed as a new measure of awareness, requires participants to place a high or a low wager on their decisions. Whereas advantageous wagering indicates awareness of the knowledge on which the decisions are based, cases in which participants fail to optimize their wagers suggest performance without awareness. Here, we hypothesize that wagering and other subjective measures of awareness reflect metacognitive capacities subtended by self-developed metarepresentations that inform an agent about its own internal states. To support this idea, we present three simulations in which neural networks learn to wager on their own responses. The simulations illustrate essential properties that are required for such metarepresentations to influence PDW as a measure of awareness. Results demonstrate a good fit to human data. We discuss the implications of this modeling work for our understanding of consciousness and its measures.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/XHDZ68FA/Pasquali - 2010 - Know thyself Metacognitive networks and measures .pdf}
}

@online{pathakCuriositydrivenExplorationSelfsupervised2017,
  title = {Curiosity-Driven {{Exploration}} by {{Self}}-Supervised {{Prediction}}},
  author = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A. and Darrell, Trevor},
  date = {2017-05-15},
  eprint = {1705.05363},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1705.05363},
  urldate = {2021-01-22},
  abstract = {In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent’s ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (e.g. new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/LXYLGDBB/Pathak et al. - 2017 - Curiosity-driven Exploration by Self-supervised Pr.pdf;/Users/alexten/Zotero/storage/XT6KFZHJ/Pathak et al. - 2017 - Curiosity-driven Exploration by Self-supervised Pr.pdf}
}

@article{pecinaHedonicHotSpots2006,
  title = {Hedonic {{Hot Spots}} in the {{Brain}}},
  author = {Peciña, Susana and Smith, Kyle S and Berridge, Kent C},
  date = {2006},
  volume = {12},
  number = {6},
  pages = {12},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/G8DJM2VU/Peciña et al. - 2006 - Hedonic Hot Spots in the Brain.pdf;/Users/alexten/Zotero/storage/R96PJUR5/Peciña et al. - 2006 - Hedonic Hot Spots in the Brain.pdf}
}

@article{pekrunPowerAnticipatedFeedback2014,
  title = {The Power of Anticipated Feedback: {{Effects}} on Students' Achievement Goals and Achievement Emotions},
  author = {Pekrun, Reinhard},
  date = {2014},
  journaltitle = {Learning and Instruction},
  pages = {10},
  abstract = {In an experimental study (N ¼ 153 high school students), we tested a theoretical model positing that anticipated achievement feedback influences achievement goals and achievement emotions, and that achievement goals mediate the link between anticipated feedback and emotions. Participants were informed that they would receive self-referential feedback, normative feedback, or no feedback for their performance on a test. Subsequently, achievement goals and discrete achievement emotions regarding the test were assessed. Self-referential feedback had a positive influence on mastery goal adoption, whereas normative feedback had a positive influence on performance-approach and performanceavoidance goal adoption. Furthermore, feedback condition and achievement goals predicted testrelated emotions (i.e., enjoyment, hope, pride, relief, anger, anxiety, hopelessness, and shame). Achievement goals were documented as significant mediators of the influence of feedback instruction on emotions, and mediation was observed for seven of the eight focal emotions. Implications for educational research and practice are discussed.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SBJC3V5X/Pekrun - 2014 - The power of anticipated feedback Effects on stud.pdf}
}

@article{pekrunPowerAnticipatedFeedback2014a,
  title = {The Power of Anticipated Feedback: {{Effects}} on Students' Achievement Goals and Achievement Emotions},
  shorttitle = {The Power of Anticipated Feedback},
  author = {Pekrun, Reinhard and Cusack, Aisling and Murayama, Kou and Elliot, Andrew J. and Thomas, Kevin},
  date = {2014-02},
  journaltitle = {Learning and Instruction},
  shortjournal = {Learning and Instruction},
  volume = {29},
  pages = {115--124},
  issn = {09594752},
  doi = {10.1016/j.learninstruc.2013.09.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959475213000637},
  urldate = {2021-01-22},
  abstract = {In an experimental study (N ¼ 153 high school students), we tested a theoretical model positing that anticipated achievement feedback influences achievement goals and achievement emotions, and that achievement goals mediate the link between anticipated feedback and emotions. Participants were informed that they would receive self-referential feedback, normative feedback, or no feedback for their performance on a test. Subsequently, achievement goals and discrete achievement emotions regarding the test were assessed. Self-referential feedback had a positive influence on mastery goal adoption, whereas normative feedback had a positive influence on performance-approach and performanceavoidance goal adoption. Furthermore, feedback condition and achievement goals predicted testrelated emotions (i.e., enjoyment, hope, pride, relief, anger, anxiety, hopelessness, and shame). Achievement goals were documented as significant mediators of the influence of feedback instruction on emotions, and mediation was observed for seven of the eight focal emotions. Implications for educational research and practice are discussed.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ZEQ8RVQD/Pekrun et al. - 2014 - The power of anticipated feedback Effects on stud.pdf}
}

@article{pelleyMetacognitiveMonkeysAssociative,
  title = {Metacognitive {{Monkeys}} or {{Associative Animals}}? {{Simple Reinforcement Learning Explains Uncertainty}} in {{Nonhuman Animals}}},
  author = {Pelley, M E Le},
  pages = {23},
  abstract = {Monkeys will selectively and adaptively learn to avoid the most difficult trials of a perceptual discrimination learning task. Couchman, Coutinho, Beran, and Smith (2010) have recently demonstrated that this pattern of responding does not depend on animals receiving trial-by-trial feedback for their responses; it also obtains if experience of the most difficult trials occurs only under conditions of deferred feedback. Couchman et al. argued that this ruled out accounts based on low-level processes of associative learning and instead required explanation in terms of metacognitive processes of decision monitoring. Contrary to this argument, a simple associative model of reinforcement learning is shown to account for the key findings of Couchman et al.’s empirical study, along with several other findings that have previously been claimed to challenge associative models.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/VGYGQPAW/Pelley - Metacognitive Monkeys or Associative Animals Simp.pdf}
}

@article{pelleyMetacognitiveMonkeysAssociativea,
  title = {Metacognitive {{Monkeys}} or {{Associative Animals}}? {{Simple Reinforcement Learning Explains Uncertainty}} in {{Nonhuman Animals}}},
  author = {Pelley, M E Le},
  pages = {23},
  abstract = {Monkeys will selectively and adaptively learn to avoid the most difficult trials of a perceptual discrimination learning task. Couchman, Coutinho, Beran, and Smith (2010) have recently demonstrated that this pattern of responding does not depend on animals receiving trial-by-trial feedback for their responses; it also obtains if experience of the most difficult trials occurs only under conditions of deferred feedback. Couchman et al. argued that this ruled out accounts based on low-level processes of associative learning and instead required explanation in terms of metacognitive processes of decision monitoring. Contrary to this argument, a simple associative model of reinforcement learning is shown to account for the key findings of Couchman et al.’s empirical study, along with several other findings that have previously been claimed to challenge associative models.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IEKJL8SG/Pelley - Metacognitive Monkeys or Associative Animals Simp.pdf}
}

@online{pereUnsupervisedLearningGoal2018,
  title = {Unsupervised {{Learning}} of {{Goal Spaces}} for {{Intrinsically Motivated Goal Exploration}}},
  author = {Péré, Alexandre and Forestier, Sébastien and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  date = {2018-10-09},
  eprint = {1803.00781},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1803.00781},
  urldate = {2021-01-22},
  abstract = {Intrinsically motivated goal exploration algorithms enable machines to discover repertoires of policies that produce a diversity of effects in complex environments. These exploration algorithms have been shown to allow real world robots to acquire skills such as tool use in high-dimensional continuous state and action spaces. However, they have so far assumed that self-generated goals are sampled in a specifically engineered feature space, limiting their autonomy. In this work, we propose to use deep representation learning algorithms to learn an adequate goal space. This is a developmental 2-stage approach: first, in a perceptual learning stage, deep learning algorithms use passive raw sensor observations of world changes to learn a corresponding latent space; then goal exploration happens in a second stage by sampling goals in this latent space. We present experiments where a simulated robot arm interacts with an object, and we show that exploration algorithms using such learned representations can match the performance obtained using engineered representations.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/alexten/Zotero/storage/EUUYZBZ7/Péré et al. - 2018 - Unsupervised Learning of Goal Spaces for Intrinsic.pdf;/Users/alexten/Zotero/storage/H3QPCA2F/Péré et al. - 2018 - Unsupervised Learning of Goal Spaces for Intrinsic.pdf}
}

@article{persaudPostdecisionWageringObjectively2007,
  title = {Post-Decision Wagering Objectively Measures Awareness},
  author = {Persaud, Navindra and McLeod, Peter and Cowey, Alan},
  date = {2007},
  journaltitle = {TECHNICAL REPORT},
  volume = {10},
  number = {2},
  pages = {5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/55YM2E49/Persaud et al. - 2007 - Post-decision wagering objectively measures awaren.pdf}
}

@article{persaudPostdecisionWageringObjectively2007a,
  title = {Post-Decision Wagering Objectively Measures Awareness},
  author = {Persaud, Navindra and McLeod, Peter and Cowey, Alan},
  date = {2007},
  journaltitle = {TECHNICAL REPORT},
  volume = {10},
  number = {2},
  pages = {5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6I8KC2VF/Persaud et al. - 2007 - Post-decision wagering objectively measures awaren.pdf}
}

@article{petroneEmpiricalBayesMethods2014,
  title = {Empirical {{Bayes}} Methods in Classical and {{Bayesian}} Inference},
  author = {Petrone, Sonia and Rizzelli, Stefano and Rousseau, Judith and Scricciolo, Catia},
  date = {2014-08},
  journaltitle = {METRON},
  shortjournal = {METRON},
  volume = {72},
  number = {2},
  pages = {201--215},
  issn = {0026-1424, 2281-695X},
  doi = {10.1007/s40300-014-0044-1},
  url = {http://link.springer.com/10.1007/s40300-014-0044-1},
  urldate = {2021-05-23},
  abstract = {Empirical Bayes methods are often thought of as a bridge between classical and Bayesian inference. In fact, in the literature the term empirical Bayes is used in quite diverse contexts and with different motivations. In this article, we provide a brief overview of empirical Bayes methods highlighting their scopes and meanings in different problems. We focus on recent results about merging of Bayes and empirical Bayes posterior distributions that regard popular, but otherwise debatable, empirical Bayes procedures as computationally convenient approximations of Bayesian solutions.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NZ88LSX2/Petrone et al. - 2014 - Empirical Bayes methods in classical and Bayesian .pdf}
}

@article{phillipsDecisionConfidenceInformation2014,
  title = {Decision {{Confidence}}, {{Information Usefulness}}, and {{Information Seeking Intention}} in the {{Presence}} of {{Disconfirming Information}}},
  author = {Phillips, Brandon and R. Prybutok, Victor and A. Peak, Daniel},
  date = {2014},
  journaltitle = {Informing Science: The International Journal of an Emerging Transdiscipline},
  shortjournal = {InformingSciJ},
  volume = {17},
  pages = {001--024},
  issn = {1547-9684, 1521-4672},
  doi = {10.28945/1932},
  url = {https://www.informingscience.org/Publications/1932},
  urldate = {2021-01-22},
  abstract = {The increasing use of data visualization for displaying information in a transdisciplinary environment raises issues about client information seeking in the decision-making processes. Field experts and individuals with high confidence tend to seek less information for their decisions than non-experts and individuals who are less confident. This work fills a gap about the effect of the information display format, visual or nonvisual, upon the client’s decision. In the context of data visualization and confirmation bias, this work provides needed research on computer aided information seeking in a decision-making, informing environment. Guided by the theories of confirmation bias and cognitive fit, we propose and test a model that investigates the impact of apriori decision confidence on seeking more information and information usefulness. Findings indicate that both information presentation type and confirmation bias affect the decision process of the information seeker. Findings also indicate that overall, the higher the confidence, the less likely users will find disconfirming evidence useful.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DJ2JVYN5/Phillips et al. - 2014 - Decision Confidence, Information Usefulness, and I.pdf;/Users/alexten/Zotero/storage/G453QRH8/Phillips et al. - Decision Confidence, Information Usefulness, and I.pdf}
}

@article{pignatelliRoleDopamineNeurons,
  title = {Role of {{Dopamine Neurons}} in {{Reward}} and {{Aversion}}: {{A Synaptic Plasticity Perspective}}},
  author = {Pignatelli, Marco},
  pages = {13},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/LQNVVXTX/Pignatelli - Role of Dopamine Neurons in Reward and Aversion A.pdf}
}

@article{pignatelliRoleDopamineNeurons2015,
  title = {Role of {{Dopamine Neurons}} in {{Reward}} and {{Aversion}}: {{A Synaptic Plasticity Perspective}}},
  shorttitle = {Role of {{Dopamine Neurons}} in {{Reward}} and {{Aversion}}},
  author = {Pignatelli, Marco and Bonci, Antonello},
  date = {2015-06},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {86},
  number = {5},
  pages = {1145--1157},
  issn = {08966273},
  doi = {10.1016/j.neuron.2015.04.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315003657},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/33N3KMKI/Pignatelli and Bonci - 2015 - Role of Dopamine Neurons in Reward and Aversion A.pdf}
}

@article{pintrichROLEGOALORIENTATION,
  title = {{{THE ROLE OF GOAL ORIENTATION IN SELF}}-{{REGULATED LEARNING}}},
  author = {Pintrich, Paul R},
  pages = {79},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/B3PXV6SA/Pintrich - THE ROLE OF GOAL ORIENTATION IN SELF-REGULATED LEA.pdf}
}

@incollection{pintrichRoleGoalOrientation2000,
  title = {The {{Role}} of {{Goal Orientation}} in {{Self}}-{{Regulated Learning}}},
  booktitle = {Handbook of {{Self}}-{{Regulation}}},
  author = {Pintrich, Paul R.},
  date = {2000},
  pages = {451--502},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-012109890-2/50043-3},
  url = {https://linkinghub.elsevier.com/retrieve/pii/B9780121098902500433},
  urldate = {2021-01-22},
  isbn = {978-0-12-109890-2},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JYQZ7Q87/Pintrich - 2000 - The Role of Goal Orientation in Self-Regulated Lea.pdf}
}

@article{powellDeconstructingIntellectualCuriosity2016,
  title = {Deconstructing Intellectual Curiosity},
  author = {Powell, Christopher and Nettelbeck, Ted and Burns, Nicholas R.},
  date = {2016-06},
  journaltitle = {Personality and Individual Differences},
  shortjournal = {Personality and Individual Differences},
  volume = {95},
  pages = {147--151},
  issn = {01918869},
  doi = {10.1016/j.paid.2016.02.037},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0191886916300927},
  urldate = {2021-01-22},
  abstract = {Scales of Need for Cognition (NFC), Typical Intellectual Engagement (TIE), and Epistemic Curiosity (EC) measure intellectual curiosity (IC). These scales correlate strongly and have been factor-analyzed individually but not together. Here N = 396 (143 males) undergraduates completed measures of NFC, TIE, and EC. Six factors, labeled Intellectual Avoidance, Deprivation, Problem Solving, Abstract Thinking, Reading, and Wide Interest, were identified. TIE is the broadest scale, measuring all factors except Deprivation; NFC measures Intellectual Avoidance and Problem Solving, plus Abstract Thinking and Deprivation to a lesser degree; and EC largely measures Deprivation. Moreover, Reading may not fit in the IC domain; higher-order factor analysis indicated that, whereas items measuring Reading loaded more strongly on their first-order factor, items measuring the other factors strongly loaded on a general factor of IC. These results are significant for understanding the contents of these scales, and for future scale development.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PW993FW6/Powell et al. - 2016 - Deconstructing intellectual curiosity.pdf;/Users/alexten/Zotero/storage/W6GFC9G8/Powell et al. - 2016 - Deconstructing intellectual curiosity.pdf}
}

@article{primsOverconfidenceLifespan,
  title = {Overconfidence over the Lifespan},
  author = {Prims, Julia P and Moore, Don A},
  journaltitle = {Judgment and Decision Making},
  pages = {13},
  abstract = {This research investigated how different forms of overconfidence correlate with age. Contrary to stereotypes that young people are more overconfident, the results provide little evidence that overestimation of one’s performance or overplacement of one’s performance relative to that of others is correlated with age. Instead, the results suggest that precision in judgment (confidence that one knows the truth) increases with age. This result is strongest for probabilistic elicitations, and not present in quantile elicitations or reported confidence intervals. The results suggest that a lifetime of experience, rather than leading to better calibration, instead may increase our confidence that we know what we’re talking about.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/D7SJ28SD/Prims and Moore - Overconﬁdence over the lifespan.pdf}
}

@article{primsOverconfidenceLifespana,
  title = {Overconfidence over the Lifespan},
  author = {Prims, Julia P and Moore, Don A},
  journaltitle = {Judgment and Decision Making},
  pages = {13},
  abstract = {This research investigated how different forms of overconfidence correlate with age. Contrary to stereotypes that young people are more overconfident, the results provide little evidence that overestimation of one’s performance or overplacement of one’s performance relative to that of others is correlated with age. Instead, the results suggest that precision in judgment (confidence that one knows the truth) increases with age. This result is strongest for probabilistic elicitations, and not present in quantile elicitations or reported confidence intervals. The results suggest that a lifetime of experience, rather than leading to better calibration, instead may increase our confidence that we know what we’re talking about.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/D5XAIP4Y/Prims and Moore - Overconﬁdence over the lifespan.pdf}
}

@article{PrinciplesObjectPerception,
  title = {Principles of {{Object Perception}}},
  pages = {28},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DMR58DAN/Principles of Object Perception.pdf}
}

@article{PrinciplesObjectPerceptiona,
  title = {Principles of {{Object Perception}}},
  pages = {28},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DYI6LAIU/Principles of Object Perception.pdf}
}

@article{pulfordOverconfidenceFeedbackItem,
  title = {Overconfidence: {{Feedback}} and Item Difficulty Effects},
  author = {Pulford, Briony D and Colman, Andrew M},
  pages = {9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IQUUU7ZX/Pulford and Colman - Overconfidence Feedback and item difficulty effec.pdf}
}

@article{pulfordOverconfidenceFeedbackItema,
  title = {Overconfidence: {{Feedback}} and Item Difficulty Effects},
  author = {Pulford, Briony D and Colman, Andrew M},
  pages = {9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GKNM838B/Pulford and Colman - Overconfidence Feedback and item difficulty effec.pdf}
}

@article{pullumSystematicityNaturalLanguage,
  title = {Systematicity and {{Natural Language Syntax}}},
  author = {Pullum, Geoffrey K and Scholz, Barbara C},
  pages = {28},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ZIJRDJQX/Pullum and Scholz - Systematicity and Natural Language Syntax.pdf}
}

@article{pullumSystematicityNaturalLanguagea,
  title = {Systematicity and {{Natural Language Syntax}}},
  author = {Pullum, Geoffrey K and Scholz, Barbara C},
  pages = {28},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/P6NL4X6K/Pullum and Scholz - Systematicity and Natural Language Syntax.pdf}
}

@article{purcellHierarchicalDecisionProcesses2016,
  title = {Hierarchical Decision Processes That Operate over Distinct Timescales Underlie Choice and Changes in Strategy},
  author = {Purcell, Braden A. and Kiani, Roozbeh},
  date = {2016-08-02},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc Natl Acad Sci USA},
  volume = {113},
  number = {31},
  pages = {E4531-E4540},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1524685113},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1524685113},
  urldate = {2021-01-22},
  abstract = {Decision-making in a natural environment depends on a hierarchy of interacting decision processes. A high-level strategy guides ongoing choices, and the outcomes of those choices determine whether or not the strategy should change. When the right decision strategy is uncertain, as in most natural settings, feedback becomes ambiguous because negative outcomes may be due to limited information or bad strategy. Disambiguating the cause of feedback requires active inference and is key to updating the strategy. We hypothesize that the expected accuracy of a choice plays a crucial rule in this inference, and setting the strategy depends on integration of outcome and expectations across choices. We test this hypothesis with a task in which subjects report the net direction of random dot kinematograms with varying difficulty while the correct stimulus−response association undergoes invisible and unpredictable switches every few trials. We show that subjects treat negative feedback as evidence for a switch but weigh it with their expected accuracy. Subjects accumulate switch evidence (in units of log-likelihood ratio) across trials and update their response strategy when accumulated evidence reaches a bound. A computational framework based on these principles quantitatively explains all aspects of the behavior, providing a plausible neural mechanism for the implementation of hierarchical multiscale decision processes. We suggest that a similar neural computation—bounded accumulation of evidence—underlies both the choice and switches in the strategy that govern the choice, and that expected accuracy of a choice represents a key link between the levels of the decision-making hierarchy.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/C7ZIQNDS/Purcell and Kiani - 2016 - Hierarchical decision processes that operate over .pdf;/Users/alexten/Zotero/storage/CVZSTQET/Purcell and Kiani - Hierarchical decision processes that operate over .pdf}
}

@article{QuantifyingMetacognitiveThresholds,
  title = {Quantifying Metacognitive Thresholds Using Signal-Detection Theory},
  pages = {27},
  abstract = {How sure are we about what we know? Confidence, measured via self-report, is often interpreted as a subjective probabilistic estimate on having made a correct judgement. The neurocognitive mechanisms underlying the construction of confidence and the information incorporated into these judgements are of increasing interest. Investigating these mechanisms requires principled and practically applicable measures of confidence and metacognition. Unfortunately, current measures of confidence are subject to distortions from decision biases and task performance. Motivated by a recent signal-detection theoretic behavioural measure of metacognitive sensitivity, known as meta-d’, here we present a quantitative behavioural measure of confidence that is invariant to decision bias and task performance. This measure, which we call m-distance, captures in a principled way the propensity to report decisions with high (or low) confidence. Computational simulations demonstrate the robustness of m-distance to decision bias and task performance, as well as its behaviour under conditions of high and low metacognitive sensitivity and under dualchannel and hierarchical models of metacognition. The introduction of the m-distance measure will enhance systematic quantitative studies of the behavioural expression and neurocognitive basis of subjective confidence.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6EVL7WAT/Quantifying metacognitive thresholds using signal-.pdf}
}

@article{rabovskyModellingN400Brain2018,
  title = {Modelling the {{N400}} Brain Potential as Change in a Probabilistic Representation of Meaning},
  author = {Rabovsky, Milena},
  date = {2018},
  journaltitle = {Nature Human Behaviour},
  volume = {2},
  pages = {15},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/TUFED379/Rabovsky - 2018 - Modelling the N400 brain potential as change in a .pdf}
}

@article{rabovskyModellingN400Brain2018a,
  title = {Modelling the {{N400}} Brain Potential as Change in a Probabilistic Representation of Meaning},
  author = {Rabovsky, Milena},
  date = {2018},
  journaltitle = {Nature Human Behaviour},
  volume = {2},
  pages = {15},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8W8Z5GN7/Rabovsky - 2018 - Modelling the N400 brain potential as change in a .pdf}
}

@report{rahnevConfidenceDatabase2019,
  type = {preprint},
  title = {The {{Confidence Database}}},
  author = {Rahnev, Dobromir and Desender, Kobe and Lee, Alan L. F. and Adler, William T. and Aguilar-Lleyda, David and Akdoğan, Başak and Arbuzova, Polina and Atlas, Lauren Yvette and Balcı, Fuat and Bang, Ji Won and Bègue, Indrit and Birney, Damian P. and Brady, Timothy F. and Calder-Travis, Joshua Michael and Chetverikov, Andrey and Clark, Torin K and Davranche, Karen and Denison, Rachel N. and Dildine, Troy and Double, Kit S and Duyan, Yalçın Akın and Faivre, Nathan and Fallow, Kaitlyn Marie and Filevich, Elisa and {gajdos}, thibault and Gallagher, Regan and de Gardelle, Vincent and Gherman, Sabina and Haddara, Nadia and {hainguerlot}, marine and {tzuyu.hsu} and Hu, Xiao and Jaquiery, Matt and Kantner, Justin and Koculak, Marcin and Konishi, Mahiko and Koß, Christina and Kvam, Peter D. and Kwok, Sze Chai and Lebreton, Maël and Lempert, Karolina Maria and Lo, Chien Ming and Luo, Liang and Maniscalco, Brian and Martin, Antonio and Massoni, Sébastien and Matthews, Julian and Mazancieux, Audrey and Merfeld, Daniel M. and O'Hora, Denis and Palser, Eleanor and Paulewicz, Borysław and Pereira, Michael and Peters, Caroline and Philiastides, Marios G. and Pfuhl, Gerit and Prieto, Fernanda and Rausch, Manuel and Recht, Samuel and Reyes, Gabriel and Rouault, Marion and Sackur, Jérôme and Sadeghi, Saeedeh and Samaha, Jason and Seow, Tricia Xing Fang and Shekhar, Medha and Sherman, Maxine Tamara and Siedlecka, Marta and Skóra, Zuzanna and Song, Chen and Soto, David and Sun, Sai and van Boxtel, Jeroen and Wang, Shuo and Weidemann, Christoph T. and Weindel, Gabriel and Wierzchoń, Michał and Xu, Xinming and Ye, Qun and Yeon, Jiwon and Zou, Futing and Zylberberg, Ariel},
  options = {useprefix=true},
  date = {2019-08-08},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/h8tju},
  url = {https://osf.io/h8tju},
  urldate = {2021-01-22},
  abstract = {Understanding how people rate their confidence is critical for characterizing a wide range of perceptual, memory, motor, and cognitive processes. However, as in many other fields, progress has been slowed by the difficulty of collecting new data and the unavailability of existing data. To address this issue, we created a large database of confidence studies spanning a broad set of paradigms, participant populations, and fields of study. The data from each study are structured in a common, easy-to-use format that can be easily imported and analyzed in multiple software packages. Each dataset is further accompanied by an explanation regarding the nature of the collected data. At the time of publication, the Confidence Database (available at osf.io/s46pr) contained 145 datasets with data from over 8,700 participants and almost 4 million trials. The database will remain open for new submissions indefinitely and is expected to continue to grow. We show the usefulness of this large collection of datasets in four different analyses that provide precise estimation for several foundational confidence-related effects and lead to new findings that depend on the availability of large quantity of data. This Confidence Database will continue to enable new discoveries and can serve as a blueprint for similar databases in related fields.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QV5KYYY6/Rahnev et al. - 2019 - The Confidence Database.pdf}
}

@report{rahnevConfidenceDatabase2019a,
  type = {preprint},
  title = {The {{Confidence Database}}},
  author = {Rahnev, Dobromir and Desender, Kobe and Lee, Alan L. F. and Adler, William T. and Aguilar-Lleyda, David and Akdoğan, Başak and Arbuzova, Polina and Atlas, Lauren Yvette and Balcı, Fuat and Bang, Ji Won and Bègue, Indrit and Birney, Damian P. and Brady, Timothy F. and Calder-Travis, Joshua Michael and Chetverikov, Andrey and Clark, Torin K and Davranche, Karen and Denison, Rachel N. and Dildine, Troy and Double, Kit S and Duyan, Yalçın Akın and Faivre, Nathan and Fallow, Kaitlyn Marie and Filevich, Elisa and {gajdos}, thibault and Gallagher, Regan and de Gardelle, Vincent and Gherman, Sabina and Haddara, Nadia and {hainguerlot}, marine and {tzuyu.hsu} and Hu, Xiao and Jaquiery, Matt and Kantner, Justin and Koculak, Marcin and Konishi, Mahiko and Koß, Christina and Kvam, Peter D. and Kwok, Sze Chai and Lebreton, Maël and Lempert, Karolina Maria and Lo, Chien Ming and Luo, Liang and Maniscalco, Brian and Martin, Antonio and Massoni, Sébastien and Matthews, Julian and Mazancieux, Audrey and Merfeld, Daniel M. and O'Hora, Denis and Palser, Eleanor and Paulewicz, Borysław and Pereira, Michael and Peters, Caroline and Philiastides, Marios G. and Pfuhl, Gerit and Prieto, Fernanda and Rausch, Manuel and Recht, Samuel and Reyes, Gabriel and Rouault, Marion and Sackur, Jérôme and Sadeghi, Saeedeh and Samaha, Jason and Seow, Tricia Xing Fang and Shekhar, Medha and Sherman, Maxine Tamara and Siedlecka, Marta and Skóra, Zuzanna and Song, Chen and Soto, David and Sun, Sai and van Boxtel, Jeroen and Wang, Shuo and Weidemann, Christoph T. and Weindel, Gabriel and Wierzchoń, Michał and Xu, Xinming and Ye, Qun and Yeon, Jiwon and Zou, Futing and Zylberberg, Ariel},
  options = {useprefix=true},
  date = {2019-08-08},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/h8tju},
  url = {https://osf.io/h8tju},
  urldate = {2021-01-22},
  abstract = {Understanding how people rate their confidence is critical for characterizing a wide range of perceptual, memory, motor, and cognitive processes. However, as in many other fields, progress has been slowed by the difficulty of collecting new data and the unavailability of existing data. To address this issue, we created a large database of confidence studies spanning a broad set of paradigms, participant populations, and fields of study. The data from each study are structured in a common, easy-to-use format that can be easily imported and analyzed in multiple software packages. Each dataset is further accompanied by an explanation regarding the nature of the collected data. At the time of publication, the Confidence Database (available at osf.io/s46pr) contained 145 datasets with data from over 8,700 participants and almost 4 million trials. The database will remain open for new submissions indefinitely and is expected to continue to grow. We show the usefulness of this large collection of datasets in four different analyses that provide precise estimation for several foundational confidence-related effects and lead to new findings that depend on the availability of large quantity of data. This Confidence Database will continue to enable new discoveries and can serve as a blueprint for similar databases in related fields.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WDC5Q2K4/Rahnev et al. - 2019 - The Confidence Database.pdf}
}

@article{ralphNeuralComputationalBases,
  title = {The Neural and Computational Bases of Semantic Cognition},
  author = {Ralph, Matthew A Lambon},
  pages = {15},
  abstract = {Semantic cognition refers to our ability to use, manipulate and generalize knowledge that is acquired over the lifespan to support innumerable verbal and non-verbal behaviours. This Review summarizes key findings and issues arising from a decade of research into the neurocognitive and neurocomputational underpinnings of this ability, leading to a new framework that we term controlled semantic cognition (CSC). CSC offers solutions to long-standing queries in philosophy and cognitive science, and yields a convergent framework for understanding the neural and computational bases of healthy semantic cognition and its dysfunction in brain disorders.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EWXK5LHS/Ralph - The neural and computational bases of semantic cog.pdf}
}

@article{ralphNeuralComputationalBases2017,
  title = {The Neural and Computational Bases of Semantic Cognition},
  author = {Ralph, Matthew A. Lambon and Jefferies, Elizabeth and Patterson, Karalyn and Rogers, Timothy T.},
  date = {2017-01},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {18},
  number = {1},
  pages = {42--55},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn.2016.150},
  url = {http://www.nature.com/articles/nrn.2016.150},
  urldate = {2021-01-22},
  abstract = {Semantic cognition refers to our ability to use, manipulate and generalize knowledge that is acquired over the lifespan to support innumerable verbal and non-verbal behaviours. This Review summarizes key findings and issues arising from a decade of research into the neurocognitive and neurocomputational underpinnings of this ability, leading to a new framework that we term controlled semantic cognition (CSC). CSC offers solutions to long-standing queries in philosophy and cognitive science, and yields a convergent framework for understanding the neural and computational bases of healthy semantic cognition and its dysfunction in brain disorders.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/LC7JV425/Ralph et al. - 2017 - The neural and computational bases of semantic cog.pdf}
}

@article{ReasonBasedChoice2012,
  title = {Reason‐based Choice: {{A}} Bargaining Rationale for the Attraction and Compromise Effects},
  date = {2012},
  journaltitle = {Theoretical Economics},
  pages = {38},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/TXFEVJB3/2012 - Reason‐based choice A bargaining rationale for th.pdf}
}

@article{rederStrategySelectionQuestion1987,
  title = {Strategy Selection in Question Answering},
  author = {Reder, Lynne M},
  date = {1987-01},
  journaltitle = {Cognitive Psychology},
  shortjournal = {Cognitive Psychology},
  volume = {19},
  number = {1},
  pages = {90--138},
  issn = {00100285},
  doi = {10.1016/0010-0285(87)90005-3},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0010028587900053},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8FMXRXIF/Reder - 1987 - Strategy selection in question answering.pdf}
}

@article{rederStrategySelectionQuestion1987a,
  title = {Strategy Selection in Question Answering},
  author = {Reder, Lynne M},
  date = {1987-01},
  journaltitle = {Cognitive Psychology},
  shortjournal = {Cognitive Psychology},
  volume = {19},
  number = {1},
  pages = {90--138},
  issn = {00100285},
  doi = {10.1016/0010-0285(87)90005-3},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0010028587900053},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/LKTNH4WV/Reder - 1987 - Strategy selection in question answering.pdf}
}

@article{reverdyModelingHumanDecision,
  title = {Modeling {{Human Decision Making}} in {{Generalized Gaussian Multiarmed Bandits}}},
  author = {Reverdy, Paul B and Leonard, Naomi Ehrich},
  pages = {28},
  abstract = {In this paper, we present a formal model of human multiarmed bandit problem on graphs, we generalize the UCL decision making in explore–exploit tasks using the context of algorithm to the block UCL algorithm and the graphical block multiarmed bandit problems, where the decision maker must UCL algorithm, respectively. We show that these algorithms choose among multiple options with uncertain rewards. We also achieve logarithmic cumulative expected regret and address the standard multiarmed bandit problem, the multi- require a sublogarithmic expected number of transitions armed bandit problem with transition costs, and the multi- among arms. We further illustrate the performance of these armed bandit problem on graphs. We focus on the case of algorithms with numerical examples.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EQEM3IUD/Reverdy and Leonard - Modeling Human Decision Making in Generalized Gaus.pdf}
}

@article{reverdyModelingHumanDecisiona,
  title = {Modeling {{Human Decision Making}} in {{Generalized Gaussian Multiarmed Bandits}}},
  author = {Reverdy, Paul B and Leonard, Naomi Ehrich},
  pages = {28},
  abstract = {In this paper, we present a formal model of human multiarmed bandit problem on graphs, we generalize the UCL decision making in explore–exploit tasks using the context of algorithm to the block UCL algorithm and the graphical block multiarmed bandit problems, where the decision maker must UCL algorithm, respectively. We show that these algorithms choose among multiple options with uncertain rewards. We also achieve logarithmic cumulative expected regret and address the standard multiarmed bandit problem, the multi- require a sublogarithmic expected number of transitions armed bandit problem with transition costs, and the multi- among arms. We further illustrate the performance of these armed bandit problem on graphs. We focus on the case of algorithms with numerical examples.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/L3HMJBB6/Reverdy and Leonard - Modeling Human Decision Making in Generalized Gaus.pdf}
}

@article{reverdyParameterEstimationSoftmax2016,
  title = {Parameter {{Estimation}} in {{Softmax Decision}}-{{Making Models With Linear Objective Functions}}},
  author = {Reverdy, Paul and Leonard, Naomi Ehrich},
  date = {2016},
  journaltitle = {IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING},
  volume = {13},
  number = {1},
  pages = {14},
  abstract = {We contribute to the development of a systematic means to infer features of human decision-making from behavioral data. Motivated by the common use of softmax selection in models of human decision-making, we study the maximum-likelihood (ML) parameter estimation problem for softmax decision-making models with linear objective functions. We present conditions under which the likelihood function is convex. These allow us to provide sufficient conditions for convergence of the resulting ML estimator and to construct its asymptotic distribution. In the case of models with nonlinear objective functions, we show how the estimator can be applied by linearizing about a nominal parameter value. We apply the estimator to fit the stochastic Upper Credible Limit (UCL) model of human decision-making to human subject data. The fits show statistically significant differences in behavior across related, but distinct, tasks.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4KU9CP95/Reverdy and Leonard - 2016 - Parameter Estimation in Softmax Decision-Making Mo.pdf}
}

@article{reverdyParameterEstimationSoftmax2016a,
  title = {Parameter {{Estimation}} in {{Softmax Decision}}-{{Making Models With Linear Objective Functions}}},
  author = {Reverdy, Paul and Leonard, Naomi Ehrich},
  date = {2016},
  journaltitle = {IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING},
  volume = {13},
  number = {1},
  pages = {14},
  abstract = {We contribute to the development of a systematic means to infer features of human decision-making from behavioral data. Motivated by the common use of softmax selection in models of human decision-making, we study the maximum-likelihood (ML) parameter estimation problem for softmax decision-making models with linear objective functions. We present conditions under which the likelihood function is convex. These allow us to provide sufficient conditions for convergence of the resulting ML estimator and to construct its asymptotic distribution. In the case of models with nonlinear objective functions, we show how the estimator can be applied by linearizing about a nominal parameter value. We apply the estimator to fit the stochastic Upper Credible Limit (UCL) model of human decision-making to human subject data. The fits show statistically significant differences in behavior across related, but distinct, tasks.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UHHJQYSR/Reverdy and Leonard - 2016 - Parameter Estimation in Softmax Decision-Making Mo.pdf}
}

@article{roebersExecutiveFunctionMetacognition2017,
  title = {Executive Function and Metacognition: {{Towards}} a Unifying Framework of Cognitive Self-Regulation},
  shorttitle = {Executive Function and Metacognition},
  author = {Roebers, Claudia M.},
  date = {2017-09},
  journaltitle = {Developmental Review},
  shortjournal = {Developmental Review},
  volume = {45},
  pages = {31--51},
  issn = {02732297},
  doi = {10.1016/j.dr.2017.04.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0273229716300132},
  urldate = {2021-01-22},
  abstract = {Executive function and metacognition are higher-order cognitive processes that undergo steady improvements throughout childhood. They are highly relevant to daily functioning in various domains, including academic achievement. Both concepts have been intensively researched, but surprisingly little literature has sought to connect them theoretically and empirically. In the present review, I elaborate on the similarities between these concepts from a developmental perspective, including the definitions, developmental timetables, factors that lead to changes over time, and relations to academic achievement and intelligence. Simultaneously, the differences between these two domains of cognitive development are discussed. These include, in particular, the relative neglect of quantifying monitoring within research on executive functions and the disregard for the neuropsychological underpinnings of metacognition. Finally, this paper presents several avenues for future research and proposes a possible unifying framework of cognitive self-regulation that integrates executive function and metacognition and may lead to a better understanding of the emergence of cognitive self-regulation in development.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6QEZI6D6/Roebers - 2017 - Executive function and metacognition Towards a un.pdf;/Users/alexten/Zotero/storage/ME5W2CIR/Roebers - 2017 - Executive function and metacognition Towards a un.pdf}
}

@article{rollsExpectedValueReward2008,
  title = {Expected {{Value}}, {{Reward Outcome}}, and {{Temporal Difference Error Representations}} in a {{Probabilistic Decision Task}}},
  author = {Rolls, E. T. and McCabe, C. and Redoute, J.},
  date = {2008-03-01},
  journaltitle = {Cerebral Cortex},
  shortjournal = {Cerebral Cortex},
  volume = {18},
  number = {3},
  pages = {652--663},
  issn = {1047-3211, 1460-2199},
  doi = {10.1093/cercor/bhm097},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhm097},
  urldate = {2021-01-22},
  abstract = {In probabilistic decision tasks, an expected value (EV) of a choice is calculated, and after the choice has been made, this can be updated based on a temporal difference (TD) prediction error between the EV and the reward magnitude (RM) obtained. The EV is measured as the probability of obtaining a reward 3 RM. To understand the contribution of different brain areas to these decision-making processes, functional magnetic resonance imaging activations related to EV versus RM (or outcome) were measured in a probabilistic decision task. Activations in the medial orbitofrontal cortex were correlated with both RM and with EV and confirmed in a conjunction analysis to extend toward the pregenual cingulate cortex. From these representations, TD reward prediction errors could be produced. Activations in areas that receive from the orbitofrontal cortex including the ventral striatum, midbrain, and inferior frontal gyrus were correlated with the TD error. Activations in the anterior insula were correlated negatively with EV, occurring when low reward outcomes were expected, and also with the uncertainty of the reward, implicating this region in basic and crucial decision-making parameters, low expected outcomes, and uncertainty.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SDHH4AM2/Rolls et al. - 2008 - Expected Value, Reward Outcome, and Temporal Diffe.pdf;/Users/alexten/Zotero/storage/T2R64MI8/Rolls et al. - 2008 - Expected Value, Reward Outcome, and Temporal Diffe.pdf}
}

@article{rooderkerkIncorporatingContextEffects2011,
  title = {Incorporating {{Context Effects}} into a {{Choice Model}}},
  author = {Rooderkerk, Robert P. and Van Heerde, Harald J. and Bijmolt, Tammo H.A.},
  date = {2011-08},
  journaltitle = {Journal of Marketing Research},
  shortjournal = {Journal of Marketing Research},
  volume = {48},
  number = {4},
  pages = {767--780},
  issn = {0022-2437, 1547-7193},
  doi = {10.1509/jmkr.48.4.767},
  url = {http://journals.sagepub.com/doi/10.1509/jmkr.48.4.767},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WJLQZBVM/Rooderkerk et al. - 2011 - Incorporating Context Effects into a Choice Model.pdf}
}

@article{rostamiGenerativeContinualConcept2020,
  title = {Generative {{Continual Concept Learning}}},
  author = {Rostami, Mohammad and Kolouri, Soheil and Pilly, Praveen and McClelland, James},
  date = {2020-04-03},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  shortjournal = {AAAI},
  volume = {34},
  number = {04},
  pages = {5545--5552},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v34i04.6006},
  url = {https://aaai.org/ojs/index.php/AAAI/article/view/6006},
  urldate = {2021-01-22},
  abstract = {After learning a concept, humans are also able to continually generalize their learned concepts to new domains by observing only a few labeled instances without any interference with the past learned knowledge. In contrast, learning concepts efficiently in a continual learning setting remains an open challenge for current Artificial Intelligence algorithms as persistent model retraining is necessary. Inspired by the Parallel Distributed Processing learning and the Complementary Learning Systems theories, we develop a computational model that is able to expand its previously learned concepts efficiently to new domains using a few labeled samples. We couple the new form of a concept to its past learned forms in an embedding space for effective continual learning. Doing so, a generative distribution is learned such that it is shared across the tasks in the embedding space and models the abstract concepts. This procedure enables the model to generate pseudo-data points to replay the past experience to tackle catastrophic forgetting.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/YPVNRH7B/Rostami et al. - 2020 - Generative Continual Concept Learning.pdf}
}

@article{rouaultFormingGlobalEstimates2019,
  title = {Forming Global Estimates of Self-Performance from Local Confidence},
  author = {Rouault, Marion and Dayan, Peter and Fleming, Stephen M.},
  date = {2019-12},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {10},
  number = {1},
  pages = {1141},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-09075-3},
  url = {http://www.nature.com/articles/s41467-019-09075-3},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/36SU6LX7/Rouault - Forming global estimates of self-performance from .pdf;/Users/alexten/Zotero/storage/UAQ8LGQ8/Rouault et al. - 2019 - Forming global estimates of self-performance from .pdf}
}

@article{russekPredictiveRepresentationsCan,
  title = {Predictive Representations Can Link Model-Based Reinforcement Learning to Model-Free Mechanisms},
  author = {Russek, Evan M and Momennejad, Ida and Botvinick, Matthew M and Gershman, Samuel J and Daw, Nathaniel D},
  pages = {35},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4ARJPLTZ/Russek et al. - Predictive representations can link model-based re.pdf}
}

@article{russekPredictiveRepresentationsCan2017,
  title = {Predictive Representations Can Link Model-Based Reinforcement Learning to Model-Free Mechanisms},
  author = {Russek, Evan M. and Momennejad, Ida and Botvinick, Matthew M. and Gershman, Samuel J. and Daw, Nathaniel D.},
  editor = {Daunizeau, Jean},
  date = {2017-09-25},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLoS Comput Biol},
  volume = {13},
  number = {9},
  pages = {e1005768},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005768},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1005768},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JJF5KTC5/Russek et al. - 2017 - Predictive representations can link model-based re.pdf}
}

@article{russellPROMOTINGUNDERSTANDINGREPRESENTATIONAL,
  title = {{{PROMOTING UNDERSTANDING THROUGH REPRESENTATIONAL REDESCRIPTION}}: {{AN EXPLORATION REFERRING TO YOUNG PUPILS}}’ {{IDEAS ABOUT GRAVITY}}.},
  author = {Russell, Terry and Mcguigan, Linda},
  pages = {8},
  abstract = {This paper describes an attempt to operationalise some aspects of the cognitive developmental hypothesis of Representational Redescription, (Karmiloff-Smith, 1992, 1994 and 1997). It is illustrated by a study that examined processes and outcomes of teaching and learning about gravitational force with pupils in the 4-11 age range. The researchers collaborated with a group of teachers in an attempt to apply to classroom practice some implications of the theoretical underpinning upon which the R-R view of knowledge development is based. Some insights into how the transformation of pupils’ internally stored representations might be provoked in the classroom are described. Our attempts at educational application do not claim to test the R-R hypothesis, but in the educational context of learning science ideas, some difficulties in applying the theoretical formulation are discussed, and some implications for ways forward are considered.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9Q3G9247/Russell and Mcguigan - PROMOTING UNDERSTANDING THROUGH REPRESENTATIONAL R.pdf}
}

@incollection{russellPromotingUnderstandingRepresentational2003,
  title = {Promoting {{Understanding}} through {{Representational Redescription}}: An {{Exploration Referring}} to {{Young Pupils}}’ {{Ideas About Gravity}}},
  shorttitle = {Promoting {{Understanding}} through {{Representational Redescription}}},
  booktitle = {Science {{Education Research}} in the {{Knowledge}}-{{Based Society}}},
  author = {Russell, Terry and McGuigan, Linda},
  editor = {Psillos, Dimitris and Kariotoglou, Petros and Tselfes, Vassilis and Hatzikraniotis, Evripides and Fassoulopoulos, George and Kallery, Maria},
  date = {2003},
  pages = {277--284},
  publisher = {{Springer Netherlands}},
  location = {{Dordrecht}},
  doi = {10.1007/978-94-017-0165-5_30},
  url = {http://link.springer.com/10.1007/978-94-017-0165-5_30},
  urldate = {2021-01-22},
  abstract = {This paper describes an attempt to operationalise some aspects of the cognitive developmental hypothesis of Representational Redescription, (Karmiloff-Smith, 1992, 1994 and 1997). It is illustrated by a study that examined processes and outcomes of teaching and learning about gravitational force with pupils in the 4-11 age range. The researchers collaborated with a group of teachers in an attempt to apply to classroom practice some implications of the theoretical underpinning upon which the R-R view of knowledge development is based. Some insights into how the transformation of pupils’ internally stored representations might be provoked in the classroom are described. Our attempts at educational application do not claim to test the R-R hypothesis, but in the educational context of learning science ideas, some difficulties in applying the theoretical formulation are discussed, and some implications for ways forward are considered.},
  isbn = {978-90-481-6337-3 978-94-017-0165-5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NTACQKPP/Russell and McGuigan - 2003 - Promoting Understanding through Representational R.pdf}
}

@article{ryanIntrinsicExtrinsicMotivations,
  title = {Intrinsic and {{Extrinsic Motivations}}: {{Classic Definitions}} and {{New Directions}}},
  author = {Ryan, Richard M and Deci, Edward L},
  pages = {14},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4NT4UT8V/Ryan and Deci - Intrinsic and Extrinsic Motivations Classic Defin.pdf;/Users/alexten/Zotero/storage/96P5CIHS/Ryan and Deci - Intrinsic and Extrinsic Motivations Classic Defin.pdf}
}

@article{salvucciThreadedCognitionIntegrated,
  title = {Threaded {{Cognition}}: {{An Integrated Theory}} of {{Concurrent Multitasking}}},
  author = {Salvucci, Dario D and Taatgen, Niels A},
  pages = {31},
  abstract = {The authors propose the idea of threaded cognition, an integrated theory of concurrent multitasking—that is, performing 2 or more tasks at once. Threaded cognition posits that streams of thought can be represented as threads of processing coordinated by a serial procedural resource and executed across other available resources (e.g., perceptual and motor resources). The theory specifies a parsimonious mechanism that allows for concurrent execution, resource acquisition, and resolution of resource conflicts, without the need for specialized executive processes. By instantiating this mechanism as a computational model, threaded cognition provides explicit predictions of how multitasking behavior can result in interference, or lack thereof, for a given set of tasks. The authors illustrate the theory in model simulations of several representative domains ranging from simple laboratory tasks such as dual-choice tasks to complex real-world domains such as driving and driver distraction.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5KL62MDF/Salvucci and Taatgen - Threaded Cognition An Integrated Theory of Concur.pdf}
}

@article{salvucciThreadedCognitionIntegrated2008,
  title = {Threaded Cognition: {{An}} Integrated Theory of Concurrent Multitasking.},
  shorttitle = {Threaded Cognition},
  author = {Salvucci, Dario D. and Taatgen, Niels A.},
  date = {2008},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {115},
  number = {1},
  pages = {101--130},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/0033-295X.115.1.101},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.115.1.101},
  urldate = {2021-01-22},
  abstract = {The authors propose the idea of threaded cognition, an integrated theory of concurrent multitasking—that is, performing 2 or more tasks at once. Threaded cognition posits that streams of thought can be represented as threads of processing coordinated by a serial procedural resource and executed across other available resources (e.g., perceptual and motor resources). The theory specifies a parsimonious mechanism that allows for concurrent execution, resource acquisition, and resolution of resource conflicts, without the need for specialized executive processes. By instantiating this mechanism as a computational model, threaded cognition provides explicit predictions of how multitasking behavior can result in interference, or lack thereof, for a given set of tasks. The authors illustrate the theory in model simulations of several representative domains ranging from simple laboratory tasks such as dual-choice tasks to complex real-world domains such as driving and driver distraction.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/TMZ2GHN6/Salvucci and Taatgen - 2008 - Threaded cognition An integrated theory of concur.pdf}
}

@article{sanbornBayesianBrainsProbabilities,
  title = {Bayesian {{Brains}} without {{Probabilities}}},
  author = {Sanborn, Adam N},
  pages = {11},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3BBD7TZH/Sanborn - Bayesian Brains without Probabilities.pdf;/Users/alexten/Zotero/storage/7GUPSSNB/Sanborn - Bayesian Brains without Probabilities.pdf}
}

@article{sandersSignaturesStatisticalComputation2016,
  title = {Signatures of a {{Statistical Computation}} in the {{Human Sense}} of {{Confidence}}},
  author = {Sanders, Joshua I},
  date = {2016},
  pages = {9},
  abstract = {Human confidence judgments are thought to originate from metacognitive processes that provide a subjective assessment about one’s beliefs. Alternatively, confidence is framed in mathematics as an objective statistical quantity: the probability that a chosen hypothesis is correct. Despite similar terminology, it remains unclear whether the subjective feeling of confidence is related to the objective, statistical computation of confidence. To address this, we collected confidence reports from humans performing perceptual and knowledge-based psychometric decision tasks. We observed two counterintuitive patterns relating confidence to choice and evidence: apparent overconfidence in choices based on uninformative evidence, and decreasing confidence with increasing evidence strength for erroneous choices. We show that these patterns lawfully arise from statistical confidence, and therefore occur even for perfectly calibrated confidence measures. Furthermore, statistical confidence quantitatively accounted for human confidence in our tasks without necessitating heuristic operations. Accordingly, we suggest that the human feeling of confidence originates from a mental computation of statistical confidence.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9FWGUI7I/Sanders - Signatures of a Statistical Computation in the Hum.pdf}
}

@book{sansoneIntrinsicExtrinsicMotivation2000,
  title = {Intrinsic and Extrinsic Motivation: The Search for Optimal Motivation and Performance},
  shorttitle = {Intrinsic and Extrinsic Motivation},
  editor = {Sansone, Carol and Harackiewicz, Judith M.},
  date = {2000},
  series = {Educational Psychology Series},
  publisher = {{Academic Press}},
  location = {{San Diego}},
  isbn = {978-0-12-619070-0},
  langid = {english},
  pagetotal = {489},
  keywords = {Motivation (Psychology),Motivation in education},
  file = {/Users/alexten/Zotero/storage/C76TZXXI/Sansone and Harackiewicz - 2000 - Intrinsic and extrinsic motivation the search for.pdf;/Users/alexten/Zotero/storage/E232IRYA/Sansone and Harackiewicz - 2000 - Intrinsic and extrinsic motivation the search for.pdf}
}

@article{santucciWhichBestIntrinsic2013,
  title = {Which Is the Best Intrinsic Motivation Signal for Learning Multiple Skills?},
  author = {Santucci, Vieri G. and Baldassarre, Gianluca and Mirolli, Marco},
  date = {2013},
  journaltitle = {Frontiers in Neurorobotics},
  shortjournal = {Front. Neurorobot.},
  volume = {7},
  issn = {1662-5218},
  doi = {10.3389/fnbot.2013.00022},
  url = {http://journal.frontiersin.org/article/10.3389/fnbot.2013.00022/abstract},
  urldate = {2021-01-22},
  abstract = {Humans and other biological agents are able to autonomously learn and cache different skills in the absence of any biological pressure or any assigned task. In this respect, Intrinsic Motivations (i.e., motivations not connected to reward-related stimuli) play a cardinal role in animal learning, and can be considered as a fundamental tool for developing more autonomous and more adaptive artificial agents. In this work, we provide an exhaustive analysis of a scarcely investigated problem: which kind of IM reinforcement signal is the most suitable for driving the acquisition of multiple skills in the shortest time? To this purpose we implemented an artificial agent with a hierarchical architecture that allows to learn and cache different skills. We tested the system in a setup with continuous states and actions, in particular, with a kinematic robotic arm that has to learn different reaching tasks. We compare the results of different versions of the system driven by several different intrinsic motivation signals. The results show (a) that intrinsic reinforcements purely based on the knowledge of the system are not appropriate to guide the acquisition of multiple skills, and (b) that the stronger the link between the IM signal and the competence of the system, the better the performance.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4MIC6YPH/Santucci et al. - 2013 - Which is the best intrinsic motivation signal for .pdf}
}

@online{saxeExactSolutionsNonlinear2014,
  title = {Exact Solutions to the Nonlinear Dynamics of Learning in Deep Linear Neural Networks},
  author = {Saxe, Andrew M. and McClelland, James L. and Ganguli, Surya},
  date = {2014-02-19},
  eprint = {1312.6120},
  eprinttype = {arxiv},
  primaryclass = {cond-mat, q-bio, stat},
  url = {http://arxiv.org/abs/1312.6120},
  urldate = {2021-01-22},
  abstract = {Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Condensed Matter - Disordered Systems and Neural Networks,Quantitative Biology - Neurons and Cognition,Statistics - Machine Learning},
  file = {/Users/alexten/Zotero/storage/2XQWZDMU/Saxe et al. - 2014 - Exact solutions to the nonlinear dynamics of learn.pdf;/Users/alexten/Zotero/storage/KL6KPVUL/Saxe et al. - 2014 - Exact solutions to the nonlinear dynamics of learn.pdf}
}

@article{scarselliGraphNeuralNetwork,
  title = {The Graph Neural Network Model},
  author = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  pages = {22},
  abstract = {Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ZGLX8LI2/Scarselli et al. - The graph neural network model.pdf}
}

@article{scarselliGraphNeuralNetwork2009,
  title = {The {{Graph Neural Network Model}}},
  author = {Scarselli, F. and Gori, M. and {Ah Chung Tsoi} and Hagenbuchner, M. and Monfardini, G.},
  date = {2009-01},
  journaltitle = {IEEE Transactions on Neural Networks},
  shortjournal = {IEEE Trans. Neural Netw.},
  volume = {20},
  number = {1},
  pages = {61--80},
  issn = {1045-9227, 1941-0093},
  doi = {10.1109/TNN.2008.2005605},
  url = {http://ieeexplore.ieee.org/document/4700287/},
  urldate = {2021-01-22},
  abstract = {Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MJ4FTIRQ/Scarselli et al. - 2009 - The Graph Neural Network Model.pdf}
}

@article{schadHowCapitalizePriori2020,
  title = {How to Capitalize on a Priori Contrasts in Linear (Mixed) Models: {{A}} Tutorial},
  shorttitle = {How to Capitalize on a Priori Contrasts in Linear (Mixed) Models},
  author = {Schad, Daniel J. and Vasishth, Shravan and Hohenstein, Sven and Kliegl, Reinhold},
  date = {2020-02},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {110},
  pages = {104038},
  issn = {0749596X},
  doi = {10.1016/j.jml.2019.104038},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X19300695},
  urldate = {2021-05-23},
  abstract = {Factorial experiments in research on memory, language, and in other areas are often analyzed using analysis of variance (ANOVA). However, for effects with more than one numerator degrees of freedom, e.g., for experimental factors with more than two levels, the ANOVA omnibus F-test is not informative about the source of a main effect or interaction. Because researchers typically have specific hypotheses about which condition means differ from each other, a priori contrasts (i.e., comparisons planned before the sample means are known) between specific conditions or combinations of conditions are the appropriate way to represent such hypotheses in the statistical model. Many researchers have pointed out that contrasts should be “tested instead of, rather than as a supplement to, the ordinary ‘omnibus’ F test” (Hays, 1973, p. 601). In this tutorial, we explain the mathematics underlying different kinds of contrasts (i.e., treatment, sum, repeated, polynomial, custom, nested, interaction contrasts), discuss their properties, and demonstrate how they are applied in the R System for Statistical Computing (R Core Team, 2018). In this context, we explain the generalized inverse which is needed to compute the coefficients for contrasts that test hypotheses that are not covered by the default set of contrasts. A detailed understanding of contrast coding is crucial for successful and correct specification in linear models (including linear mixed models). Contrasts defined a priori yield far more useful confirmatory tests of experimental hypotheses than standard omnibus F-tests. Reproducible code is available from https://osf.io/7ukf6/.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/TKF6H875/Schad et al. - 2020 - How to capitalize on a priori contrasts in linear .pdf}
}

@article{schapiroComplementaryLearningSystems2017,
  title = {Complementary Learning Systems within the Hippocampus: A Neural Network Modelling Approach to Reconciling Episodic Memory with Statistical Learning},
  shorttitle = {Complementary Learning Systems within the Hippocampus},
  author = {Schapiro, Anna C. and Turk-Browne, Nicholas B. and Botvinick, Matthew M. and Norman, Kenneth A.},
  date = {2017-01-05},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  shortjournal = {Phil. Trans. R. Soc. B},
  volume = {372},
  number = {1711},
  pages = {20160049},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2016.0049},
  url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2016.0049},
  urldate = {2021-01-22},
  abstract = {A growing literature suggests that the hippocampus is critical for the rapid extraction of regularities from the environment. Although this fits with the known role of the hippocampus in rapid learning, it seems at odds with the idea that the hippocampus specializes in memorizing individual episodes. In particular, the Complementary Learning Systems theory argues that there is a computational trade-off between learning the specifics of individual experiences and regularities that hold across those experiences. We asked whether it is possible for the hippocampus to handle both statistical learning and memorization of individual episodes. We exposed a neural network model that instantiates known properties of hippocampal projections and subfields to sequences of items with temporal regularities. We found that the monosynaptic pathway—the pathway connecting entorhinal cortex directly to region CA1—was able to support statistical learning, while the trisynaptic pathway—connecting entorhinal cortex to CA1 through dentate gyrus and CA3—learned individual episodes, with apparent representations of regularities resulting from associative reactivation through recurrence. Thus, in paradigms involving rapid learning, the computational trade-off between learning episodes and regularities may be handled by separate anatomical pathways within the hippocampus itself.             This article is part of the themed issue ‘New frontiers for statistical learning in the cognitive sciences’.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/XHZM3M84/Schapiro et al. - 2017 - Complementary learning systems within the hippocam.pdf;/Users/alexten/Zotero/storage/ZML9QWZU/Schapiro et al. - Complementary learning systems within the hippocam.pdf}
}

@article{schapiroHumanHippocampalReplay2018,
  title = {Human Hippocampal Replay during Rest Prioritizes Weakly Learned Information and Predicts Memory Performance},
  author = {Schapiro, Anna C},
  date = {2018},
  journaltitle = {NATURE COMMUNICATIONS},
  pages = {11},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GJJFTKFN/Schapiro et al. - 2018 - Human hippocampal replay during rest prioritizes w.pdf;/Users/alexten/Zotero/storage/UBPXE8B3/Schapiro - 2018 - Human hippocampal replay during rest prioritizes w.pdf}
}

@online{schaulPrioritizedExperienceReplay2016,
  title = {Prioritized {{Experience Replay}}},
  author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  date = {2016-02-25},
  eprint = {1511.05952},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1511.05952},
  urldate = {2021-01-22},
  abstract = {Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new stateof-the-art, outperforming DQN with uniform replay on 41 out of 49 games.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/alexten/Zotero/storage/TWDMNXWJ/Schaul et al. - 2016 - Prioritized Experience Replay.pdf}
}

@online{schaulPrioritizedExperienceReplay2016a,
  title = {Prioritized {{Experience Replay}}},
  author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  date = {2016-02-25},
  eprint = {1511.05952},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1511.05952},
  urldate = {2021-01-22},
  abstract = {Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new stateof-the-art, outperforming DQN with uniform replay on 41 out of 49 games.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/alexten/Zotero/storage/CMDMCGMW/Schaul et al. - 2016 - Prioritized Experience Replay.pdf}
}

@inproceedings{schmidhuberCuriousModelbuildingControl1991,
  title = {Curious Model-Building Control Systems},
  booktitle = {[{{Proceedings}}] 1991 {{IEEE International Joint Conference}} on {{Neural Networks}}},
  author = {Schmidhuber, J.},
  date = {1991},
  pages = {1458-1463 vol.2},
  publisher = {{IEEE}},
  location = {{Singapore}},
  doi = {10.1109/IJCNN.1991.170605},
  url = {https://ieeexplore.ieee.org/document/170605/},
  urldate = {2021-01-22},
  abstract = {A controller is a device which receives inputs from a (dynamic) environment and produces outputs that manipulate the environmental state. A model-building control system is a controller with an additional module (the `world model') which is trained to predict future inputs from previous input/action pairs. The novel curious model-building control system described in this paper is a model-building control system which actively tries to provoke situations for which it learned to expect to learn something about the environment. Such a system has been implemented as a 4-network system based on Watkins' Q-learning algorithm which can be used to maximize the expectation of the temporal derivative of the adaptive assumed reliability of future predictions. An experiment with an arti cial non-deterministic environment demonstrates that the system can be superior to previous model-building control systems (the latter do not address the problem of modelling the reliability of the world model's predictions in uncertain environments and use ad-hoc methods (like random search) to train the world model).},
  eventtitle = {1991 {{IEEE International Joint Conference}} on {{Neural Networks}}},
  isbn = {978-0-7803-0227-3},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/C9ZXIXXK/Schmidhuber - 1991 - Curious model-building control systems.pdf}
}

@article{schmidhuberDevelopmentalRoboticsOptimal,
  title = {Developmental {{Robotics}}, {{Optimal Artiﬁcial Curiosity}}, {{Creativity}}, {{Music}}, and the {{Fine Arts}}},
  author = {Schmidhuber, Jurgen and Munich, TU},
  pages = {14},
  abstract = {Even in absence of external reward, babies and scientists and others explore their world. Using some sort of adaptive predictive world model, they improve their ability to answer questions such as: what happens if I do this or that? They lose interest in both the predictable things and those predicted to remain unpredictable despite some effort. One can design curious robots that do the same. The author’s basic idea for doing so (1990, 1991): a reinforcement learning (RL) controller is rewarded for action sequences that improve the predictor. Here this idea is revisited in the context of recent results on optimal predictors and optimal RL machines. Several new variants of the basic principle are proposed. Finally it is pointed out how the fine arts can be formally understood as a consequence of the principle: given some subjective observer, great works of art and music yield observation histories exhibiting more novel, previously unknown compressibility / regularity / predictability (with respect to the observer’s particular learning algorithm) than lesser works, thus deepening the observer’s understanding of the world and what is possible in it.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NYTFVWN5/Schmidhuber and Munich - Developmental Robotics, Optimal Artiﬁcial Curiosit.pdf}
}

@article{schmidhuberDevelopmentalRoboticsOptimal2006,
  title = {Developmental Robotics, Optimal Artificial Curiosity, Creativity, Music, and the Fine Arts},
  author = {Schmidhuber, Jürgen},
  date = {2006-06},
  journaltitle = {Connection Science},
  shortjournal = {Connection Science},
  volume = {18},
  number = {2},
  pages = {173--187},
  issn = {0954-0091, 1360-0494},
  doi = {10.1080/09540090600768658},
  url = {http://www.tandfonline.com/doi/abs/10.1080/09540090600768658},
  urldate = {2021-01-22},
  abstract = {Even in absence of external reward, babies and scientists and others explore their world. Using some sort of adaptive predictive world model, they improve their ability to answer questions such as: what happens if I do this or that? They lose interest in both the predictable things and those predicted to remain unpredictable despite some effort. One can design curious robots that do the same. The author’s basic idea for doing so (1990, 1991): a reinforcement learning (RL) controller is rewarded for action sequences that improve the predictor. Here this idea is revisited in the context of recent results on optimal predictors and optimal RL machines. Several new variants of the basic principle are proposed. Finally it is pointed out how the fine arts can be formally understood as a consequence of the principle: given some subjective observer, great works of art and music yield observation histories exhibiting more novel, previously unknown compressibility / regularity / predictability (with respect to the observer’s particular learning algorithm) than lesser works, thus deepening the observer’s understanding of the world and what is possible in it.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/23THZLUV/Schmidhuber - 2006 - Developmental robotics, optimal artificial curiosi.pdf}
}

@article{schmitzComponentsTaskSwitching2014,
  title = {Components of Task Switching: {{A}} Closer Look at Task Switching and Cue Switching},
  author = {Schmitz, Florian and Voss, Andreas},
  date = {2014},
  journaltitle = {Acta Psychologica},
  pages = {13},
  abstract = {Research using the diffusion model to decompose task-switching effects has contributed to a better understanding of the processes underlying the observed effect in the explicit task cueing paradigm: Previous findings could be reconciled with multiple component models of task switching or with an account on compound-cue retrieval/ repetition priming. In the present study, we used two cues for each task in order to decompose task-switch and cue-switch effects. Response time data support previous findings that comparable parts of the switching effect can be attributed to cue-switching and task-switching. A diffusion model analysis of the data confirmed that non-decision time is increased and drift rates are decreased in unpredicted task-switches. Importantly, it was shown that non-decision time was selectively increased in task-switching trials but not in cue-switching trials. Results of the present study specifically support the notion of additional processes in task-switches and can be reconciled with broader multiple component accounts.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Q5EPUR55/Schmitz and Voss - 2014 - Components of task switching A closer look at tas.pdf;/Users/alexten/Zotero/storage/SJXG2TKV/Schmitz and Voss - 2014 - Components of task switching A closer look at tas.pdf}
}

@article{schneiderWhatComingNext2013,
  title = {‘‘{{What}}’s Coming next?’’ {{Epistemic}} Curiosity and Lurking Behavior in Online Communities},
  author = {Schneider, Andreas},
  date = {2013},
  journaltitle = {Computers in Human Behavior},
  pages = {11},
  abstract = {Prior research has repeatedly found that lurkers, the passive members of online communities, dominate such communities in terms of membership. Yet lurking in online communities reflects a phenomenon largely neglected by contemporary information systems theory and research. This study starts by reviewing existing literature on lurking behavior in online communities and identifies an unexplored opportunity related to the nature and origins of lurkers’ behavior, the individual propensity to de-lurk, and the dynamic interplay between lurking and de-lurking behavior. A theoretical process-based framework linking epistemic curiosity to lurking and de-lurking behavior in online communities is presented. This framework links prior academic work on epistemic curiosity as personality trait and emotional–motivational state to lurkers’ contribution behavior in online communities. The article concludes by proposing that the psychology of curiosity in general holds great promise for research on online communities in information systems.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Q5Z79CB5/Schneider - 2013 - ‘‘What’s coming next’’ Epistemic curiosity and lu.pdf}
}

@article{scholerNewDirectionsSelfRegulation2018,
  title = {New {{Directions}} in {{Self}}-{{Regulation}}: {{The Role}} of {{Metamotivational Beliefs}}},
  shorttitle = {New {{Directions}} in {{Self}}-{{Regulation}}},
  author = {Scholer, Abigail A. and Miele, David B. and Murayama, Kou and Fujita, Kentaro},
  date = {2018-12},
  journaltitle = {Current Directions in Psychological Science},
  shortjournal = {Curr Dir Psychol Sci},
  volume = {27},
  number = {6},
  pages = {437--442},
  issn = {0963-7214, 1467-8721},
  doi = {10.1177/0963721418790549},
  url = {http://journals.sagepub.com/doi/10.1177/0963721418790549},
  urldate = {2021-01-22},
  abstract = {Research on self-regulation has primarily focused on how people exert control over their thoughts, emotions, and behavior. Less attention has been paid to the ways in which people manage their motivational states in the service of achieving valued goals. In the present paper, we explore an emerging line of research that focuses on people’s beliefs about their own motivation (i.e., their metamotivational knowledge), as well as the influence of these beliefs on their selection of regulatory strategies. In particular, we review evidence showing that people are often quite sensitive to the fact that distinct motivational states (e.g., eagerness vs. vigilance) are adaptive for different kinds of tasks. We also discuss how other metamotivational beliefs are inaccurate on average (e.g., beliefs about how rewards affect intrinsic motivation). Finally, we consider the implications of metamotivation research for the field of self-regulation and discuss future directions.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KY3KVASR/Scholer et al. - 2018 - New Directions in Self-Regulation The Role of Met.pdf}
}

@article{schonbrodtBayesFactorDesign,
  title = {Bayes {{Factor Design Analysis}}: {{Planning}} for {{Compelling Evidence}}},
  author = {Schönbrodt, Felix D and Wagenmakers, Eric-Jan},
  pages = {16},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ZQYSZG63/Schönbrodt and Wagenmakers - Bayes Factor Design Analysis Planning for Compell.pdf}
}

@article{schultzDopamineRewardPrediction2016,
  title = {Dopamine Reward Prediction Error Coding},
  author = {Schultz, Wolfram},
  date = {2016},
  journaltitle = {Dialogues in Clinical Neuroscience},
  volume = {18},
  number = {1},
  pages = {10},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MWXCSCEJ/Schultz - 2016 - Dopamine reward prediction error coding.pdf;/Users/alexten/Zotero/storage/VLI73F6N/Schultz - 2016 - Dopamine reward prediction error coding.pdf}
}

@article{schultzMultipleRewardSignals2000,
  title = {Multiple Reward Signals in the Brain},
  author = {Schultz, Wolfram},
  date = {2000-12},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {1},
  number = {3},
  pages = {199--207},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/35044563},
  url = {http://www.nature.com/articles/35044563},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3PSZ76QM/Schultz - 2000 - Multiple reward signals in the brain.pdf}
}

@article{schultzMultipleRewardSignals2000a,
  title = {Multiple Reward Signals in the Brain},
  author = {Schultz, Wolfram},
  date = {2000-12},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {1},
  number = {3},
  pages = {199--207},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/35044563},
  url = {http://www.nature.com/articles/35044563},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PB7MPUMN/Schultz - 2000 - Multiple reward signals in the brain.pdf}
}

@article{schultzNeuralSubstratePrediction,
  title = {A {{Neural Substrate}} of {{Prediction}} and {{Reward}}},
  author = {Schultz, Wolfram and Dayan, Peter and Montague, P Read},
  pages = {7},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4VNHK5CT/Schultz et al. - A Neural Substrate of Prediction and Reward.pdf;/Users/alexten/Zotero/storage/QWBAGW9M/Schultz et al. - A Neural Substrate of Prediction and Reward.pdf}
}

@article{schulzAlgorithmicArchitectureExploration2019,
  title = {The Algorithmic Architecture of Exploration in the Human Brain},
  author = {Schulz, Eric},
  date = {2019},
  journaltitle = {Current Opinion in Neurobiology},
  pages = {8},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/B66Z9949/Schulz - 2019 - The algorithmic architecture of exploration in the.pdf}
}

@article{schulzAlgorithmicArchitectureExploration2019a,
  title = {The Algorithmic Architecture of Exploration in the Human Brain},
  author = {Schulz, Eric and Gershman, Samuel J.},
  date = {2019-04},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  volume = {55},
  pages = {7--14},
  issn = {09594388},
  doi = {10.1016/j.conb.2018.11.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438818300904},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8G5YGJMK/Schulz and Gershman - 2019 - The algorithmic architecture of exploration in the.pdf}
}

@article{schwartzMetamemoryUpdateCritical,
  title = {Metamemory: {{An Update}} of {{Critical Findings}}},
  author = {Schwartz, Bennett L},
  pages = {10},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CFSK6MY5/Schwartz - Metamemory An Update of Critical Findings.pdf}
}

@article{schwartzMetamemoryUpdateCriticala,
  title = {Metamemory: {{An Update}} of {{Critical Findings}}},
  author = {Schwartz, Bennett L},
  pages = {10},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4RCTYDFL/Schwartz - Metamemory An Update of Critical Findings.pdf}
}

@article{schwartzSourcesInformationMetamemory,
  title = {Sources of Information in Metamemory: {{Judgments}} of Learning and Feelings of Knowing},
  author = {Schwartz, Bennettl},
  pages = {19},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8SRGJ2J5/Schwartz - Sources of information in metamemory Judgments of.pdf}
}

@article{schwartzSourcesInformationMetamemory1994,
  title = {Sources of Information in Metamemory: {{Judgments}} of Learning and Feelings of Knowing},
  shorttitle = {Sources of Information in Metamemory},
  author = {Schwartz, Bennett L.},
  date = {1994-09},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychonomic Bulletin \& Review},
  volume = {1},
  number = {3},
  pages = {357--375},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03213977},
  url = {http://link.springer.com/10.3758/BF03213977},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/A2ZQ7FVB/Schwartz - 1994 - Sources of information in metamemory Judgments of.pdf}
}

@article{schwartzTipofthetongueStatesMetacognition,
  title = {Tip-of-the-Tongue States as Metacognition},
  author = {Schwartz, Bennett L},
  pages = {10},
  abstract = {The tip-of-the-tongue state (henceforth, TOT) is typically defined as the feeling that a known word will be recalled even though it is not accessible immediately. Others have defined TOTs as simply the state of temporary inaccessibility (cognitive state) rather than the feeling of temporary inaccessibility (metacognitive experience). I argue that TOTs are metacognitive experiences rather than cognitive states. I present several lines of evidence to support this from the existing literature. In addition, I present evidence to support a distinction between TOTs and feelings of knowing (FOK). Although there is no definitive data, several lines of research support that TOTs and FOKs, although similar, are partially produced by different processes. Indeed, recent neuroimaging data show that different areas of the brain may be involved in TOTs and FOKs.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/M23PJHF4/Schwartz - Tip-of-the-tongue states as metacognition.pdf}
}

@article{schwartzTipofthetongueStatesMetacognition2006,
  title = {Tip-of-the-Tongue States as Metacognition},
  author = {Schwartz, Bennett L.},
  date = {2006-08},
  journaltitle = {Metacognition and Learning},
  shortjournal = {Metacognition Learning},
  volume = {1},
  number = {2},
  pages = {149--158},
  issn = {1556-1623, 1556-1631},
  doi = {10.1007/s11409-006-9583-z},
  url = {http://link.springer.com/10.1007/s11409-006-9583-z},
  urldate = {2021-01-22},
  abstract = {The tip-of-the-tongue state (henceforth, TOT) is typically defined as the feeling that a known word will be recalled even though it is not accessible immediately. Others have defined TOTs as simply the state of temporary inaccessibility (cognitive state) rather than the feeling of temporary inaccessibility (metacognitive experience). I argue that TOTs are metacognitive experiences rather than cognitive states. I present several lines of evidence to support this from the existing literature. In addition, I present evidence to support a distinction between TOTs and feelings of knowing (FOK). Although there is no definitive data, several lines of research support that TOTs and FOKs, although similar, are partially produced by different processes. Indeed, recent neuroimaging data show that different areas of the brain may be involved in TOTs and FOKs.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UUM5GNME/Schwartz - 2006 - Tip-of-the-tongue states as metacognition.pdf}
}

@online{scialomAskLearnStudy2019,
  title = {Ask to {{Learn}}: {{A Study}} on {{Curiosity}}-Driven {{Question Generation}}},
  shorttitle = {Ask to {{Learn}}},
  author = {Scialom, Thomas and Staiano, Jacopo},
  date = {2019-11-08},
  eprint = {1911.03350},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1911.03350},
  urldate = {2021-01-22},
  abstract = {We propose a novel text generation task, namely Curiosity-driven Question Generation. We start from the observation that the Question Generation task has traditionally been considered as the dual problem of Question Answering, hence tackling the problem of generating a question given the text that contains its answer. Such questions can be used to evaluate machine reading comprehension. However, in real life, and especially in conversational settings, humans tend to ask questions with the goal of enriching their knowledge and/or clarifying aspects of previously gathered information. We refer to these inquisitive questions as Curiosity-driven: these questions are generated with the goal of obtaining new information (the answer) which is not present in the input text. In this work, we experiment on this new task using a conversational Question Answering (QA) dataset; further, since the majority of QA dataset are not built in a conversational manner, we describe a methodology to derive data for this novel task from non-conversational QA data. We investigate several automated metrics to measure the different properties of Curious Questions, and experiment different approaches on the Curiosity-driven Question Generation task, including model pre-training and reinforcement learning. Finally, we report a qualitative evaluation of the generated outputs.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/alexten/Zotero/storage/J8LBH7QQ/Scialom and Staiano - 2019 - Ask to Learn A Study on Curiosity-driven Question.pdf}
}

@article{scottBlindInsightMetacognitive,
  title = {Blind {{Insight}}: {{Metacognitive Discrimination Despite Chance Task Performance}}},
  author = {Scott, Ryan B and Dienes, Zoltan and Barrett, Adam B and Bor, Daniel and Seth, Anil K},
  pages = {10},
  abstract = {Blindsight and other examples of unconscious knowledge and perception demonstrate dissociations between judgment accuracy and metacognition: Studies reveal that participants’ judgment accuracy can be above chance while their confidence ratings fail to discriminate right from wrong answers. Here, we demonstrated the opposite dissociation: a reliable relationship between confidence and judgment accuracy (demonstrating metacognition) despite judgment accuracy being no better than chance. We evaluated the judgments of 450 participants who completed an AGL task. For each trial, participants decided whether a stimulus conformed to a given set of rules and rated their confidence in that judgment. We identified participants who performed at chance on the discrimination task, utilizing a subset of their responses, and then assessed the accuracy and the confidence-accuracy relationship of their remaining responses. Analyses revealed above-chance metacognition among participants who did not exhibit decision accuracy. This important new phenomenon, which we term blind insight, poses critical challenges to prevailing models of metacognition grounded in signal detection theory.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/I3EF588D/Scott et al. - Blind Insight Metacognitive Discrimination Despit.pdf}
}

@article{scottBlindInsightMetacognitive2014,
  title = {\emph{Blind }{{\emph{Insight}}} : {{Metacognitive Discrimination Despite Chance Task Performance}}},
  shorttitle = {\emph{Blind }{{\emph{Insight}}}},
  author = {Scott, Ryan B. and Dienes, Zoltan and Barrett, Adam B. and Bor, Daniel and Seth, Anil K.},
  date = {2014-12},
  journaltitle = {Psychological Science},
  shortjournal = {Psychol Sci},
  volume = {25},
  number = {12},
  pages = {2199--2208},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797614553944},
  url = {http://journals.sagepub.com/doi/10.1177/0956797614553944},
  urldate = {2021-01-22},
  abstract = {Blindsight and other examples of unconscious knowledge and perception demonstrate dissociations between judgment accuracy and metacognition: Studies reveal that participants’ judgment accuracy can be above chance while their confidence ratings fail to discriminate right from wrong answers. Here, we demonstrated the opposite dissociation: a reliable relationship between confidence and judgment accuracy (demonstrating metacognition) despite judgment accuracy being no better than chance. We evaluated the judgments of 450 participants who completed an AGL task. For each trial, participants decided whether a stimulus conformed to a given set of rules and rated their confidence in that judgment. We identified participants who performed at chance on the discrimination task, utilizing a subset of their responses, and then assessed the accuracy and the confidence-accuracy relationship of their remaining responses. Analyses revealed above-chance metacognition among participants who did not exhibit decision accuracy. This important new phenomenon, which we term blind insight, poses critical challenges to prevailing models of metacognition grounded in signal detection theory.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/45KQ9Z6H/Scott et al. - 2014 - Blind Insight  Metacognitive Discriminatio.pdf}
}

@article{senkoAchievementGoalTheory2011,
  title = {Achievement {{Goal Theory}} at the {{Crossroads}}: {{Old Controversies}}, {{Current Challenges}}, and {{New Directions}}},
  shorttitle = {Achievement {{Goal Theory}} at the {{Crossroads}}},
  author = {Senko, Corwin and Hulleman, Chris S. and Harackiewicz, Judith M.},
  date = {2011-01-26},
  journaltitle = {Educational Psychologist},
  shortjournal = {Educational Psychologist},
  volume = {46},
  number = {1},
  pages = {26--47},
  issn = {0046-1520, 1532-6985},
  doi = {10.1080/00461520.2011.538646},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00461520.2011.538646},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7MT7SSQJ/Senko et al. - 2011 - Achievement Goal Theory at the Crossroads Old Con.pdf}
}

@article{sethInteroceptiveInferenceEmotion2013,
  title = {Interoceptive Inference, Emotion, and the Embodied Self},
  author = {Seth, Anil K},
  date = {2013},
  volume = {17},
  number = {11},
  pages = {9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/D8IWXLQV/Seth - 2013 - Interoceptive inference, emotion, and the embodied.pdf;/Users/alexten/Zotero/storage/WDYJEK58/Seth - 2013 - Interoceptive inference, emotion, and the embodied.pdf}
}

@article{sethPostdecisionWageringMeasures2008,
  title = {Post-Decision Wagering Measures Metacognitive Content, Not Sensory Consciousness},
  author = {Seth, Anil K},
  date = {2008},
  journaltitle = {Consciousness and Cognition},
  pages = {3},
  abstract = {A recent report by Persaud et al. [Persaud, N., McLeod, P. \& Cowey, A. (2007). Post-decision wagering objectively measures awareness. Nature Neuroscience 10, 257–261] addresses a fundamental issue in consciousness science: the experimental measurement of conscious content. The authors propose a novel technique, ‘post-decision wagering’, in which subjects place bets on the correctness of decisions or discriminations. In this note, I critique the authors’ claim that their method ‘‘measures awareness directly’’.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SED6F3N4/Seth - 2008 - Post-decision wagering measures metacognitive cont.pdf}
}

@article{sethPostdecisionWageringMeasures2008a,
  title = {Post-Decision Wagering Measures Metacognitive Content, Not Sensory Consciousness},
  author = {Seth, Anil K},
  date = {2008},
  journaltitle = {Consciousness and Cognition},
  pages = {3},
  abstract = {A recent report by Persaud et al. [Persaud, N., McLeod, P. \& Cowey, A. (2007). Post-decision wagering objectively measures awareness. Nature Neuroscience 10, 257–261] addresses a fundamental issue in consciousness science: the experimental measurement of conscious content. The authors propose a novel technique, ‘post-decision wagering’, in which subjects place bets on the correctness of decisions or discriminations. In this note, I critique the authors’ claim that their method ‘‘measures awareness directly’’.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/J3W28EJ4/Seth - 2008 - Post-decision wagering measures metacognitive cont.pdf}
}

@article{shafirContextdependentViolationsRational2002,
  title = {Context-Dependent Violations of Rational Choice in Honeybees ( {{Apis}} Mellifera ) and Gray Jays ( {{Perisoreus}} Canadensis )},
  author = {Shafir, Sharoni and Waite, Tom and Smith, Brian},
  date = {2002-01-01},
  journaltitle = {Behavioral Ecology and Sociobiology},
  shortjournal = {Behavioral Ecology and Sociobiology},
  volume = {51},
  number = {2},
  pages = {180--187},
  issn = {0340-5443, 1432-0762},
  doi = {10.1007/s00265-001-0420-8},
  url = {http://link.springer.com/10.1007/s00265-001-0420-8},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/9KEV5XVK/Shafir et al. - 2002 - Context-dependent violations of rational choice in.pdf;/Users/alexten/Zotero/storage/JETVRBVH/Shafir et al. - Context-dependent violations of rational choice in.pdf}
}

@article{sheaGlobalWorkspaceNeeds,
  title = {The {{Global Workspace Needs Metacognition}}},
  author = {Shea, Nicholas},
  journaltitle = {Trends in Cognitive Sciences},
  pages = {12},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/VXI6DLIT/Shea - The Global Workspace Needs Metacognition.pdf}
}

@article{sheaGlobalWorkspaceNeeds2019,
  title = {The {{Global Workspace Needs Metacognition}}},
  author = {Shea, Nicholas and Frith, Chris D.},
  date = {2019-07},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {23},
  number = {7},
  pages = {560--571},
  issn = {13646613},
  doi = {10.1016/j.tics.2019.04.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661319300993},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PLKLD728/Shea and Frith - 2019 - The Global Workspace Needs Metacognition.pdf}
}

@report{shermanQuantifyingMetacognitiveThresholds2018,
  type = {preprint},
  title = {Quantifying Metacognitive Thresholds Using Signal-Detection Theory},
  author = {Sherman, M.T. and Seth, A.K. and Barrett, A.B},
  date = {2018-07-04},
  institution = {{Neuroscience}},
  doi = {10.1101/361543},
  url = {http://biorxiv.org/lookup/doi/10.1101/361543},
  urldate = {2021-01-22},
  abstract = {How sure are we about what we know? Confidence, measured via self-report, is often interpreted as a subjective probabilistic estimate on having made a correct judgement. The neurocognitive mechanisms underlying the construction of confidence and the information incorporated into these judgements are of increasing interest. Investigating these mechanisms requires principled and practically applicable measures of confidence and metacognition. Unfortunately, current measures of confidence are subject to distortions from decision biases and task performance. Motivated by a recent signal-detection theoretic behavioural measure of metacognitive sensitivity, known as meta-d’, here we present a quantitative behavioural measure of confidence that is invariant to decision bias and task performance. This measure, which we call m-distance, captures in a principled way the propensity to report decisions with high (or low) confidence. Computational simulations demonstrate the robustness of m-distance to decision bias and task performance, as well as its behaviour under conditions of high and low metacognitive sensitivity and under dualchannel and hierarchical models of metacognition. The introduction of the m-distance measure will enhance systematic quantitative studies of the behavioural expression and neurocognitive basis of subjective confidence.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ULXUR3TT/Sherman et al. - 2018 - Quantifying metacognitive thresholds using signal-.pdf}
}

@article{sherPrimingEnablingAssessment,
  title = {Priming, Enabling and Assessment of Curiosity},
  author = {Sher, Keren Ben-Tov},
  pages = {22},
  abstract = {In the information age, where all answers are just a click away, curiosity, the intrinsic drive to learn, becomes of paramount importance. How easy is it to prime for curiosity and what are its effects? What simple interventions can be used to enable curiosity-driven behaviors? We have conducted a large-scale study to address these questions, using a novel curiositybased application (app) on university applicants. Using the same app, we addressed the issue of curiosity assessment, which in recent years has mainly been performed via selfreporting questionnaires. The curiosity assessment tool was developed in order to assess curiosity via an objective, quantitative and digital way. The tool measured several behavioral aspects during a free and task-less interaction with the tablet app. From the recorded activity logs we calculated quantitative behavioral measures related to their exploration patterns. We show that a single word can prime the participants and induce better learning of their self-explored knowledge. We also show that by simply enabling more time to explore, without the ability to stop at will, induces more exploration and more learning. Finally, we show that our behavioral measures, obtained with the digital quantitative assessment tool, are significant predictors of the participants’ self-reported curiosity and Psychometric Entrance Test scores. These results suggest that simple priming for curiosity and enabling enough time to explore improve self-paced learning, and that a relatively simple and short interaction with a digital app can greatly improve state-of-the-art curiosity assessment.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3EX58SYE/Sher - Priming, enabling and assessment of curiosity.pdf}
}

@article{sherPrimingEnablingAssessment2019,
  title = {Priming, Enabling and Assessment of Curiosity},
  author = {Sher, Keren Ben-Tov and Levi-Keren, Michal and Gordon, Goren},
  date = {2019-08},
  journaltitle = {Educational Technology Research and Development},
  shortjournal = {Education Tech Research Dev},
  volume = {67},
  number = {4},
  pages = {931--952},
  issn = {1042-1629, 1556-6501},
  doi = {10.1007/s11423-019-09665-4},
  url = {http://link.springer.com/10.1007/s11423-019-09665-4},
  urldate = {2021-01-22},
  abstract = {In the information age, where all answers are just a click away, curiosity, the intrinsic drive to learn, becomes of paramount importance. How easy is it to prime for curiosity and what are its effects? What simple interventions can be used to enable curiosity-driven behaviors? We have conducted a large-scale study to address these questions, using a novel curiositybased application (app) on university applicants. Using the same app, we addressed the issue of curiosity assessment, which in recent years has mainly been performed via selfreporting questionnaires. The curiosity assessment tool was developed in order to assess curiosity via an objective, quantitative and digital way. The tool measured several behavioral aspects during a free and task-less interaction with the tablet app. From the recorded activity logs we calculated quantitative behavioral measures related to their exploration patterns. We show that a single word can prime the participants and induce better learning of their self-explored knowledge. We also show that by simply enabling more time to explore, without the ability to stop at will, induces more exploration and more learning. Finally, we show that our behavioral measures, obtained with the digital quantitative assessment tool, are significant predictors of the participants’ self-reported curiosity and Psychometric Entrance Test scores. These results suggest that simple priming for curiosity and enabling enough time to explore improve self-paced learning, and that a relatively simple and short interaction with a digital app can greatly improve state-of-the-art curiosity assessment.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GZ593QLR/Sher et al. - 2019 - Priming, enabling and assessment of curiosity.pdf}
}

@article{shiffrinSurveyModelEvaluation2008,
  title = {A {{Survey}} of {{Model Evaluation Approaches With}} a {{Tutorial}} on {{Hierarchical Bayesian Methods}}},
  author = {Shiffrin, Richard M and Lee, Michael D and Kim, Woojae and Wagenmakers, Eric-Jan},
  date = {2008},
  journaltitle = {Cognitive Science},
  pages = {37},
  abstract = {This article reviews current methods for evaluating models in the cognitive sciences, including theoretically based approaches, such as Bayes factors and minimum description length measures; simulation approaches, including model mimicry evaluations; and practical approaches, such as validation and generalization measures. This article argues that, although often useful in specific settings, most of these approaches are limited in their ability to give a general assessment of models. This article argues that hierarchical methods, generally, and hierarchical Bayesian methods, specifically, can provide a more thorough evaluation of models in the cognitive sciences. This article presents two worked examples of hierarchical Bayesian analyses to demonstrate how the approach addresses key questions of descriptive adequacy, parameter interference, prediction, and generalization in principled and coherent ways.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/72HPREP7/Shiffrin et al. - 2008 - A Survey of Model Evaluation Approaches With a Tut.pdf;/Users/alexten/Zotero/storage/PG9HSAUU/Shiffrin et al. - 2008 - A Survey of Model Evaluation Approaches With a Tut.pdf}
}

@article{shinHomoCuriousCurious2019,
  title = {Homo {{Curious}}: {{Curious}} or {{Interested}}?},
  shorttitle = {Homo {{Curious}}},
  author = {Shin, Dajung Diane and Kim, Sung-il},
  date = {2019-12},
  journaltitle = {Educational Psychology Review},
  shortjournal = {Educ Psychol Rev},
  volume = {31},
  number = {4},
  pages = {853--874},
  issn = {1040-726X, 1573-336X},
  doi = {10.1007/s10648-019-09497-x},
  url = {http://link.springer.com/10.1007/s10648-019-09497-x},
  urldate = {2021-01-22},
  abstract = {This review aims to clarify four perennial issues surrounding the concept of curiosity: its nature, conceptual distinction from situational interest, types, and educational implications. First, we argue that humans have evolved to be deeply curious to adapt to a world of uncertainty. Curiosity can be likened to an appetite for knowledge which can be satiated by specific information that fills a knowledge gap. Information-seeking behavior is determined by the expected availability of information using a cost–benefit analysis. Second, although curiosity and situational interest are often considered synonyms, we show that the two constructs differ in terms of their theoretical account, biological underpinnings, triggering factors, emotional valence, specificity of information searches, and relationship with individual interest. Unlike situational interest, which is the positive affect triggered by a wide variety of sources (e.g., autonomy, relatedness, competence), curiosity is an aversive cognitive state caused by an information gap. Situational interest follows the hedonic principle and is associated with opioid liking system in the brain. Curiosity, by contrast, is understood through drive theory and involves dopaminergic wanting system. Situational interest drives individuals to approach the stimulus while curiosity promotes the active seeking of missing information. Iterative cycles of curiosity resolution can lead to the development of individual interest. Third, we introduce two types of curiosity: curiosity for what (forward curiosity) is provoked by unpredictability, whereas curiosity for why (backward curiosity) arises from incongruity. Finally, driven by the unique characteristics of curiosity, we suggest ways to design learning environment that can nurture students’ curiosity.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/34VX5UBX/Shin and Kim - 2019 - Homo Curious Curious or Interested.pdf;/Users/alexten/Zotero/storage/AHX4PTSV/Shin and Kim - Homo Curious Curious or Interested.pdf}
}

@article{shmueliExplainPredict,
  title = {To {{Explain}} or to {{Predict}}?},
  author = {Shmueli, Galit},
  pages = {22},
  abstract = {Statistical modeling is a powerful tool for developing and testing theories by way of causal explanation, prediction, and description. In many disciplines there is near-exclusive use of statistical modeling for causal explanation and the assumption that models with high explanatory power are inherently of high predictive power. Conflation between explanation and prediction is common, yet the distinction must be understood for progressing scientific knowledge. While this distinction has been recognized in the philosophy of science, the statistical literature lacks a thorough discussion of the many differences that arise in the process of modeling for an explanatory versus a predictive goal. The purpose of this article is to clarify the distinction between explanatory and predictive modeling, to discuss its sources, and to reveal the practical implications of the distinction to each step in the modeling process.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IVYSBZ38/Shmueli - To Explain or to Predict.pdf}
}

@article{silverMasteringGameGo,
  title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
  author = {Silver, David},
  pages = {20},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/5H9LCJJE/Silver - Mastering the game of Go with deep neural networks.pdf}
}

@article{silverMasteringGameGoa,
  title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
  author = {Silver, David},
  pages = {20},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8I4KFF28/Silver - Mastering the game of Go with deep neural networks.pdf}
}

@article{silviaInterestCuriousEmotion,
  title = {Interest—{{The Curious Emotion}}},
  author = {Silvia, Paul J},
  volume = {17},
  number = {1},
  pages = {5},
  abstract = {Despite their interest in why people do what they do, psychologists typically overlook interest itself as a facet of human motivation and emotion. In recent years, however, researchers from diverse areas of psychology have turned their attention to the role of interest in learning, motivation, and development. This article reviews the emerging body of work on the psychology of interest, with an emphasis on what contemporary emotion research has learned about the subject. After considering four central questions—Is interest like other emotions? What functions does interest serve? What makes something interesting? Is interest merely another label for happiness?—the article considers unanswered questions and fruitful applications. Given interest’s central role in cultivating knowledge and expertise, psychologists should apply research on interest to practical problems of learning, education, and motivation.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/J4UBC7EZ/Silvia - Interest—The Curious Emotion.pdf;/Users/alexten/Zotero/storage/QSHX2WTZ/Silvia - Interest—The Curious Emotion.pdf}
}

@article{singhIntrinsicallyMotivatedReinforcement2010,
  title = {Intrinsically {{Motivated Reinforcement Learning}}: {{An Evolutionary Perspective}}},
  author = {Singh, Satinder and Lewis, Richard L and Barto, Andrew G and Sorg, Jonathan},
  date = {2010},
  journaltitle = {IEEE TRANSACTIONS ON AUTONOMOUS MENTAL DEVELOPMENT},
  volume = {2},
  number = {2},
  pages = {13},
  abstract = {There is great interest in building intrinsic motivation into artificial systems using the reinforcement learning framework. Yet, what intrinsic motivation may mean computationally, and how it may differ from extrinsic motivation, remains a murky and controversial subject. In this paper, we adopt an evolutionary perspective and define a new optimal reward framework that captures the pressure to design good primary reward functions that lead to evolutionary success across environments. The results of two computational experiments show that optimal primary reward signals may yield both emergent intrinsic and extrinsic motivation. The evolutionary perspective and the associated optimal reward framework thus lead to the conclusion that there are no hard and fast features distinguishing intrinsic and extrinsic reward computationally. Rather, the directness of the relationship between rewarding behavior and evolutionary success varies along a continuum.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6VK4Y669/Singh et al. - 2010 - Intrinsically Motivated Reinforcement Learning An.pdf;/Users/alexten/Zotero/storage/H43K6NLX/Singh et al. - 2010 - Intrinsically Motivated Reinforcement Learning An.pdf}
}

@article{singhWhereRewardsCome,
  title = {Where {{Do Rewards Come From}}?},
  author = {Singh, Satinder and Lewis, Richard L and Barto, Andrew G},
  pages = {6},
  abstract = {Reinforcement learning has achieved broad and successful application in cognitive science in part because of its general formulation of the adaptive control problem as the maximization of a scalar reward function. The computational reinforcement learning framework is motivated by correspondences to animal reward processes, but it leaves the source and nature of the rewards unspecified. This paper advances a general computational framework for reward that places it in an evolutionary context, formulating a notion of an optimal reward function given a fitness function and some distribution of environments. Novel results from computational experiments show how traditional notions of extrinsically and intrinsically motivated behaviors may emerge from such optimal reward functions. In the experiments these rewards are discovered through automated search rather than crafted by hand. The precise form of the optimal reward functions need not bear a direct relationship to the fitness function, but may nonetheless confer significant advantages over rewards based only on fitness.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/U9YKSYYI/Singh et al. - Where Do Rewards Come From.pdf}
}

@article{singhWhereRewardsComea,
  title = {Where {{Do Rewards Come From}}?},
  author = {Singh, Satinder and Lewis, Richard L and Barto, Andrew G},
  pages = {6},
  abstract = {Reinforcement learning has achieved broad and successful application in cognitive science in part because of its general formulation of the adaptive control problem as the maximization of a scalar reward function. The computational reinforcement learning framework is motivated by correspondences to animal reward processes, but it leaves the source and nature of the rewards unspecified. This paper advances a general computational framework for reward that places it in an evolutionary context, formulating a notion of an optimal reward function given a fitness function and some distribution of environments. Novel results from computational experiments show how traditional notions of extrinsically and intrinsically motivated behaviors may emerge from such optimal reward functions. In the experiments these rewards are discovered through automated search rather than crafted by hand. The precise form of the optimal reward functions need not bear a direct relationship to the fitness function, but may nonetheless confer significant advantages over rewards based only on fitness.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/XKBYLQPT/Singh et al. - Where Do Rewards Come From.pdf}
}

@inbook{siReinforcementLearningIts2009,
  title = {Reinforcement {{Learning}} and {{Its Relationship}} to {{Supervised Learning}}},
  booktitle = {Handbook of {{Learning}} and {{Approximate Dynamic Programming}}},
  date = {2009},
  publisher = {{IEEE}},
  doi = {10.1109/9780470544785.ch2},
  url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?arnumber=5273620},
  urldate = {2021-03-04},
  bookauthor = {Si, Jennie and Barto, Andrew G. and Powell, Warren Buckler and Wunsch, Don},
  isbn = {978-0-470-54478-5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/A8F52RZ7/2009 - Reinforcement Learning and Its Relationship to Sup.pdf}
}

@inbook{siReinforcementLearningIts2009a,
  title = {Reinforcement {{Learning}} and {{Its Relationship}} to {{Supervised Learning}}},
  booktitle = {Handbook of {{Learning}} and {{Approximate Dynamic Programming}}},
  date = {2009},
  publisher = {{IEEE}},
  doi = {10.1109/9780470544785.ch2},
  url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?arnumber=5273620},
  urldate = {2021-03-04},
  bookauthor = {Si, Jennie and Barto, Andrew G. and Powell, Warren Buckler and Wunsch, Don},
  isbn = {978-0-470-54478-5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Q6FW9JFG/2009 - Reinforcement Learning and Its Relationship to Sup.pdf}
}

@article{smithDevelopingInfantCreates,
  title = {The {{Developing Infant Creates}} a {{Curriculum}} for {{Statistical Learning}}},
  author = {Smith, Linda B and Jayaraman, Swapnaa and Clerkin, Elizabeth and Yu, Chen},
  pages = {13},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SP2ARUAA/Smith et al. - The Developing Infant Creates a Curriculum for Sta.pdf}
}

@article{smithDevelopingInfantCreates2018,
  title = {The {{Developing Infant Creates}} a {{Curriculum}} for {{Statistical Learning}}},
  author = {Smith, Linda B. and Jayaraman, Swapnaa and Clerkin, Elizabeth and Yu, Chen},
  date = {2018-04},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {22},
  number = {4},
  pages = {325--336},
  issn = {13646613},
  doi = {10.1016/j.tics.2018.02.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661318300275},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GNBCYX78/Smith et al. - 2018 - The Developing Infant Creates a Curriculum for Sta.pdf}
}

@article{smithNotKnowingWhat,
  title = {Not {{Knowing What One Knows}}: {{A Meaningful Failure}} of {{Metacognition}} in {{Capuchin Monkeys}}},
  author = {Smith, Travis R and Smith, J David and Beran, Michael J},
  pages = {13},
  abstract = {Metacognition encompasses the processes of monitoring representational and perceptual states and controlling information-gathering behaviors. Metacognition is considered one of humans’ most sophisticated abilities, and it has been a growing area of focus in comparative cognition research. Despite the successes of some species such as the great apes and some Old World monkeys, there has been a fairly consistent lack of metacognitive responding in the New World primate species, capuchin monkeys. These failures are meaningful for what they highlight about the phylogenetic breadth of metacognition, and for what they offer to ongoing debates about the proper interpretation of data from other species that do succeed in various tests of comparative metacognition. We summarize these meaningful failures and place them in a broader context of comparative metacognition research, with a specific focus on explaining what it might mean that some monkeys seemingly do not know what they know.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WBAFKTUQ/Smith et al. - Not Knowing What One Knows A Meaningful Failure o.pdf}
}

@article{smithNotKnowingWhat2018,
  title = {Not Knowing What One Knows: {{A Meaningful}} Failure of Metacognition in Capuchin Monkeys.},
  shorttitle = {Not Knowing What One Knows},
  author = {Smith, Travis R. and Smith, J. David and Beran, Michael J.},
  date = {2018-02-01},
  journaltitle = {Animal Behavior and Cognition},
  shortjournal = {AB\&C},
  volume = {5},
  number = {1},
  pages = {55--67},
  issn = {23725052, 23724323},
  doi = {10.26451/abc.05.01.05.2018},
  url = {http://animalbehaviorandcognition.org/article.php?id=1127},
  urldate = {2021-01-22},
  abstract = {Metacognition encompasses the processes of monitoring representational and perceptual states and controlling information-gathering behaviors. Metacognition is considered one of humans’ most sophisticated abilities, and it has been a growing area of focus in comparative cognition research. Despite the successes of some species such as the great apes and some Old World monkeys, there has been a fairly consistent lack of metacognitive responding in the New World primate species, capuchin monkeys. These failures are meaningful for what they highlight about the phylogenetic breadth of metacognition, and for what they offer to ongoing debates about the proper interpretation of data from other species that do succeed in various tests of comparative metacognition. We summarize these meaningful failures and place them in a broader context of comparative metacognition research, with a specific focus on explaining what it might mean that some monkeys seemingly do not know what they know.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KH4P2YW3/Smith et al. - 2018 - Not knowing what one knows A Meaningful failure o.pdf}
}

@article{soaresValueLearningProblem,
  title = {The {{Value Learning Problem}}},
  author = {Soares, Nate},
  pages = {7},
  abstract = {Autonomous AI systems’ programmed goals can easily fall short of programmers’ intentions. Even a machine intelligent enough to understand its designers’ intentions would not necessarily act as intended. We discuss early ideas on how one might design smarter-than-human AI systems that can inductively learn what to value from labeled training data, and highlight questions about the construction of systems that model and act upon their operators’ preferences.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KRTDRUG9/Soares - The Value Learning Problem.pdf}
}

@incollection{soaresValueLearningProblem2018,
  title = {The {{Value Learning Problem}}},
  booktitle = {Artificial {{Intelligence Safety}} and {{Security}}},
  author = {Soares, Nate},
  editor = {Yampolskiy, Roman V.},
  date = {2018-07-27},
  edition = {1},
  pages = {89--97},
  publisher = {{Chapman and Hall/CRC}},
  location = {{First edition. | Boca Raton, FL : CRC Press/Taylor \& Francis Group, 2018.}},
  doi = {10.1201/9781351251389-7},
  url = {https://www.taylorfrancis.com/books/9781351251372/chapters/10.1201/9781351251389-7},
  urldate = {2021-01-22},
  abstract = {Autonomous AI systems’ programmed goals can easily fall short of programmers’ intentions. Even a machine intelligent enough to understand its designers’ intentions would not necessarily act as intended. We discuss early ideas on how one might design smarter-than-human AI systems that can inductively learn what to value from labeled training data, and highlight questions about the construction of systems that model and act upon their operators’ preferences.},
  isbn = {978-1-351-25138-9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/HVBM8QBV/Soares - 2018 - The Value Learning Problem.pdf}
}

@article{soberInstrumentalismParsimonyAkaike,
  title = {Instrumentalism, {{Parsimony}}, and the {{Akaike Framework}}},
  author = {Sober, Elliott},
  pages = {12},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GNDVXCEL/Sober - Instrumentalism, Parsimony, and the Akaike Framewo.pdf;/Users/alexten/Zotero/storage/I8MHWWBZ/Sober - Instrumentalism, Parsimony, and the Akaike Framewo.pdf}
}

@article{soltaniAdaptiveLearningExpected,
  title = {Adaptive Learning under Expected and Unexpected Uncertainty},
  author = {Soltani, Alireza},
  pages = {10},
  abstract = {The outcome of a decision is often uncertain, and outcomes can vary over repeated decisions. Whether decision outcomes should substantially affect behaviour and learning depends on whether they are representative of a typically experienced range of outcomes or signal a change in the reward environment. Successful learning and decision-m aking therefore require the ability to estimate expected uncertainty (related to the variability of outcomes) and unexpected uncertainty (related to the variability of the environment). Understanding the bases and effects of these two types of uncertainty and the interactions between them — at the computational and the neural level — is crucial for understanding adaptive learning. Here, we examine computational models and experimental findings to distil computational principles and neural mechanisms for adaptive learning under uncertainty.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MRGZZKT2/Soltani - Adaptive learning under expected and unexpected un.pdf;/Users/alexten/Zotero/storage/WLKU77SW/Soltani - Adaptive learning under expected and unexpected un.pdf}
}

@article{somervilleChartingExpansionStrategic,
  title = {Charting the {{Expansion}} of {{Strategic Exploratory Behavior During Adolescence}}},
  author = {Somerville, Leah H and Sasse, Stephanie F and Garrad, Megan C and Akar, Nadine Abi and Insel, Catherine and Drysdale, Andrew T and Wilson, Robert C},
  pages = {11},
  abstract = {Although models of exploratory decision making implicate a suite of strategies that guide the pursuit of information, the developmental emergence of these strategies remains poorly understood. This study takes an interdisciplinary perspective, merging computational decision making and developmental approaches to characterize age-related shifts in exploratory strategy from adolescence to young adulthood. Participants were 149 12–28-year-olds who completed a computational explore– exploit paradigm that manipulated reward value, information value, and decision horizon (i.e., the utility that information holds for future choices). Strategic directed exploration, defined as information seeking selective for long time horizons, emerged during adolescence and maintained its level through early adulthood. This age difference was partially driven by adolescents valuing immediate reward over new information. Strategic random exploration, defined as stochastic choice behavior selective for long time horizons, was invoked at comparable levels over the age range, and predicted individual differences in attitudes toward risk taking in daily life within the adolescent portion of the sample. Collectively, these findings reveal an expansion of the diversity of strategic exploration over development, implicate distinct mechanisms for directed and random exploratory strategies, and suggest novel mechanisms for adolescent-typical shifts in decision making.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3JZ7Q6PB/Somerville et al. - 2017 - Charting the expansion of strategic exploratory be.pdf;/Users/alexten/Zotero/storage/E3SYE28X/Somerville et al. - Charting the Expansion of Strategic Exploratory Be.pdf;/Users/alexten/Zotero/storage/KMGC7DJ7/Somerville et al. - 2017 - Charting the expansion of strategic exploratory be.pdf;/Users/alexten/Zotero/storage/TTPZIM7T/Somerville et al. - Charting the Expansion of Strategic Exploratory Be.pdf}
}

@article{songNonparametricMeasureHeteroskedasticity,
  title = {A {{Nonparametric Measure}} of {{Heteroskedasticity}}},
  author = {Song, Xiaojun and Taamouti, Abderrahim},
  pages = {41},
  abstract = {We introduce a nonparametric measure to quantify the degree of heteroskedasticity at a fixed quantile of the conditional distribution of a random variable. Our measure of heteroskedasticity is based on nonparametric quantile regressions and is expressed in terms of unrestricted and restricted expectations of quantile loss functions. It can be consistently estimated by replacing the unknown expectations by their nonparametric estimates. We derive a Bahadur-type representation for the nonparametric estimator of the measure. We provide the asymptotic distribution of this estimator, which one can use to build tests for the statistical significance of the measure. Thereafter, we establish the validity of a fixed regressor bootstrap that one can use in finite-sample settings to perform tests. A Monte Carlo simulation study reveals that the bootstrap-based test has a good finite sample size and power for a variety of data generating processes and different sample sizes. Finally, two empirical applications are provided to illustrate the importance of the proposed measure.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WBVQWYWH/Song and Taamouti - A Nonparametric Measure of Heteroskedasticity.pdf}
}

@article{sonJudgmentsLearningEvidence,
  title = {Judgments of Learning: {{Evidence}} for a Two-Stage Process},
  author = {Son, Lisa K},
  pages = {14},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4U9HJNGN/Son - Judgments of learning Evidence for a two-stage pr.pdf}
}

@article{sonJudgmentsLearningEvidencea,
  title = {Judgments of Learning: {{Evidence}} for a Two-Stage Process},
  author = {Son, Lisa K},
  pages = {14},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QW4S388U/Son - Judgments of learning Evidence for a two-stage pr.pdf}
}

@article{sonMetacognitiveControlOptimal2006a,
  title = {Metacognitive {{Control}} and {{Optimal Learning}}},
  author = {Son, Lisa K and Sethi, Rajiv},
  date = {2006},
  journaltitle = {Cognitive Science},
  pages = {16},
  abstract = {The notion of optimality is often invoked informally in the literature on metacognitive control. We provide a precise formulation of the optimization problem and show that optimal time allocation strategies depend critically on certain characteristics of the learning environment, such as the extent of time pressure, and the nature of the uptake function. When the learning curve is concave, optimality requires that items at lower levels of initial competence be allocated greater time. On the other hand, with logistic learning curves, optimal allocations vary with time availability in complex and surprising ways. Hence there are conditions under which optimal strategies will be relatively easy to uncover, and others in which suboptimal time allocation might be expected. The model can therefore be used to address the question of whether and when learners should be able to exercise good metacognitive control in practice.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ZUYHSLVG/Son and Sethi - 2006 - Metacognitive Control and Optimal Learning.pdf}
}

@article{sonMetacognitiveControlStrategies,
  title = {Metacognitive and {{Control Strategies}} in {{Study}}-{{Time Allocation}}},
  author = {Son, Lisa K and Metcalfe, Janet},
  pages = {18},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UECY659F/Son and Metcalfe - Metacognitive and Control Strategies in Study-Time.pdf}
}

@article{sonMetacognitiveControlStrategiesa,
  title = {Metacognitive and {{Control Strategies}} in {{Study}}-{{Time Allocation}}},
  author = {Son, Lisa K and Metcalfe, Janet},
  pages = {18},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UGEN5X96/Son and Metcalfe - Metacognitive and Control Strategies in Study-Time.pdf}
}

@article{souchayAreFeelingofknowingJudgmentoflearning2012,
  title = {Are Feeling-of-Knowing and Judgment-of-Learning Different? {{Evidence}} from Older Adults},
  author = {Souchay, Celine and Isingrini, Michel},
  date = {2012},
  journaltitle = {Acta Psychologica},
  pages = {7},
  abstract = {This study aims to assess age differences between Judgments-of-learning (JOLs) and Feeling-of-knowing (FOKs) as they are typically studied. The novel contribution of the present study is a comparison between these two metacognitive judgments in a within subject design. Young and older adults were tested on their JOL accuracy and were asked to predict future recall during learning. All participants were also asked to predict future recognition of unrecalled items (FOK judgments). Results showed that although older adults had similar low levels of memory performance in the JOL task and in the FOK task, metacognitive impairments were only found on the resolution of FOKs. Furthermore, an analysis of covariance showed that age differences on memory performance explained the age effect observed on the FOK, thus supporting the memory constraint hypothesis (Hertzog et al., 2010). Results are discussed in relation to contemporary models of memory.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IIKLE8P2/Souchay and Isingrini - 2012 - Are feeling-of-knowing and judgment-of-learning di.pdf}
}

@online{spanosWhereStatisticalModels2006,
  title = {Where Do Statistical Models Come from? {{Revisiting}} the Problem of Specification},
  shorttitle = {Where Do Statistical Models Come From?},
  author = {Spanos, Aris},
  date = {2006-10-27},
  eprint = {math/0610849},
  eprinttype = {arxiv},
  doi = {10.1214/074921706000000419},
  url = {http://arxiv.org/abs/math/0610849},
  urldate = {2021-01-22},
  abstract = {R. A. Fisher founded modern statistical inference in 1922 and identified its fundamental problems to be: specification, estimation and distribution. Since then the problem of statistical model specification has received scant attention in the statistics literature. The paper traces the history of statistical model specification, focusing primarily on pioneers like Fisher, Neyman, and more recently Lehmann and Cox, and attempts a synthesis of their views in the context of the Probabilistic Reduction (PR) approach. As argued by Lehmann [11], a major stumbling block for a general approach to statistical model specification has been the delineation of the appropriate role for substantive subject matter information. The PR approach demarcates the interrelated but complemenatry roles of substantive and statistical information summarized ab initio in the form of a structural and a statistical model, respectively. In an attempt to preserve the integrity of both sources of information, as well as to ensure the reliability of their fusing, a purely probabilistic construal of statistical models is advocated. This probabilistic construal is then used to shed light on a number of issues relating to specification, including the role of preliminary data analysis, structural vs. statistical models, model specification vs. model selection, statistical vs. substantive adequacy and model validation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {62N-03; 62A01; 62J20; 60J65 (Primary),Mathematics - Statistics Theory},
  file = {/Users/alexten/Zotero/storage/6NHC365V/Spanos - 2006 - Where do statistical models come from Revisiting .pdf}
}

@online{spanosWhereStatisticalModels2006a,
  title = {Where Do Statistical Models Come from? {{Revisiting}} the Problem of Specification},
  shorttitle = {Where Do Statistical Models Come From?},
  author = {Spanos, Aris},
  date = {2006-10-27},
  eprint = {math/0610849},
  eprinttype = {arxiv},
  doi = {10.1214/074921706000000419},
  url = {http://arxiv.org/abs/math/0610849},
  urldate = {2021-01-22},
  abstract = {R. A. Fisher founded modern statistical inference in 1922 and identified its fundamental problems to be: specification, estimation and distribution. Since then the problem of statistical model specification has received scant attention in the statistics literature. The paper traces the history of statistical model specification, focusing primarily on pioneers like Fisher, Neyman, and more recently Lehmann and Cox, and attempts a synthesis of their views in the context of the Probabilistic Reduction (PR) approach. As argued by Lehmann [11], a major stumbling block for a general approach to statistical model specification has been the delineation of the appropriate role for substantive subject matter information. The PR approach demarcates the interrelated but complemenatry roles of substantive and statistical information summarized ab initio in the form of a structural and a statistical model, respectively. In an attempt to preserve the integrity of both sources of information, as well as to ensure the reliability of their fusing, a purely probabilistic construal of statistical models is advocated. This probabilistic construal is then used to shed light on a number of issues relating to specification, including the role of preliminary data analysis, structural vs. statistical models, model specification vs. model selection, statistical vs. substantive adequacy and model validation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {62N-03; 62A01; 62J20; 60J65 (Primary),Mathematics - Statistics Theory},
  file = {/Users/alexten/Zotero/storage/APQJDNRH/Spanos - 2006 - Where do statistical models come from Revisiting .pdf}
}

@article{SpecialFeature5th2016,
  title = {Special {{Feature}}: 5th {{Anniversary}} of {{Methods}} in {{Ecology}} and {{Evolution}}},
  date = {2016},
  journaltitle = {Methods in Ecology and Evolution},
  pages = {14},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7HCM29F3/2016 - Special Feature 5th Anniversary of Methods in Eco.pdf}
}

@article{speekenbrinkUncertaintyExplorationRestless,
  title = {Uncertainty and Exploration in a Restless Bandit Task},
  author = {Speekenbrink, Maarten and Konstantinidis, Emmanouil},
  pages = {6},
  abstract = {Decision-making in noisy and changing environments requires a fine balance between exploiting knowledge about good courses of action and exploring the environment in order to improve upon this knowledge. We present an experiment in which participants made repeated choices between options for which the average rewards changed over time. Comparing a number of computational models of participants’ behaviour in this task, we find evidence that a substantial number of them balanced exploration and exploitation by considering the probability that an option offers the maximum reward out of all the available options.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BICTD5P2/Speekenbrink and Konstantinidis - Uncertainty and exploration in a restless bandit t.pdf}
}

@article{speekenbrinkUncertaintyExplorationRestlessa,
  title = {Uncertainty and Exploration in a Restless Bandit Task},
  author = {Speekenbrink, Maarten and Konstantinidis, Emmanouil},
  pages = {6},
  abstract = {Decision-making in noisy and changing environments requires a fine balance between exploiting knowledge about good courses of action and exploring the environment in order to improve upon this knowledge. We present an experiment in which participants made repeated choices between options for which the average rewards changed over time. Comparing a number of computational models of participants’ behaviour in this task, we find evidence that a substantial number of them balanced exploration and exploitation by considering the probability that an option offers the maximum reward out of all the available options.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/H5JXH9QS/Speekenbrink and Konstantinidis - Uncertainty and exploration in a restless bandit t.pdf}
}

@article{StatesRewardsDissociable,
  title = {States versus {{Rewards}}: {{Dissociable Neural Prediction Error Signals Underlying Model}}-{{Based}} and {{Model}}-{{Free Reinforcement Learning}}},
  pages = {11},
  abstract = {Reinforcement learning (RL) uses sequential experience with situations (‘‘states’’) and outcomes to assess actions. Whereas model-free RL uses this experience directly, in the form of a reward prediction error (RPE), model-based RL uses it indirectly, building a model of the state transition and outcome structure of the environment, and evaluating actions by searching this model. A state prediction error (SPE) plays a central role, reporting discrepancies between the current model and the observed state transitions. Using functional magnetic resonance imaging in humans solving a probabilistic Markov decision task, we found the neural signature of an SPE in the intraparietal sulcus and lateral prefrontal cortex, in addition to the previously well-characterized RPE in the ventral striatum. This finding supports the existence of two unique forms of learning signal in humans, which may form the basis of distinct computational strategies for guiding behavior.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/MCELZNH2/States versus Rewards Dissociable Neural Predicti.pdf}
}

@article{sternModelsMemoryWittgenstein,
  title = {Models of Memory: {{Wittgenstein}} and Cognitive Science},
  author = {Stern, David G},
  pages = {16},
  abstract = {The model of memory as a store, from which records can be retrieved, is taken for granted by many contemporary researchers. On this view, memories are stored by memory traces, which represent the original event and provide a causal link between that episode and one's ability to remember it . I argue that this seemingly plausible model leads to an unacceptable conception of the relationship between mind and brain, and that a nonrepresentational, connectionist, model offers a promising alternative . I also offer a new reading of Wittgenstein's paradoxical remarks about thought and brain processes : as a critique of the cognitivist thesis that information stored in the brain has a linguistic structure and a particular location. On this reading, Wittgenstein's criticism foreshadows some of the most promising contemporary work on connectionist models of neural functioning.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3CI9JA5R/Stern - Models of memory Wittgenstein and cognitive scien.PDF}
}

@article{sternModelsMemoryWittgenstein1991,
  title = {Models of Memory: {{Wittgenstein}} and Cognitive Science},
  shorttitle = {Models of Memory},
  author = {Stern, David G.},
  date = {1991-01},
  journaltitle = {Philosophical Psychology},
  shortjournal = {Philosophical Psychology},
  volume = {4},
  number = {2},
  pages = {203--218},
  issn = {0951-5089, 1465-394X},
  doi = {10.1080/09515089108573027},
  url = {http://www.tandfonline.com/doi/full/10.1080/09515089108573027},
  urldate = {2021-01-22},
  abstract = {The model of memory as a store, from which records can be retrieved, is taken for granted by many contemporary researchers. On this view, memories are stored by memory traces, which represent the original event and provide a causal link between that episode and one's ability to remember it . I argue that this seemingly plausible model leads to an unacceptable conception of the relationship between mind and brain, and that a nonrepresentational, connectionist, model offers a promising alternative . I also offer a new reading of Wittgenstein's paradoxical remarks about thought and brain processes : as a critique of the cognitivist thesis that information stored in the brain has a linguistic structure and a particular location. On this reading, Wittgenstein's criticism foreshadows some of the most promising contemporary work on connectionist models of neural functioning.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/VR7TSW34/Stern - 1991 - Models of memory Wittgenstein and cognitive scien.PDF}
}

@article{steyversBayesianAnalysisHuman,
  title = {A {{Bayesian Analysis}} of {{Human Decision}}-{{Making}} on {{Bandit Problems}}},
  author = {Steyvers, Mark and Lee, Michael D and Wagenmakers, Eric-Jan},
  pages = {29},
  abstract = {The bandit problem is a dynamic decision-making task that is simply described, well-suited to controlled laboratory study, and representative of a broad class of real-world problems. In bandit problems, people must choose between a set of alternatives, each with different unknown reward rates, to maximize the total reward they receive over a fixed number of trials. A key feature of the task is that it challenges people to balance the exploration of unfamiliar choices with the exploitation of familiar ones. We use a Bayesian model of optimal decision-making on the task, in which how people balance exploration with exploitation depends on their assumptions about the distribution of reward rates. We also use Bayesian model selection measures that assesses how well people adhere to an optimal decision process, compared to simpler heuristic decision strategies. Using these models, we make inferences about the decision-making of 451 participants who completed a set of bandit problems, and relate various measures of their performance to other psychological variables, including psychometric assessments of cognitive abilities and personality traits. We find clear evidence of individual differences in the way the participants made decisions on the bandit problems, and some interesting correlations with measures of general intelligence.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2QTI7WZ3/Steyvers et al. - A Bayesian Analysis of Human Decision-Making on Ba.pdf}
}

@article{suHowFontSize,
  title = {How Font Size Affects Judgments of Learning: {{Simultaneous}} Mediating Effect of Item-Specific Beliefs about Fluency and Moderating Effect of Beliefs about Font Size and Memory},
  author = {Su, Ningxin and Li, Tongtong and Zheng, Jun and Hu, Xiao and Fan, Tian and Luo, Liang},
  pages = {14},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/6HEEJTNW/Su et al. - 2018 - How font size affects judgments of learning Simul.pdf;/Users/alexten/Zotero/storage/7XSFLJSS/Su et al. - How font size affects judgments of learning Simul.pdf}
}

@article{suriTDModelsReward2002,
  title = {{{TD}} Models of Reward Predictive Responses in Dopamine Neurons},
  author = {Suri, Roland E.},
  date = {2002-06},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {15},
  number = {4-6},
  pages = {523--533},
  issn = {08936080},
  doi = {10.1016/S0893-6080(02)00046-1},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608002000461},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WKAWVV7T/Suri - 2002 - TD models of reward predictive responses in dopami.pdf}
}

@article{suriTDModelsReward2002a,
  title = {{{TD}} Models of Reward Predictive Responses in Dopamine Neurons},
  author = {Suri, Roland E.},
  date = {2002-06},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {15},
  number = {4-6},
  pages = {523--533},
  issn = {08936080},
  doi = {10.1016/S0893-6080(02)00046-1},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608002000461},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ZHDCKAZQ/Suri - 2002 - TD models of reward predictive responses in dopami.pdf}
}

@article{suriValueBasedDecisionMaking,
  title = {Value-{{Based Decision Making}}:},
  author = {Suri, Gaurav and Gross, James J and McClelland, James L},
  pages = {87},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2GCTVR89/Suri et al. - Value-Based Decision Making.pdf}
}

@article{suriValuebasedDecisionMaking2020,
  title = {Value-Based Decision Making: {{An}} Interactive Activation Perspective.},
  shorttitle = {Value-Based Decision Making},
  author = {Suri, Gaurav and Gross, James J. and McClelland, James L.},
  date = {2020-03},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {127},
  number = {2},
  pages = {153--185},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/rev0000164},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/rev0000164},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/NN6N5MM8/Suri et al. - 2020 - Value-based decision making An interactive activa.pdf;/Users/alexten/Zotero/storage/YL2LCHSF/Suri et al. - 2020 - Value-based decision making An interactive activa.pdf}
}

@article{suriValuebasedDecisionMaking2020b,
  title = {Value-Based Decision Making: {{An}} Interactive Activation Perspective.},
  shorttitle = {Value-Based Decision Making},
  author = {Suri, Gaurav and Gross, James J. and McClelland, James L.},
  date = {2020-03},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {127},
  number = {2},
  pages = {153--185},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/rev0000164},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/rev0000164},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BUY6AD3I/Suri et al. - 2020 - Value-based decision making An interactive activa.pdf}
}

@article{sussanTrainingMetacognitiveMonitoring,
  title = {The {{Training}} of {{Metacognitive Monitoring}} in {{Children}}},
  author = {Sussan, Danielle and Son, Lisa K},
  pages = {12},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/64JRSGNV/Sussan and Son - The Training of Metacognitive Monitoring in Childr.pdf}
}

@article{sussanTrainingMetacognitiveMonitoringa,
  title = {The {{Training}} of {{Metacognitive Monitoring}} in {{Children}}},
  author = {Sussan, Danielle and Son, Lisa K},
  pages = {12},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/W24KVMCV/Sussan and Son - The Training of Metacognitive Monitoring in Childr.pdf}
}

@article{suttonLearningPredictMethods,
  title = {Learning to Predict by the Methods of Temporal Differences},
  author = {Sutton, Richard S},
  pages = {37},
  abstract = {This article introduces a class of incremental learning procedures specialized for prediction that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, tile new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference method\textasciitilde{} have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, telnporal-differenee methods require less memory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporaldifference methods can be applied to advantage.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UVTKHD8J/Sutton - Learning to predict by the methods of temporal dif.pdf}
}

@article{suttonLearningPredictMethods1988,
  title = {Learning to Predict by the Methods of Temporal Differences},
  author = {Sutton, Richard S.},
  date = {1988-08},
  journaltitle = {Machine Learning},
  shortjournal = {Mach Learn},
  volume = {3},
  number = {1},
  pages = {9--44},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/BF00115009},
  url = {http://link.springer.com/10.1007/BF00115009},
  urldate = {2021-01-22},
  abstract = {This article introduces a class of incremental learning procedures specialized for prediction that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, tile new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference method\textasciitilde{} have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, telnporal-differenee methods require less memory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporaldifference methods can be applied to advantage.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4KI4NHUJ/Sutton - 1988 - Learning to predict by the methods of temporal dif.pdf}
}

@article{symondsBriefGuideModel2011,
  title = {A Brief Guide to Model Selection, Multimodel Inference and Model Averaging in Behavioural Ecology Using {{Akaike}}’s Information Criterion},
  author = {Symonds, Matthew R E and Moussalli, Adnan},
  date = {2011},
  journaltitle = {Behav Ecol Sociobiol},
  pages = {9},
  abstract = {Akaike’s information criterion (AIC) is increasingly being used in analyses in the field of ecology. This measure allows one to compare and rank multiple competing models and to estimate which of them best approximates the “true” process underlying the biological phenomenon under study. Behavioural ecologists have been slow to adopt this statistical tool, perhaps because of unfounded fears regarding the complexity of the technique. Here, we provide, using recent examples from the behavioural ecology literature, a simple introductory guide to AIC: what it is, how and when to apply it and what it achieves. We discuss multimodel inference using AIC—a procedure which should be used where no one model is strongly supported. Finally, we highlight a few of the pitfalls and problems that can be encountered by novice practitioners.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7DX3IJ85/Symonds and Moussalli - 2011 - A brief guide to model selection, multimodel infer.pdf}
}

@article{SystematicityLanguageThought,
  title = {On the {{Systematicity}} of {{Language}} and {{Thought}}},
  journaltitle = {THE JOURNAL OF PHILOSOPHY},
  pages = {29},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FVBDRQJJ/On the Systematicity of Language and Thought.pdf}
}

@article{SystematicityLanguageThoughta,
  title = {On the {{Systematicity}} of {{Language}} and {{Thought}}},
  journaltitle = {THE JOURNAL OF PHILOSOPHY},
  pages = {29},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FENF6C6H/On the Systematicity of Language and Thought.pdf}
}

@article{talevichComprehensiveTaxonomyHuman2017a,
  title = {Toward a Comprehensive Taxonomy of Human Motives},
  author = {Talevich, Jennifer R and Read, Stephen J and Walsh, David A and Iyer, Ravi and Chopra, Gurveen},
  date = {2017},
  journaltitle = {PLOS ONE},
  pages = {32},
  abstract = {A major success in personality has been the development of a consensual structure of traits. However, much less progress has been made on the structure of an equally important aspect of human psychology: motives. We present an empirically and theoretically structured hierarchical taxonomy of 161 motives gleaned from a literature review from McDougall to the present and based on the cluster analysis of similarity judgments among these 161 motives, a broader sampling of motives than previous work. At the broadest level were: Meaning, Communion, and Agency. These divided into nine clusters: Morality \& Virtue, Religion \& Spirituality, Self-Actualization, Avoidance, Social Relating, Family, Health, Mastery \& Competence, and Financial \& Occupational Success. Each divided into more concrete clusters to form 5 levels. We discuss contributions to research on motives, especially recent work on goal systems, and the aiding of communication and systematization of research. Finally, we compare the taxonomy to other motive organizations.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ZL5SACV8/Talevich et al. - 2017 - Toward a comprehensive taxonomy of human motives.pdf}
}

@article{tanakaWithinPersonAnalysesSituational,
  title = {Within-{{Person Analyses}} of {{Situational Interest}} and {{Boredom}}: {{Interactions Between Task}}-{{Specific Perceptions}} and {{Achievement Goals}}},
  author = {Tanaka, Ayumi and Murayama, Kou},
  pages = {13},
  abstract = {Despite the increasing number of studies examining the correlates of interest and boredom, surprisingly little research has focused on within-person fluctuations in these emotions, making it difficult to describe their situational nature. To address this gap in the literature, this study conducted repeated measurements (12 times) on a sample of 158 undergraduate students using a variety of self-report assessments and examined the within-person relationships between task-specific perceptions (expectancy, utility, and difficulty) and interest and boredom. This study further explored the role of achievement goals in predicting between-person differences in these within-person relationships. Using hierarchical linear modeling, we found that, on average, a higher perception of both expectancy and utility, as well as a lower perception of difficulty, was associated with higher interest and lower boredom levels within individuals. Moreover, mastery-approach goals weakened the negative within-person relationship between difficulty and interest and the negative within-person relationship between utility and boredom. Mastery-avoidance and performance-avoidance goals strengthened the negative relationship between expectancy and boredom. These results suggest how educators can more effectively instruct students with different types of goals, minimizing boredom and maximizing interest and learning.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/L4WBT8B6/Tanaka and Murayama - Within-Person Analyses of Situational Interest and.pdf}
}

@article{tanakaWithinpersonAnalysesSituational2014,
  title = {Within-Person Analyses of Situational Interest and Boredom: {{Interactions}} between Task-Specific Perceptions and Achievement Goals.},
  shorttitle = {Within-Person Analyses of Situational Interest and Boredom},
  author = {Tanaka, Ayumi and Murayama, Kou},
  date = {2014},
  journaltitle = {Journal of Educational Psychology},
  shortjournal = {Journal of Educational Psychology},
  volume = {106},
  number = {4},
  pages = {1122--1134},
  issn = {1939-2176, 0022-0663},
  doi = {10.1037/a0036659},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0036659},
  urldate = {2021-01-22},
  abstract = {Despite the increasing number of studies examining the correlates of interest and boredom, surprisingly little research has focused on within-person fluctuations in these emotions, making it difficult to describe their situational nature. To address this gap in the literature, this study conducted repeated measurements (12 times) on a sample of 158 undergraduate students using a variety of self-report assessments and examined the within-person relationships between task-specific perceptions (expectancy, utility, and difficulty) and interest and boredom. This study further explored the role of achievement goals in predicting between-person differences in these within-person relationships. Using hierarchical linear modeling, we found that, on average, a higher perception of both expectancy and utility, as well as a lower perception of difficulty, was associated with higher interest and lower boredom levels within individuals. Moreover, mastery-approach goals weakened the negative within-person relationship between difficulty and interest and the negative within-person relationship between utility and boredom. Mastery-avoidance and performance-avoidance goals strengthened the negative relationship between expectancy and boredom. These results suggest how educators can more effectively instruct students with different types of goals, minimizing boredom and maximizing interest and learning.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/35JSKKPL/Tanaka and Murayama - 2014 - Within-person analyses of situational interest and.pdf}
}

@article{tapolaPredictorsOutcomesSituational,
  title = {Predictors and Outcomes of Situational Interest during a Science Learning Task},
  author = {Tapola, Anna and Veermans, Marjaana and Niemivirta, Markku},
  pages = {19},
  abstract = {In this study we examined change in students’ situational interest as a function of student and task characteristics. Fifth- and sixth-graders (n = 52) were assigned to one of two task conditions that used a different version of a science simulation. The versions differed in how concrete vs. abstract the simulation elements were. Students’ prior knowledge, achievement goal orientations, and subject-specific interest were assessed before the task and situational interest was measured repeatedly in different phases of the task. Post-task performance was assessed 1 day after the task. The results showed different mean-level changes in situational interest in the two task conditions; students working with the more concrete version of the simulation reported increase in their interest while the opposite was true for students working with the more abstract version. The ratings of situational interest were nevertheless rather stable over time, regardless of the task condition. Students’ situational interest at the beginning of the task was predicted by masteryintrinsic goal orientation and subject-specific interest. Post-task performance was predicted by prior knowledge and the task condition; students working in the more concrete task condition performed better. The importance of acknowledging both individual characteristics and task elements in the emergence of students’ situational interest is discussed.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CG6TPN9H/Tapola et al. - Predictors and outcomes of situational interest du.pdf}
}

@article{tapolaPredictorsOutcomesSituational2013,
  title = {Predictors and Outcomes of Situational Interest during a Science Learning Task},
  author = {Tapola, Anna and Veermans, Marjaana and Niemivirta, Markku},
  date = {2013-11},
  journaltitle = {Instructional Science},
  shortjournal = {Instr Sci},
  volume = {41},
  number = {6},
  pages = {1047--1064},
  issn = {0020-4277, 1573-1952},
  doi = {10.1007/s11251-013-9273-6},
  url = {http://link.springer.com/10.1007/s11251-013-9273-6},
  urldate = {2021-01-22},
  abstract = {In this study we examined change in students’ situational interest as a function of student and task characteristics. Fifth- and sixth-graders (n = 52) were assigned to one of two task conditions that used a different version of a science simulation. The versions differed in how concrete vs. abstract the simulation elements were. Students’ prior knowledge, achievement goal orientations, and subject-specific interest were assessed before the task and situational interest was measured repeatedly in different phases of the task. Post-task performance was assessed 1 day after the task. The results showed different mean-level changes in situational interest in the two task conditions; students working with the more concrete version of the simulation reported increase in their interest while the opposite was true for students working with the more abstract version. The ratings of situational interest were nevertheless rather stable over time, regardless of the task condition. Students’ situational interest at the beginning of the task was predicted by masteryintrinsic goal orientation and subject-specific interest. Post-task performance was predicted by prior knowledge and the task condition; students working in the more concrete task condition performed better. The importance of acknowledging both individual characteristics and task elements in the emergence of students’ situational interest is discussed.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SYEU4S6Z/Tapola et al. - 2013 - Predictors and outcomes of situational interest du.pdf}
}

@incollection{tenCuriositydrivenExplorationDiversityinpress,
  title = {Curiosity-Driven Exploration: {{Diversity}} of Mechanisms and Functions},
  booktitle = {To Appear in a {{Cambridge University Press}} Volume on Information-Seeking},
  author = {Ten, Alexandr and Oudeyer, Pierre-Yves and Moulin-Frier, Clement},
  year = {in press},
  pages = {21},
  publisher = {{Cambridge University Press}},
  abstract = {Intrinsically motivated information-seeking, also called curiositydriven exploration, is widely believed to be a key ingredient for autonomous learning in the real world. Such forms of spontaneous exploration have been studied in multiple independent lines of computational research, producing a diverse range of algorithmic models that capture different aspects of these processes. These algorithms resolve some of the limitations of neurocognitive theories by formally describing computational functions and algorithmic implementations of intrinsically motivated learning. Moreover, they reveal a high diversity of effective forms of intrinsically motivated information-seeking that can be characterized along different mechanistic and functional dimensions. This chapter aims at reviewing different classes of algorithms and highlighting several important dimensions of variation among them. Identifying these dimensions provides means for structuring a comprehensive taxonomy of approaches. We believe this exercise to be useful in working towards a general computational account of information-seeking. Such an account should facilitate the proposition of new hypotheses about informationseeking in humans and complement the existing psychological theory of curiosity.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/36QRZD9Q/Ten et al. - Curiosity-driven exploration Diversity of mechani.pdf}
}

@article{tenenbaumBayesianModelingHuman1999,
  title = {Bayesian Modeling of Human Concept Learning},
  author = {Tenenbaum, Joshua B},
  date = {1999},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {11},
  pages = {7},
  abstract = {I consider the problem of learning concepts from small numbers of positive examples, a feat which humans perform routinely but which computers are rarely capable of. Bridging machine learning and cognitive science perspectives, I present both theoretical analysis and an empirical study with human subjects for the simple task of learning concepts corresponding to axis-aligned rectangles in a multidimensional feature space. Existing learning models, when applied to this task, cannot explain how subjects generalize from only a few examples of the concept. I propose a principled Bayesian model based on the assumption that the examples are a random sample from the concept to be learned. The model gives precise fits to human behavior on this simple task and provides qualitative insights into more complex, realistic cases of concept learning.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/AKHQC56Z/Tenenbaum - Bayesian modeling of human concept learning.pdf}
}

@article{tenenbaumRulesSimilarityConcept,
  title = {Rules and {{Similarity}} in {{Concept Learning}}},
  author = {Tenenbaum, Joshua B},
  pages = {7},
  abstract = {This paper argues that two apparently distinct modes of generalizing concepts – abstracting rules and computing similarity to exemplars – should both be seen as special cases of a more general Bayesian learning framework. Bayes explains the specific workings of these two modes – which rules are abstracted, how similarity is measured – as well as why generalization should appear rule- or similarity-based in different situations. This analysis also suggests why the rules/similarity distinction, even if not computationally fundamental, may still be useful at the algorithmic level as part of a principled approximation to fully Bayesian learning.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Z354NJ5K/Tenenbaum - Rules and Similarity in Concept Learning.pdf}
}

@article{tenHumansMonitorLearning,
  title = {Humans Monitor Learning Progress in Curiosity-Driven Exploration},
  author = {Ten, Alexandr and Kaushik, Pramod and Oudeyer, Pierre-Yves and Gottlieb, Jacqueline},
  pages = {18},
  abstract = {Curiosity-driven learning is foundational to human cognition. By enabling humans to autonomously decide when and what to learn, curiosity has been argued to be crucial for self-organizing temporally extended learning curricula. However, the mechanisms driving people to set intrinsic goals, when they are free to explore multiple learning activities, are still poorly understood. Computational theories propose different heuristics, including competence measures (e.g., percent correct) and learning progress, that could be used as intrinsic utility functions to efficiently organize exploration. Such intrinsic utilities constitute computationally cheap but smart heuristics to prevent people from laboring in vain on unlearnable activities, while still motivating them to self-challenge on difficult learnable activities. Here, we provide empirical evidence for these ideas by means of a free-choice experimental paradigm and computational modeling. We show that while humans rely on competence information to avoid easy tasks, models that include a learning-progress component provide the best fit to task selection data. These results bridge the research in artificial and biological curiosity, reveal strategies that are used by humans but have not been considered in computational research, and introduce tools for probing how humans become intrinsically motivated to learn and acquire interests and skills on extended time scales.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/KCWUZFYH/Ten et al. - Humans monitor learning progress in curiosity-driv.pdf}
}

@article{tenIntrinsicRewardsHuman2021,
  title = {Intrinsic {{Rewards}} in {{Human Curiosity}}-{{Driven Exploration}}: {{An Empirical Study}}},
  author = {Ten, Alexandr and Gottlieb, Jacqueline and Oudeyer, Pierre-Yves},
  date = {2021},
  volume = {43},
  pages = {7},
  issn = {1069-7977},
  abstract = {Despite their apparent importance for the acquisition of fullfledged human intelligence, mechanisms of intrinsically motivated autonomous learning are poorly understood. How do humans identify useful sources of knowledge and decide which learning situations to approach in the absence of external rewards? While the recognition of this important problem has grown in psychological sciences over the recent years, an intriguing proposition for the possible mechanism comes from artificial intelligence, where efficient autonomous learning is achieved by programming agents to follow the heuristic of maximizing learning progress (LP) during exploration. In this study, we set out to examine the empirical evidence for this idea. Using computational modeling, we demonstrate that humans show signs of following LP while they freely explore and practice a set of multiple learning activities of varying difficulty, including an activity that is impossible to learn. Different approaches to operationalizing the notion of LP and their plausibility in light of empirical data are also discussed. We also show that models combining several types of intrinsic rewards fit better human exploration data than single component models considered so far in theoretical accounts.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/C3JGTGWV/Ten - Intrinsic Rewards in Human Curiosity-Driven Explor.pdf}
}

@article{thiedeGeneralModelSelfRegulated,
  title = {Toward a {{General Model}} of {{Self}}-{{Regulated Study}}: {{An Analysis}} of {{Selection}} of {{Items}} for {{Study}} and {{Self}}-{{Paced Study Time}}},
  author = {Thiede, Keith W and Dunlosky, John},
  pages = {14},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IB8WUVY8/Thiede and Dunlosky - Toward a General Model of Self-Regulated Study An.pdf}
}

@article{thiedeImportanceMonitoringSelfregulation1999,
  title = {The Importance of Monitoring and Self-Regulation during Multitrial Learning},
  author = {Thiede, Keith W.},
  date = {1999-12},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychonomic Bulletin \& Review},
  volume = {6},
  number = {4},
  pages = {662--667},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03212976},
  url = {http://link.springer.com/10.3758/BF03212976},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ZUURULBH/Thiede - 1999 - The importance of monitoring and self-regulation d.pdf}
}

@article{thrunCientExplorationReinforcement,
  title = {E Cient {{Exploration In Reinforcement Learning}}},
  author = {Thrun, Sebastian B},
  pages = {44},
  abstract = {Exploration plays a fundamental role in any active learning system. This study evaluates the role of exploration in active learning and describes several local techniques for exploration in nite, discrete domains, embedded in a reinforcement learning framework  delayed reinforcement .},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/RW9CZ7AC/Thrun - E cient Exploration In Reinforcement Learning.pdf;/Users/alexten/Zotero/storage/V4K5TYZS/Thrun - E cient Exploration In Reinforcement Learning.pdf}
}

@article{timmermansHigherOrderThoughts2012,
  title = {Higher Order Thoughts in Action: Consciousness as an Unconscious Re-Description Process},
  shorttitle = {Higher Order Thoughts in Action},
  author = {Timmermans, Bert and Schilbach, Leonhard and Pasquali, Antoine and Cleeremans, Axel},
  date = {2012-05-19},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  shortjournal = {Phil. Trans. R. Soc. B},
  volume = {367},
  number = {1594},
  pages = {1412--1423},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2011.0421},
  url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2011.0421},
  urldate = {2021-01-22},
  abstract = {Metacognition is usually construed as a conscious, intentional process whereby people reflect upon their own mental activity. Here, we instead suggest that metacognition is but an instance of a larger class of representational re-description processes that we assume occur unconsciously and automatically. From this perspective, the brain continuously and unconsciously learns to anticipate the consequences of action or activity on itself, on the world and on other people through three predictive loops: an inner loop, a perception–action loop and a self–other (social cognition) loop, which together form a tangled hierarchy. We ask what kinds of mechanisms may subtend this form of enactive metacognition. We extend previous neural network simulations and compare the model with signal detection theory, highlighting that while the latter approach assumes that both type I (objective) and type II (subjective, metacognition-based) decisions tap into the same signal at different hierarchical levels, our approach is closer to dual-route models in which it is assumed that the re-descriptions made possible by the emergence of meta-representations occur independently and outside of the first-order causal chain. We close by reviewing relevant neurological evidence for the idea that awareness, self-awareness and social cognition involve the same mechanisms.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Q3GNMPSY/Timmermans et al. - 2012 - Higher order thoughts in action consciousness as .pdf;/Users/alexten/Zotero/storage/TZHF7AZK/Timmermans et al. - 2012 - Higher order thoughts in action consciousness as .pdf}
}

@article{townsendJudgmentsLearningImprovement2011,
  title = {Judgments of Learning and Improvement},
  author = {Townsend, Corinne L. and Heit, Evan},
  date = {2011-02},
  journaltitle = {Memory \& Cognition},
  shortjournal = {Mem Cogn},
  volume = {39},
  number = {2},
  pages = {204--216},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/s13421-010-0019-2},
  url = {http://link.springer.com/10.3758/s13421-010-0019-2},
  urldate = {2021-01-22},
  abstract = {Can learners accurately judge the rate of their learning? Rates of learning may be informative when study time is allocated across materials, and students' judgments of their learning rate have been proposed as a possible metacognitive tool. Participants estimated how much they improved between presentations in multitrial learning situations in which n-gram paragraphs (in Experiments 1 and 2) or word pairs (Experiments 3 and 4) were learned . In the first experiment, participants rated improvement on a percentage scale, whereas on the second and third, judgments were given on a 0–6 scale. Experiment 4 used both a percentage scale and an absolute number scale. The main result was that judgments of improvement were poorly correlated with actual improvement and, in one case, were negatively correlated. Although judgments of improvement were correlated with changes in judgments of learning, they were not reliable indicators of actual improvement. Implications are discussed for theoretical work on metacognition.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/XKT8WDAC/Townsend and Heit - 2011 - Judgments of learning and improvement.pdf}
}

@article{townsendJudgmentsLearningImprovement2011a,
  title = {Judgments of Learning and Improvement},
  author = {Townsend, Corinne L and Heit, Evan},
  date = {2011},
  pages = {13},
  abstract = {Can learners accurately judge the rate of their learning? Rates of learning may be informative when study time is allocated across materials, and students' judgments of their learning rate have been proposed as a possible metacognitive tool. Participants estimated how much they improved between presentations in multitrial learning situations in which n-gram paragraphs (in Experiments 1 and 2) or word pairs (Experiments 3 and 4) were learned . In the first experiment, participants rated improvement on a percentage scale, whereas on the second and third, judgments were given on a 0–6 scale. Experiment 4 used both a percentage scale and an absolute number scale. The main result was that judgments of improvement were poorly correlated with actual improvement and, in one case, were negatively correlated. Although judgments of improvement were correlated with changes in judgments of learning, they were not reliable indicators of actual improvement. Implications are discussed for theoretical work on metacognition.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/RTEJ95JJ/Townsend and Heit - 2011 - Judgments of learning and improvement.pdf}
}

@article{tricomiPerformanceFeedbackDrives,
  title = {Performance {{Feedback Drives Caudate Activation}} in a {{Phonological Learning Task}}},
  author = {Tricomi, Elizabeth and Delgado, Mauricio R and McCandliss, Bruce D and McClelland, James L and Fiez, Julie A},
  volume = {18},
  number = {6},
  pages = {15},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/ZYKGKTBI/Tricomi et al. - Performance Feedback Drives Caudate Activation in .pdf}
}

@article{tricomiPerformanceFeedbackDrivesa,
  title = {Performance {{Feedback Drives Caudate Activation}} in a {{Phonological Learning Task}}},
  author = {Tricomi, Elizabeth and Delgado, Mauricio R and McCandliss, Bruce D and McClelland, James L and Fiez, Julie A},
  volume = {18},
  number = {6},
  pages = {15},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BR7BNQD9/Tricomi et al. - Performance Feedback Drives Caudate Activation in .pdf}
}

@article{tricomiRoleFeedbackLearning,
  title = {The {{Role}} of {{Feedback}} in {{Learning}} and {{Motivation}}},
  author = {Tricomi, Elizabeth and DePasque, Samantha},
  pages = {28},
  abstract = {Performance feedback about whether responses are correct or incorrect provides valuable information to help guide learning. Although feedback itself has no extrinsic value, it can produce subjective feelings similar to “rewards” and “punishments.” Therefore, feedback can play both an informative and a motivational role. Over the past decade, researchers have identified a neural circuit that processes reward value and promotes reinforcement learning, involving target regions of dopaminergic input (e.g., striatum and ventromedial prefrontal cortex). Importantly, this circuit is engaged by performance feedback even in the absence of reward. Recent research suggests that feedback-related brain activity can be modulated by motivational context, such as whether feedback reflects goal achievement, whether learners are oriented toward the informative versus evaluative aspect of feedback, and whether individual learners are motivated to perform well relative to their peers. This body of research suggests that the brain responds flexibly to feedback, based on the learner’s goals.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/JYT9JSGS/Tricomi and DePasque - The Role of Feedback in Learning and Motivation.pdf}
}

@incollection{tricomiRoleFeedbackLearning2016,
  title = {The {{Role}} of {{Feedback}} in {{Learning}} and {{Motivation}}},
  booktitle = {Advances in {{Motivation}} and {{Achievement}}},
  author = {Tricomi, Elizabeth and DePasque, Samantha},
  editor = {Kim, Sung-il and Reeve, Johnmarshall and Bong, Mimi},
  date = {2016-11-21},
  volume = {19},
  pages = {175--202},
  publisher = {{Emerald Group Publishing Limited}},
  doi = {10.1108/S0749-742320160000019015},
  url = {https://www.emerald.com/insight/content/doi/10.1108/S0749-742320160000019015/full/html},
  urldate = {2021-01-22},
  abstract = {Performance feedback about whether responses are correct or incorrect provides valuable information to help guide learning. Although feedback itself has no extrinsic value, it can produce subjective feelings similar to “rewards” and “punishments.” Therefore, feedback can play both an informative and a motivational role. Over the past decade, researchers have identified a neural circuit that processes reward value and promotes reinforcement learning, involving target regions of dopaminergic input (e.g., striatum and ventromedial prefrontal cortex). Importantly, this circuit is engaged by performance feedback even in the absence of reward. Recent research suggests that feedback-related brain activity can be modulated by motivational context, such as whether feedback reflects goal achievement, whether learners are oriented toward the informative versus evaluative aspect of feedback, and whether individual learners are motivated to perform well relative to their peers. This body of research suggests that the brain responds flexibly to feedback, based on the learner’s goals.},
  isbn = {978-1-78635-474-7 978-1-78635-473-0},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DN6HI4MI/Tricomi and DePasque - 2016 - The Role of Feedback in Learning and Motivation.pdf}
}

@article{tsaiEffectsAmountInformation2008,
  title = {Effects of Amount of Information on Judgment Accuracy and Confidence},
  author = {Tsai, Claire I and Klayman, Joshua and Hastie, Reid},
  date = {2008},
  journaltitle = {Organizational Behavior and Human Decision Processes},
  pages = {9},
  abstract = {When a person evaluates his or her confidence in a judgment, what is the effect of receiving more judgment-relevant information? We report three studies that show when judges receive more information, their confidence increases more than their accuracy, producing substantial confidence–accuracy discrepancies. Our results suggest that judges do not adjust for the cognitive limitations that reduce their ability to use additional information effectively. We place these findings in a more general framework of understanding the cues to confidence that judges use and how those cues relate to accuracy and calibration.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4P45FS6L/Tsai et al. - 2008 - Effects of amount of information on judgment accur.pdf;/Users/alexten/Zotero/storage/M7DJDK3Z/Tsai et al. - 2008 - Effects of amount of information on judgment accur.pdf}
}

@article{tsutsuiComplexityScaleAesthetic2011,
  title = {Complexity {{Scale}} and {{Aesthetic Judgments}} of {{Color Combinations}}},
  author = {Tsutsui, Ako and Ohmi, Gentarow},
  date = {2011},
  journaltitle = {Empirical Studies of the Arts},
  volume = {29},
  number = {1},
  pages = {15},
  abstract = {The present research constructed a complexity scale of color combinations and examined whether the scale can account for aesthetic judgments. Twenty-eight Japanese undergraduate students rated 96 color combinations on scales of complexity, pleasantness, and interestingness. In two factors of composing color combinations, complexity was defined by both factors of the color relations (similarity or contrast between component colors) and of the number of colors. This confirms that the subjective complexity scale in color combinations is well explained by compositions of these two factors. Pleasantness showed a relationship with complexity suggestive of an inverted-U function in mean ratings; however, the relationship between interestingness and complexity was linear. These relations suggest that the complexity scale is closely related to the aesthetic judgments.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PZUBPFUU/Tsutsui and Ohmi - Complexity Scale and Aesthetic Judgments of Color .pdf}
}

@article{tverskySupportTheoryNonextensional,
  title = {Support {{Theory}}: {{A Nonextensional Representation}} of {{Subjective Probability}}},
  author = {Tversky, Amos and Koehler, Derek J},
  pages = {21},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FVCY3FJR/Tversky and Koehler - Support Theory A Nonextensional Representation of.pdf}
}

@article{ullmanNatureOriginIntuitive,
  title = {On the {{Nature}} and {{Origin}} of {{Intuitive Theories}}: {{Learning}}, {{Physics}} and {{Psychology}}},
  author = {Ullman, Tomer David},
  pages = {236},
  abstract = {This thesis develops formal computational models of intuitive theories, in particular intuitive physics and intuitive psychology, which form the basis of commonsense reasoning. The overarching formal framework is that of hierarchical Bayesian models, which see the mind as having domain-specific hypotheses about how the world works. The work first extends models of intuitive psychology to include higher-level social utilities, arguing against a pure ‘classifier’ view. Second, the work extends models of intuitive physics by introducing an ontological hierarchy of physics concepts, and examining how well people can reason about novel dynamic displays. I then examine the question of learning intuitive theories in general, arguing that an algorithmic approach based on stochastic search can address several puzzles of learning, including the ‘chicken and egg’ problem of concept learning. Finally, I argue the need for a joint theory-space for reasoning about intuitive physics and intuitive psychology, and provide such a simplified space in the form of a generative model for a novel domain called Lineland. Taken together, these results forge links between formal modeling, intuitive theories, and cognitive development.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/Q5EB2LM4/Ullman - On the Nature and Origin of Intuitive Theories Le.pdf}
}

@online{vanderplasFrequentismBayesianismPythondriven2014,
  title = {Frequentism and {{Bayesianism}}: {{A Python}}-Driven {{Primer}}},
  shorttitle = {Frequentism and {{Bayesianism}}},
  author = {VanderPlas, Jake},
  date = {2014-11-18},
  eprint = {1411.5018},
  eprinttype = {arxiv},
  primaryclass = {astro-ph},
  url = {http://arxiv.org/abs/1411.5018},
  urldate = {2021-01-22},
  abstract = {This paper presents a brief, semi-technical comparison of the essential features of the frequentist and Bayesian approaches to statistical inference, with several illustrative examples implemented in Python. The differences between frequentism and Bayesianism fundamentally stem from differing definitions of probability, a philosophical divide which leads to distinct approaches to the solution of statistical problems as well as contrasting ways of asking and answering questions about unknown parameters. After an example-driven discussion of these differences, we briefly compare several leading Python statistical packages which implement frequentist inference using classical methods and Bayesian inference using Markov Chain Monte Carlo.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
  file = {/Users/alexten/Zotero/storage/AZHFSG35/VanderPlas - 2014 - Frequentism and Bayesianism A Python-driven Prime.pdf;/Users/alexten/Zotero/storage/FFHQK2UH/VanderPlas - 2014 - Frequentism and Bayesianism A Python-driven Prime.pdf}
}

@article{vangelderWHYDISTRIBUTEDREPRESENTATION,
  title = {{{WHY DISTRIBUTED REPRESENTATION}} 15 {{INHERENTLY NON}}-{{SYMBOLIC}}},
  author = {van Gelder, Tim},
  options = {useprefix=true},
  pages = {9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/DXQTY7G3/van Gelder - WHY DISTRIBUTED REPRESENTATION 15 INHERENTLY NON-S.pdf}
}

@article{vanhoveCollinearityIsnDisease,
  title = {Collinearity Isn’t a Disease That Needs Curing},
  author = {Vanhove, Jan},
  pages = {11},
  abstract = {Once they have learnt about the effects of collinearity on the output of multiple regression models, researchers may unduly worry about these and resort to (sometimes dubious) modelling techniques to mitigate them. I argue that, to the extent that problems occur in the presence of collinearity, they are not caused by it but rather by common mental shortcuts that researchers take when interpreting statistical models and that can also lead them astray in the absence of collinearity. Moreover, I illustrate that common strategies for dealing with collinearity only sidestep the perceived problem by biasing parameter estimates, reformulating the model in such a way that it maps onto different research questions, or both. I conclude that collinearity in itself is not a problem and that researchers should be aware of what their approaches for addressing it actually achieve.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/GIPP686K/Vanhove - Collinearity isn’t a disease that needs curing.pdf}
}

@article{vanravenzwaaijSimpleIntroductionMarkov,
  title = {A {{Simple Introduction}} to {{Markov Chain Monte}}–{{Carlo Sampling}}},
  author = {van Ravenzwaaij, Don and Cassey, Pete and Brown, Scott D},
  options = {useprefix=true},
  pages = {19},
  abstract = {Markov Chain Monte–Carlo (MCMC) is an increasingly popular method for obtaining information about distributions, especially for estimating posterior distributions in Bayesian inference. This article provides a very basic introduction to MCMC sampling. It describes what MCMC is, and what it can be used for, with simple illustrative examples. Highlighted are some of the benefits and limitations of MCMC sampling, as well as di↵erent approaches to circumventing the limitations most likely to trouble cognitive scientists.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7HLH9LES/van Ravenzwaaij et al. - A Simple Introduction to Markov Chain Monte–Carlo .pdf;/Users/alexten/Zotero/storage/JZ6M22HS/van Ravenzwaaij et al. - 2018 - A simple introduction to Markov Chain Monte–Carlo .pdf}
}

@article{vasconcelosIrrationalChoiceValue,
  title = {Irrational Choice and the Value of Information},
  author = {Vasconcelos, Marco},
  journaltitle = {Scientific Reports},
  pages = {13},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/BAGQY7AD/Vasconcelos et al. - 2015 - Irrational choice and the value of information.pdf;/Users/alexten/Zotero/storage/XE2EIE2Y/Vasconcelos - Irrational choice and the value of information.pdf}
}

@article{vasishthStatisticalMethodsLinguistic2016,
  title = {Statistical Methods for Linguistic Research: {{Foundational Ideas}} - {{Part I}}},
  shorttitle = {Statistical Methods for Linguistic Research},
  author = {Vasishth, Shravan and Nicenboim, Bruno},
  date = {2016-08},
  journaltitle = {Language and Linguistics Compass},
  shortjournal = {Language and Linguistics Compass},
  volume = {10},
  number = {8},
  eprint = {1601.01126},
  eprinttype = {arxiv},
  pages = {349--369},
  issn = {1749818X},
  doi = {10.1111/lnc3.12201},
  url = {http://arxiv.org/abs/1601.01126},
  urldate = {2021-05-23},
  abstract = {We present the fundamental ideas underlying statistical hypothesis testing using the frequentist framework. We begin with a simple example that builds up the one-sample t-test from the beginning, explaining important concepts such as the sampling distribution of the sample mean, and the iid assumption. Then we examine the p-value in detail, and discuss several important misconceptions about what a p-value does and does not tell us. This leads to a discussion of Type I, II error and power, and Type S and M error. An important conclusion from this discussion is that one should aim to carry out appropriately powered studies. Next, we discuss two common issues we have encountered in psycholinguistics and linguistics: running experiments until significance is reached; and the “garden-of-forking-paths” problem discussed by Gelman and others, whereby the researcher attempts to find statistical significance by analyzing the data in different ways. The best way to use frequentist methods is to run appropriately powered studies, check model assumptions, clearly separate exploratory data analysis from confirmatory hypothesis testing, and always attempt to replicate results.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Applications,Statistics - Methodology},
  file = {/Users/alexten/Zotero/storage/Y2QIQRKA/Vasishth and Nicenboim - 2016 - Statistical methods for linguistic research Found.pdf}
}

@article{venablesCodingMatricesContrast,
  title = {Coding {{Matrices}}, {{Contrast Matrices}} and {{Linear Models}}},
  author = {Venables, Bill},
  pages = {21},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4GS4MHII/Venables - Coding Matrices, Contrast Matrices and Linear Mode.pdf}
}

@article{voglSurprisedCuriousConfused,
  title = {Surprised–{{Curious}}–{{Confused}}: {{Epistemic Emotions}} and {{Knowledge Exploration}}},
  author = {Vogl, Elisabeth and Murayama, Kou and Pekrun, Reinhard and Loderer, Kristina},
  pages = {18},
  abstract = {Some epistemic emotions, such as surprise and curiosity, have attracted increasing scientific attention, whereas others, such as confusion, have yet to receive the attention they deserve. In addition, little is known about the relations between these emotions, their joint antecedents and outcomes, and how they differ from other emotions prompted during learning and knowledge generation (e.g., achievement emotions). In 3 studies (Ns ϭ 102, 373, 125) using a trivia task with immediate feedback, we examined within-person interrelations, antecedents, and effects of 3 epistemic emotions (surprise, curiosity, and confusion). Studies 2 and 3 additionally included 2 achievement emotions (pride and shame). Using multilevel modeling to disentangle within- and between-person variance, we found that achievement emotions were associated with accuracy (i.e., correctness of the answer), whereas epistemic emotions were related to high-confidence errors (i.e., incorrect answers a person was confident in) generating cognitive incongruity. Furthermore, as compared with achievement emotions, epistemic emotions were more strongly and positively related to subsequent knowledge exploration. Specifically, surprise and curiosity were positive predictors of exploration. Confusion had positive predictive effects on exploration which were significant in Studies 1 and 3 but not in Study 2, suggesting that the effects of confusion are less stable and need to be investigated further. Apart from the findings for confusion, the results were fully robust across all 3 studies. They shed light on the distinct origins and outcomes of epistemic emotions. Directions for future research and practical implications are discussed.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/M3CGPMUA/Vogl et al. - Surprised–Curious–Confused Epistemic Emotions and.pdf}
}

@article{vulOneDoneOptimal2014,
  title = {One and {{Done}}? {{Optimal Decisions From Very Few Samples}}},
  author = {Vul, Edward and Goodman, Noah and Griffiths, Thomas L and Tenenbaum, Joshua B},
  date = {2014},
  journaltitle = {Cognitive Science},
  pages = {39},
  abstract = {In many learning or inference tasks human behavior approximates that of a Bayesian ideal observer, suggesting that, at some level, cognition can be described as Bayesian inference. However, a number of findings have highlighted an intriguing mismatch between human behavior and standard assumptions about optimality: People often appear to make decisions based on just one or a few samples from the appropriate posterior probability distribution, rather than using the full distribution. Although sampling-based approximations are a common way to implement Bayesian inference, the very limited numbers of samples often used by humans seem insufficient to approximate the required probability distributions very accurately. Here, we consider this discrepancy in the broader framework of statistical decision theory, and ask: If people are making decisions based on samples—but as samples are costly—how many samples should people use to optimize their total expected or worst-case reward over a large number of decisions? We find that under reasonable assumptions about the time costs of sampling, making many quick but locally suboptimal decisions based on very few samples may be the globally optimal strategy over long periods. These results help to reconcile a large body of work showing sampling-based or probability matching behavior with the hypothesis that human cognition can be understood in Bayesian terms, and they suggest promising future directions for studies of resource-constrained cognition.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/HZMPJFVL/Vul et al. - 2014 - One and Done Optimal Decisions From Very Few Samp.pdf}
}

@article{vulOneDoneOptimal2014a,
  title = {One and {{Done}}? {{Optimal Decisions From Very Few Samples}}},
  shorttitle = {One and {{Done}}?},
  author = {Vul, Edward and Goodman, Noah and Griffiths, Thomas L. and Tenenbaum, Joshua B.},
  date = {2014-05},
  journaltitle = {Cognitive Science},
  shortjournal = {Cogn Sci},
  volume = {38},
  number = {4},
  pages = {599--637},
  issn = {03640213},
  doi = {10.1111/cogs.12101},
  url = {http://doi.wiley.com/10.1111/cogs.12101},
  urldate = {2021-01-22},
  abstract = {In many learning or inference tasks human behavior approximates that of a Bayesian ideal observer, suggesting that, at some level, cognition can be described as Bayesian inference. However, a number of findings have highlighted an intriguing mismatch between human behavior and standard assumptions about optimality: People often appear to make decisions based on just one or a few samples from the appropriate posterior probability distribution, rather than using the full distribution. Although sampling-based approximations are a common way to implement Bayesian inference, the very limited numbers of samples often used by humans seem insufficient to approximate the required probability distributions very accurately. Here, we consider this discrepancy in the broader framework of statistical decision theory, and ask: If people are making decisions based on samples—but as samples are costly—how many samples should people use to optimize their total expected or worst-case reward over a large number of decisions? We find that under reasonable assumptions about the time costs of sampling, making many quick but locally suboptimal decisions based on very few samples may be the globally optimal strategy over long periods. These results help to reconcile a large body of work showing sampling-based or probability matching behavior with the hypothesis that human cognition can be understood in Bayesian terms, and they suggest promising future directions for studies of resource-constrained cognition.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/FV8VMV89/Vul et al. - 2014 - One and Done Optimal Decisions From Very Few Samp.pdf}
}

@article{wagenmakersAICModelSelection,
  title = {{{AIC}} Model Selection Using {{Akaike}} Weights},
  author = {Wagenmakers, Eric-Jan and Farrell, Simon},
  pages = {5},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4VC89DEN/Wagenmakers and Farrell - AIC model selection using Akaike weights.pdf;/Users/alexten/Zotero/storage/K6UNXNBL/Wagenmakers and Farrell - AIC model selection using Akaike weights.pdf}
}

@article{wagenmakersBayesianHypothesisTesting2010,
  title = {Bayesian Hypothesis Testing for Psychologists: {{A}} Tutorial on the {{Savage}}–{{Dickey}} Method},
  author = {Wagenmakers, Eric-Jan and Lodewyckx, Tom and Kuriyal, Himanshu and Grasman, Raoul},
  date = {2010},
  journaltitle = {Cognitive Psychology},
  pages = {32},
  abstract = {In the field of cognitive psychology, the p-value hypothesis test has established a stranglehold on statistical reporting. This is unfortunate, as the p-value provides at best a rough estimate of the evidence that the data provide for the presence of an experimental effect. An alternative and arguably more appropriate measure of evidence is conveyed by a Bayesian hypothesis test, which prefers the model with the highest average likelihood. One of the main problems with this Bayesian hypothesis test, however, is that it often requires relatively sophisticated numerical methods for its computation. Here we draw attention to the Savage–Dickey density ratio method, a method that can be used to compute the result of a Bayesian hypothesis test for nested models and under certain plausible restrictions on the parameter priors. Practical examples demonstrate the method’s validity, generality, and flexibility.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/L7Z9DM3A/Wagenmakers et al. - 2010 - Bayesian hypothesis testing for psychologists A t.pdf;/Users/alexten/Zotero/storage/XDQHLJN8/Wagenmakers et al. - 2010 - Bayesian hypothesis testing for psychologists A t.pdf}
}

@article{wagenmakersBayesianInferencePsychology2018,
  title = {Bayesian Inference for Psychology. {{Part I}}: {{Theoretical}} Advantages and Practical Ramifications},
  author = {Wagenmakers, Eric-Jan},
  date = {2018},
  journaltitle = {Psychon Bull Rev},
  pages = {23},
  abstract = {Bayesian parameter estimation and Bayesian hypothesis testing present attractive alternatives to classical inference using confidence intervals and p values. In part I of this series we outline ten prominent advantages of the Bayesian approach. Many of these advantages translate to concrete opportunities for pragmatic researchers. For instance, Bayesian hypothesis testing allows researchers to quantify evidence and monitor its progression as data come in, without needing to know the intention with which the data were collected. We end by countering several objections to Bayesian hypothesis testing. Part II of this series discusses JASP, a free and open source software program that makes it easy to conduct Bayesian estimation and testing for a range of popular statistical scenarios (Wagenmakers et al., this issue).},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7DE4TX5T/Wagenmakers - 2018 - Bayesian inference for psychology. Part I Theoret.pdf;/Users/alexten/Zotero/storage/CEX3NBW5/Wagenmakers et al. - 2018 - Bayesian inference for psychology. Part I Theoret.pdf}
}

@article{wagerIndividualDifferencesMultiple2006,
  title = {Individual Differences in Multiple Types of Shifting Attention},
  author = {Wager, Tor D. and Jonides, John and Smith, Edward E.},
  date = {2006-12},
  journaltitle = {Memory \& Cognition},
  shortjournal = {Memory \& Cognition},
  volume = {34},
  number = {8},
  pages = {1730--1743},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03195934},
  url = {http://link.springer.com/10.3758/BF03195934},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2BNGZDE8/Wager et al. - 2006 - Individual differences in multiple types of shifti.pdf;/Users/alexten/Zotero/storage/6FBEGIM5/Wager and Jonides - Individual differences in multiple types of shifti.pdf}
}

@article{walkerBerlyneTheoreticalContributions,
  title = {Berlyne's Theoretical Contributions to Psychology},
  author = {Walker, Edward L},
  pages = {7},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QFEYRHJY/Walker - Berlyne's theoretical contributions to psychology.pdf;/Users/alexten/Zotero/storage/RIIMZJH8/Walker - Berlyne's theoretical contributions to psychology.pdf}
}

@article{wangWantKnowAnswer2018,
  title = {“{{I Want}} to {{Know}} the {{Answer}}! {{Give Me Fish}} ’n’ {{Chips}}!”: {{The Impact}} of {{Curiosity}} on {{Indulgent Choice}}},
  author = {Wang, Chen and Huang, Yanliu},
  date = {2018},
  journaltitle = {JOURNAL OF CONSUMER RESEARCH},
  pages = {17},
  abstract = {This research examines how incidentally induced consumer curiosity influences subsequent indulgent decisions. Prior research has primarily focused on the effect of curiosity on information seeking in the present domain. The current research goes further to propose that the curiosity effect can spill over to prompt consumers to prefer indulgent options in other, unrelated domains (e.g., food, money). This situation is likely to occur because curiosity motivates individuals to seek the missing information as the specific information reward in the current domain. Such desire to obtain the information reward primes a reward-seeking goal, which in turn leads to increased preferences for indulgent options in subsequent, unrelated domains. Furthermore, the impact of curiosity on indulgent options possesses goal-priming properties as identified by the literature. That is, the effect should (1) persist after a time delay, and (2) diminish when the reward-seeking goal is satiated by the obtainment of a reward before the indulgent task. We conduct a series of studies to provide support for our hypotheses. This research contributes to both curiosity and indulgence decision literature and offers important practical implications.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/CFB9YLJ7/Wang and Huang - 2018 - “I Want to Know the Answer! Give Me Fish ’n’ Chips.pdf;/Users/alexten/Zotero/storage/MJUQHUUP/Wang and Huang - 2018 - “I Want to Know the Answer! Give Me Fish ’n’ Chips.pdf}
}

@article{weinsteinEffectQuestionOrder,
  title = {The Effect of Question Order on Evaluations of Test Performance: How Does the Bias Evolve?},
  author = {Weinstein, Yana and Iii, Henry L Roediger},
  pages = {9},
  abstract = {Weinstein and Roediger (Memory \& Cognition 38:366–376, 2010) found that manipulating the order of questions on a general knowledge quiz resulted in differing evaluations of performance at the end of the quiz: Irrespective of their actual performance, participants were consistently more optimistic about their performance when questions were given in an easy-to-hard order. In the present experiment, the participants were stopped 10 times throughout a 100-item test and asked to evaluate their performance on the last 10 questions they had answered, as well as rating their impressions of the test so far and predicting their final performance. Arranging the questions from the easiest to the hardest produced more optimistic performance evaluations on each block than did an analogous hard–easy question order, even though performance on the two versions did not differ significantly as a function of question order. Furthermore, the ratings of item difficulty on each block of 10 questions were asymmetrical in the two conditions, with a higher sensitivity to increasing as compared to decreasing question difficulty. On the other hand, the item-by-item ratings and predictions remained unaffected by question order. Our findings are best explained by an anchoring interpretation, which suggests that students fail to adjust their evaluations of performance as the difficulty of the questions changes across the test.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/A7WETBRC/Weinstein and Iii - The effect of question order on evaluations of tes.pdf}
}

@article{weinsteinEffectQuestionOrdera,
  title = {The Effect of Question Order on Evaluations of Test Performance: How Does the Bias Evolve?},
  author = {Weinstein, Yana and Iii, Henry L Roediger},
  pages = {9},
  abstract = {Weinstein and Roediger (Memory \& Cognition 38:366–376, 2010) found that manipulating the order of questions on a general knowledge quiz resulted in differing evaluations of performance at the end of the quiz: Irrespective of their actual performance, participants were consistently more optimistic about their performance when questions were given in an easy-to-hard order. In the present experiment, the participants were stopped 10 times throughout a 100-item test and asked to evaluate their performance on the last 10 questions they had answered, as well as rating their impressions of the test so far and predicting their final performance. Arranging the questions from the easiest to the hardest produced more optimistic performance evaluations on each block than did an analogous hard–easy question order, even though performance on the two versions did not differ significantly as a function of question order. Furthermore, the ratings of item difficulty on each block of 10 questions were asymmetrical in the two conditions, with a higher sensitivity to increasing as compared to decreasing question difficulty. On the other hand, the item-by-item ratings and predictions remained unaffected by question order. Our findings are best explained by an anchoring interpretation, which suggests that students fail to adjust their evaluations of performance as the difficulty of the questions changes across the test.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/PM8X7NRT/Weinstein and Iii - The effect of question order on evaluations of tes.pdf}
}

@article{whiteMOTIVATIONRECONSIDEREDCONCEPT,
  title = {{{MOTIVATION RECONSIDERED}}: {{THE CONCEPT OF COMPETENCE}}},
  author = {White, Robert W},
  pages = {37},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3GU58EW8/White - MOTIVATION RECONSIDERED THE CONCEPT OF COMPETENCE.pdf}
}

@article{whittingtonTheoriesErrorBackPropagation,
  title = {Theories of {{Error Back}}-{{Propagation}} in the {{Brain}}},
  author = {Whittington, James C R},
  pages = {16},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8WM9P6G4/Whittington - Theories of Error Back-Propagation in the Brain.pdf}
}

@article{whittingtonTheoriesErrorBackPropagationa,
  title = {Theories of {{Error Back}}-{{Propagation}} in the {{Brain}}},
  author = {Whittington, James C R},
  pages = {16},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WPQUGJ62/Whittington - Theories of Error Back-Propagation in the Brain.pdf}
}

@book{williamonProceedingsInternationalSymposium2013,
  title = {Proceedings of the {{International Symposium}} on {{Performance Science}} 2013.},
  author = {Williamon, Aaron},
  date = {2013},
  publisher = {{Association Européenne des Conservatoires}},
  isbn = {978-2-9601378-0-4},
  langid = {english},
  annotation = {OCLC: 859857672},
  file = {/Users/alexten/Zotero/storage/TK8NREMX/Williamon - 2013 - Proceedings of the International Symposium on Perf.pdf}
}

@book{williamonProceedingsInternationalSymposium2013a,
  title = {Proceedings of the {{International Symposium}} on {{Performance Science}} 2013.},
  author = {Williamon, Aaron},
  date = {2013},
  publisher = {{Association Européenne des Conservatoires}},
  isbn = {978-2-9601378-0-4},
  langid = {english},
  annotation = {OCLC: 859857672},
  file = {/Users/alexten/Zotero/storage/HWBBYJXC/Williamon - 2013 - Proceedings of the International Symposium on Perf.pdf}
}

@article{wilsonEcologistsGuideAnimal2009,
  title = {An Ecologists Guide to the Animal Model},
  author = {Wilson, Alastair J and Postma, Erik and Walling, Craig A and Kruuk, Loeske E B and Nussey, Daniel H},
  date = {2009},
  journaltitle = {Journal of Animal Ecology},
  pages = {14},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QJUC36IA/Wilson et al. - 2009 - An ecologists guide to the animal model.pdf}
}

@article{wilsonEightyFivePercent,
  title = {The {{Eighty Five Percent Rule}} for Optimal Learning},
  author = {Wilson, Robert C},
  pages = {9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/WNU4H6V7/Wilson - The Eighty Five Percent Rule for optimal learning.pdf}
}

@article{wilsonEightyFivePercenta,
  title = {The {{Eighty Five Percent Rule}} for Optimal Learning},
  author = {Wilson, Robert C},
  pages = {9},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/XB54HYFF/Wilson - The Eighty Five Percent Rule for optimal learning.pdf}
}

@article{wilsonHumansUseDirected,
  title = {Humans {{Use Directed}} and {{Random Exploration}} to {{Solve}} the {{Explore}}–{{Exploit Dilemma}}},
  author = {Wilson, Robert C and Geana, Andra and White, John M and Ludvig, Elliot A and Cohen, Jonathan D},
  pages = {8},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/A3Z3IMAP/Wilson et al. - Humans Use Directed and Random Exploration to Solv.pdf;/Users/alexten/Zotero/storage/XZCRQFYI/Wilson et al. - Humans Use Directed and Random Exploration to Solv.pdf}
}

@article{wilsonTenSimpleRules,
  title = {Ten Simple Rules for the Computational Modeling of Behavioral Data},
  author = {Wilson, Robert C and Collins, Anne GE},
  pages = {33},
  abstract = {Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/EIT7L9NQ/Wilson and Collins - Ten simple rules for the computational modeling of.pdf}
}

@article{wimmerGeneralizationValueReinforcement2012,
  title = {Generalization of Value in Reinforcement Learning by Humans},
  author = {Wimmer, G Elliott and Daw, Nathaniel D and Shohamy, Daphna},
  date = {2012},
  journaltitle = {European Journal of Neuroscience},
  pages = {13},
  abstract = {Research in decision-making has focused on the role of dopamine and its striatal targets in guiding choices via learned stimulus–reward or stimulus–response associations, behavior that is well described by reinforcement learning theories. However, basic reinforcement learning is relatively limited in scope and does not explain how learning about stimulus regularities or relations may guide decision-making. A candidate mechanism for this type of learning comes from the domain of memory, which has highlighted a role for the hippocampus in learning of stimulus–stimulus relations, typically dissociated from the role of the striatum in stimulus–response learning. Here, we used functional magnetic resonance imaging and computational model-based analyses to examine the joint contributions of these mechanisms to reinforcement learning. Humans performed a reinforcement learning task with added relational structure, modeled after tasks used to isolate hippocampal contributions to memory. On each trial participants chose one of four options, but the reward probabilities for pairs of options were correlated across trials. This (uninstructed) relationship between pairs of options potentially enabled an observer to learn about option values based on experience with the other options and to generalize across them. We observed blood oxygen level-dependent (BOLD) activity related to learning in the striatum and also in the hippocampus. By comparing a basic reinforcement learning model to one augmented to allow feedback to generalize between correlated options, we tested whether choice behavior and BOLD activity were influenced by the opportunity to generalize across correlated options. Although such generalization goes beyond standard computational accounts of reinforcement learning and striatal BOLD, both choices and striatal BOLD activity were better explained by the augmented model. Consistent with the hypothesized role for the hippocampus in this generalization, functional connectivity between the ventral striatum and hippocampus was modulated, across participants, by the ability of the augmented model to capture participants’ choice. Our results thus point toward an interactive model in which striatal reinforcement learning systems may employ relational representations typically associated with the hippocampus.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/7DST33BX/Wimmer et al. - 2012 - Generalization of value in reinforcement learning .pdf;/Users/alexten/Zotero/storage/GZJLAQ3N/Wimmer et al. - 2012 - Generalization of value in reinforcement learning .pdf}
}

@article{wimmerGoalOrientationsActivation2018,
  title = {Goal {{Orientations}} and {{Activation}} of {{Approach Versus Avoidance Motivation While Awaiting}} an {{Achievement Situation}} in the {{Laboratory}}},
  author = {Wimmer, Sigrid},
  date = {2018},
  journaltitle = {Frontiers in Psychology},
  volume = {9},
  pages = {10},
  abstract = {While some students try to give their best in an achievement situation, others show disengagement and just want to get the situation over and done with. The present study investigates the role of students’ tendencies for approach or avoidance motivation while anticipating tasks and the corresponding activation of the approach/avoidance motivational system as indicated by transient changes of EEG alpha asymmetry. Overall, 62 students (50 female; age: M = 23.8, SD = 3.5) completed a goal orientation questionnaire (learning goals, performance-approach, performance-avoidance, and work avoidance). They joined a laboratory experiment where EEG was recorded during resting condition as well as when students were anticipating tasks. Standard multiple regression analysis showed that higher values on performance-avoidance were related to a higher activation of the approach system whereas higher values on work avoidance were related to a higher activation of the avoidance system. Results question present assumptions about avoidance related goal orientations.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/XJZ7RD8M/Wimmer - 2018 - Goal Orientations and Activation of Approach Versu.pdf;/Users/alexten/Zotero/storage/Z8WLGUWN/Wimmer - 2018 - Goal Orientations and Activation of Approach Versu.pdf}
}

@article{wongFrameworkDefiningScientific2020,
  title = {A {{Framework}} for {{Defining Scientific Concepts}} in {{Science Education}}},
  author = {Wong, Chee Leong and Chu, Hye-Eun and Yap, Kueh Chin},
  date = {2020-12-18},
  journaltitle = {Asia-Pacific Science Education},
  shortjournal = {Asia-Pac. Sci. Educ.},
  volume = {6},
  number = {2},
  pages = {615--644},
  issn = {2364-1177},
  doi = {10.1163/23641177-BJA10010},
  url = {https://brill.com/view/journals/apse/6/2/article-p615_15.xml},
  urldate = {2021-08-10},
  abstract = {Abstract                            Studies have shown that inadequate definitions of scientific concepts could complicate the learning of science and could prevent students from understanding the definitions of scientific concepts. The article provides a framework for defining scientific concepts in primary, secondary, and university education by proposing teachers draw attention to five common               features               of a definition: object/system, nature/characteristics, cause/effect, mathematical expression/equation, and condition/ reference frame that can help students to consider four dimensions, including, ‘comprehensiveness,’ ‘precision,’ ‘consistency,’ and ‘circularity’ when learning science concepts. This framework can be used by science teachers to guide students to analyze and redefine scientific concepts in the classroom and may be especially beneficial for students in Asian countries where teachers and students often rely on rote memorization as a strategy for learning scientific concepts. We conclude by describing the need for future studies in educational contexts in Asian countries where pedagogical strategies have traditionally emphasized memorization of science concepts.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/SURNRFTW/Wong et al. - 2020 - A Framework for Defining Scientific Concepts in Sc.pdf}
}

@article{xuRationalConstructivistTheory,
  title = {Towards a {{Rational Constructivist Theory}} of {{Cognitive Development}}},
  author = {Xu, Fei},
  pages = {25},
  abstract = {This article provides a synthesis and overview of a theory of cognitive development, rational constructivism. The basic tenets of this view are as follows: (a) Initial state: Human infants begin life with a set of proto-conceptual primitives. These early representations are not in the format of a language of thought. (b) Mature state: Human adults represent the world in terms of a set of domain-specific intuitive theories. (c) Three types of mechanisms account for learning, development, and conceptual change: language and symbol learning, Bayesian inductive learning, and constructive thinking. (d) The child is an active learner, and cognitive agency is part and parcel of development. I will discuss each of these tenets, and provide an overview of the kind of empirical evidence that supports this view. This is a non-Piagetian view though it is in the spirit of constructivist theories of development; this view emphasizes the utility of formal computational models in understanding learning and developmental change. Lastly, this view also has implications for the study of philosophy of mind and epistemology.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/2R7E25P9/Xu - Towards a Rational Constructivist Theory of Cognit.pdf}
}

@article{xuRationalConstructivistTheory2019,
  title = {Towards a Rational Constructivist Theory of Cognitive Development.},
  author = {Xu, Fei},
  date = {2019-11},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {126},
  number = {6},
  pages = {841--864},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/rev0000153},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/rev0000153},
  urldate = {2021-01-22},
  abstract = {This article provides a synthesis and overview of a theory of cognitive development, rational constructivism. The basic tenets of this view are as follows: (a) Initial state: Human infants begin life with a set of proto-conceptual primitives. These early representations are not in the format of a language of thought. (b) Mature state: Human adults represent the world in terms of a set of domain-specific intuitive theories. (c) Three types of mechanisms account for learning, development, and conceptual change: language and symbol learning, Bayesian inductive learning, and constructive thinking. (d) The child is an active learner, and cognitive agency is part and parcel of development. I will discuss each of these tenets, and provide an overview of the kind of empirical evidence that supports this view. This is a non-Piagetian view though it is in the spirit of constructivist theories of development; this view emphasizes the utility of formal computational models in understanding learning and developmental change. Lastly, this view also has implications for the study of philosophy of mind and epistemology.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/N9VZBF7B/Xu - 2019 - Towards a rational constructivist theory of cognit.pdf}
}

@article{yangActiveSensingCategorization,
  title = {Active Sensing in the Categorization of Visual Patterns},
  author = {Yang, Scott Cheng-Hsin},
  pages = {22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/B6LIWCEE/Yang - Active sensing in the categorization of visual pat.pdf;/Users/alexten/Zotero/storage/SPNAQQT3/Yang - Active sensing in the categorization of visual pat.pdf}
}

@article{yeungMetacognitionHumanDecisionmaking2012,
  title = {Metacognition in Human Decision-Making: Confidence and Error Monitoring},
  author = {Yeung, Nick and Summerfield, Christopher},
  date = {2012},
  pages = {12},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/IK7HLZJJ/Yeung and Summerﬁeld - 2012 - Metacognition in human decision-making conﬁdence .pdf}
}

@article{yonelinasJournalMemoryLanguage,
  title = {Journal of {{Memory}} and {{Language}}},
  author = {Yonelinas, Andrew P},
  pages = {77},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/QPWCHFIZ/Yonelinas - Journal of Memory and Language.pdf}
}

@article{yonelinasNatureRecollectionFamiliarity2002,
  title = {The {{Nature}} of {{Recollection}} and {{Familiarity}}: {{A Review}} of 30 {{Years}} of {{Research}}},
  shorttitle = {The {{Nature}} of {{Recollection}} and {{Familiarity}}},
  author = {Yonelinas, Andrew P},
  date = {2002-04},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {46},
  number = {3},
  pages = {441--517},
  issn = {0749596X},
  doi = {10.1006/jmla.2002.2864},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X02928640},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/3DIRUV85/Yonelinas - 2002 - The Nature of Recollection and Familiarity A Revi.pdf}
}

@article{yuDynamicsAttentionalSelection,
  title = {Dynamics of {{Attentional Selection Under Conflict}}: {{Toward}} a {{Rational Bayesian Account}}},
  author = {Yu, Angela J and Dayan, Peter and Cohen, Jonathan D},
  pages = {19},
  abstract = {The brain exhibits remarkable facility in exerting attentional control in most circumstances, but it also suffers apparent limitations in others. The authors’ goal is to construct a rational account for why attentional control appears suboptimal under conditions of conflict and what this implies about the underlying computational principles. The formal framework used is based on Bayesian probability theory, which provides a convenient language for delineating the rationale and dynamics of attentional selection. The authors illustrate these issues with the Eriksen flanker task, a classical paradigm that explores the effects of competing sensory inputs on response tendencies. The authors show how 2 distinctly formulated models, based on compatibility bias and spatial uncertainty principles, can account for the behavioral data. They also suggest novel experiments that may differentiate these models. In addition, they elaborate a simplified model that approximates optimal computation and may map more directly onto the underlying neural machinery. This approximate model uses conflict monitoring, putatively mediated by the anterior cingulate cortex, as a proxy for compatibility representation. The authors also consider how this conflict information might be disseminated and used to control processing.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/AU8YXZGV/Yu et al. - Dynamics of Attentional Selection Under Conflict .pdf;/Users/alexten/Zotero/storage/G2USH3YC/Yu et al. - 2009 - Dynamics of attentional selection under conflict .pdf}
}

@article{yuUncertaintyNeuromodulationAttention,
  title = {Uncertainty, {{Neuromodulation}}, and {{Attention}}},
  author = {Yu, Angela J and Dayan, Peter},
  pages = {12},
  abstract = {Uncertainty in various forms plagues our interactions with the environment. In a Bayesian statistical framework, optimal inference and prediction, based on unreliable observations in changing contexts, require the representation and manipulation of different forms of uncertainty. We propose that the neuromodulators acetylcholine and norepinephrine play a major role in the brain’s implementation of these uncertainty computations. Acetylcholine signals expected uncertainty, coming from known unreliability of predictive cues within a context. Norepinephrine signals unexpected uncertainty, as when unsignaled context switches produce strongly unexpected observations. These uncertainty signals interact to enable optimal inference and learning in noisy and changeable environments. This formulation is consistent with a wealth of physiological, pharmacological, and behavioral data implicating acetylcholine and norepinephrine in specific aspects of a range of cognitive processes. Moreover, the model suggests a class of attentional cueing tasks that involve both neuromodulators and shows how their interactions may be part-antagonistic, part-synergistic.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/4IAQFEZY/Yu and Dayan - Uncertainty, Neuromodulation, and Attention.pdf}
}

@article{yuUncertaintyNeuromodulationAttention2005,
  title = {Uncertainty, {{Neuromodulation}}, and {{Attention}}},
  author = {Yu, Angela J. and Dayan, Peter},
  date = {2005-05},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {46},
  number = {4},
  pages = {681--692},
  issn = {08966273},
  doi = {10.1016/j.neuron.2005.04.026},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627305003624},
  urldate = {2021-01-22},
  abstract = {Uncertainty in various forms plagues our interactions with the environment. In a Bayesian statistical framework, optimal inference and prediction, based on unreliable observations in changing contexts, require the representation and manipulation of different forms of uncertainty. We propose that the neuromodulators acetylcholine and norepinephrine play a major role in the brain’s implementation of these uncertainty computations. Acetylcholine signals expected uncertainty, coming from known unreliability of predictive cues within a context. Norepinephrine signals unexpected uncertainty, as when unsignaled context switches produce strongly unexpected observations. These uncertainty signals interact to enable optimal inference and learning in noisy and changeable environments. This formulation is consistent with a wealth of physiological, pharmacological, and behavioral data implicating acetylcholine and norepinephrine in specific aspects of a range of cognitive processes. Moreover, the model suggests a class of attentional cueing tasks that involve both neuromodulators and shows how their interactions may be part-antagonistic, part-synergistic.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/U8DQNMBA/Yu and Dayan - 2005 - Uncertainty, Neuromodulation, and Attention.pdf}
}

@article{zandtROCCurvesCon,
  title = {{{ROC Curves}} and {{Con}} Dence {{Judgments In Recognition Memory}}},
  author = {Zandt, Trisha Van},
  pages = {60},
  abstract = {Most models of recognition memory rely on a strength/familiarity-based signal-detection account that assumes that the processes giving rise to a con dence judgment are the same as those giving rise to an old/new decision. Con dence is assumed to be scaled directly from the perceived familiarity of a probe. This assumption is tested in two experiments that examine the shape of con dence-based zROC curves under di erent levels of response bias induced by changing stimulus probabilities (Experiment 1) and payo s (Experiment 2). Changes in the shape of the zROC curves with bias indicate that con dence is not scaled directly from perceived familiarity or likelihood. A model of information accumulation in recognition memory is proposed that can account for the observed e ects.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/R7KK35XZ/Zandt - ROC Curves and Con dence Judgments In Recognition .pdf}
}

@article{zandtROCCurvesCona,
  title = {{{ROC Curves}} and {{Con}} Dence {{Judgments In Recognition Memory}}},
  author = {Zandt, Trisha Van},
  pages = {60},
  abstract = {Most models of recognition memory rely on a strength/familiarity-based signal-detection account that assumes that the processes giving rise to a con dence judgment are the same as those giving rise to an old/new decision. Con dence is assumed to be scaled directly from the perceived familiarity of a probe. This assumption is tested in two experiments that examine the shape of con dence-based zROC curves under di erent levels of response bias induced by changing stimulus probabilities (Experiment 1) and payo s (Experiment 2). Changes in the shape of the zROC curves with bias indicate that con dence is not scaled directly from perceived familiarity or likelihood. A model of information accumulation in recognition memory is proposed that can account for the observed e ects.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/94GDFJLN/Zandt - ROC Curves and Con dence Judgments In Recognition .pdf}
}

@article{zawadzkaRemindMeContext2018,
  title = {Remind Me of the Context\_ {{Memory}} and Metacognition at Restudy},
  author = {Zawadzka, Katarzyna},
  date = {2018},
  journaltitle = {Journal of Memory and Language},
  pages = {17},
  abstract = {Mastering study materials often requires repeated learning. However, the strategy of restudying the same materials has been criticized for not giving sufficient opportunity for retrieval in the form of self-assessments that are known to benefit not only learning but also metacognitive monitoring of the learning process. Here we focus on the contribution of spontaneous retrieval in the form of reminding to repeated learning that does not require explicit self-assessments. By manipulating environmental context in which restudy takes place, we demonstrate that repeated learning in the same environmental context increases the incidence of reminding, augmenting learning and influencing metacognitive monitoring (as tapped into by immediate judgments of learning). At the same time, we demonstrate that explicit self-assessments – delayed judgments of learning – can be led astray by non-diagnostic spurious familiarity of environmental context which accompanies these assessments. The study thus reveals the positive effects of environmental context on restudy, while highlighting possible inaccuracies of metacognitive processes involved in explicit self-assessments of learning.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/X9SURKEA/Zawadzka - 2018 - Remind me of the context_ Memory and metacognition.pdf}
}

@article{zawadzkaRemindMeContext2018a,
  title = {Remind Me of the Context\_ {{Memory}} and Metacognition at Restudy},
  author = {Zawadzka, Katarzyna},
  date = {2018},
  journaltitle = {Journal of Memory and Language},
  pages = {17},
  abstract = {Mastering study materials often requires repeated learning. However, the strategy of restudying the same materials has been criticized for not giving sufficient opportunity for retrieval in the form of self-assessments that are known to benefit not only learning but also metacognitive monitoring of the learning process. Here we focus on the contribution of spontaneous retrieval in the form of reminding to repeated learning that does not require explicit self-assessments. By manipulating environmental context in which restudy takes place, we demonstrate that repeated learning in the same environmental context increases the incidence of reminding, augmenting learning and influencing metacognitive monitoring (as tapped into by immediate judgments of learning). At the same time, we demonstrate that explicit self-assessments – delayed judgments of learning – can be led astray by non-diagnostic spurious familiarity of environmental context which accompanies these assessments. The study thus reveals the positive effects of environmental context on restudy, while highlighting possible inaccuracies of metacognitive processes involved in explicit self-assessments of learning.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/HIJABT6J/Zawadzka - 2018 - Remind me of the context_ Memory and metacognition.pdf}
}

@article{zentallPerspectivesObservationalLearning,
  title = {Perspectives on {{Observational Learning}} in {{Animals}}},
  author = {Zentall, Thomas R},
  pages = {16},
  abstract = {Observational learning is presumed to have occurred when an organism copies an improbable action or action outcome that it has observed and the matching behavior cannot be explained by an alternative mechanism. Psychologists have been particularly interested in the form of observational learning known as imitation and in how to distinguish imitation from other processes. To successfully make this distinction, one must disentangle the degree to which behavioral similarity results from (a) predisposed behavior, (b) increased motivation resulting from the presence of another animal, (c) attention drawn to a place or object, (d) learning about the way the environment works, as distinguished from what we think of as (e) imitation (the copying of the demonstrated behavior). Several of the processes that may be involved in observational learning are reviewed, including social facilitation, stimulus enhancement, several kinds of emulation, and various forms of imitation.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/LRBZ2T2X/Zentall - Perspectives on Observational Learning in Animals.pdf}
}

@article{zentallPerspectivesObservationalLearning2012,
  title = {Perspectives on Observational Learning in Animals.},
  author = {Zentall, Thomas R.},
  date = {2012},
  journaltitle = {Journal of Comparative Psychology},
  shortjournal = {Journal of Comparative Psychology},
  volume = {126},
  number = {2},
  pages = {114--128},
  issn = {1939-2087, 0735-7036},
  doi = {10.1037/a0025381},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0025381},
  urldate = {2021-01-22},
  abstract = {Observational learning is presumed to have occurred when an organism copies an improbable action or action outcome that it has observed and the matching behavior cannot be explained by an alternative mechanism. Psychologists have been particularly interested in the form of observational learning known as imitation and in how to distinguish imitation from other processes. To successfully make this distinction, one must disentangle the degree to which behavioral similarity results from (a) predisposed behavior, (b) increased motivation resulting from the presence of another animal, (c) attention drawn to a place or object, (d) learning about the way the environment works, as distinguished from what we think of as (e) imitation (the copying of the demonstrated behavior). Several of the processes that may be involved in observational learning are reviewed, including social facilitation, stimulus enhancement, several kinds of emulation, and various forms of imitation.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/8CSVJDZG/Zentall - 2012 - Perspectives on observational learning in animals..pdf}
}

@article{zentallPigeonsPreferInformation2012,
  title = {Do Pigeons Prefer Information in the Absence of Differential Reinforcement?},
  author = {Zentall, Thomas R and Stagner, Jessica P},
  date = {2012},
  journaltitle = {Learn Behav},
  pages = {11},
  abstract = {Prior research has indicated that pigeons do not prefer an alternative that provides a sample (for matching to sample) over an alternative that does not provide a sample (i.e., there is no indication of which comparison stimulus is correct). However, Zentall and Stagner (Journal of Experimental Psychology. Animal Behavior Processes 36:506–509, 2010) showed that when delay of reinforcement was controlled, pigeons had a strong preference for matching over pseudomatching (i.e., there was a sample, but it did not indicate which comparison stimulus was correct). Experiment 1 of the present study replicated and extended the results of the Zentall and Stagner (Journal of Experimental Psychology. Animal Behavior Processes 36:506–509, 2010) study by including an identity relation between the sample and one of the comparison stimuli in both the matching and pseudomatching tasks. In Experiment 2, in which we asked whether the pigeons would still prefer matching if we equated the two tasks for probability of reinforcement, we found no systematic preference for matching over pseudomatching. Thus, it appears that in the absence of differential reinforcement, the information provided by a sample that signals which of the two comparison stimuli is correct is insufficient to produce a preference for that alternative.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/APDVG294/Zentall and Stagner - 2012 - Do pigeons prefer information in the absence of di.pdf;/Users/alexten/Zotero/storage/TYHR8B6G/Zentall and Stagner - 2012 - Do pigeons prefer information in the absence of di.pdf}
}

@article{zhangForgetfulBayesMyopic,
  title = {Forgetful {{Bayes}} and Myopic Planning: {{Human}} Learning and Decision-Making in a Bandit Setting},
  author = {Zhang, Shunan and Yu, Angela J},
  pages = {9},
  abstract = {How humans achieve long-term goals in an uncertain environment, via repeated trials and noisy observations, is an important problem in cognitive science. We investigate this behavior in the context of a multi-armed bandit task. We compare human behavior to a variety of models that vary in their representational and computational complexity. Our result shows that subjects’ choices, on a trial-totrial basis, are best captured by a “forgetful” Bayesian iterative learning model [21] in combination with a partially myopic decision policy known as Knowledge Gradient [7]. This model accounts for subjects’ trial-by-trial choice better than a number of other previously proposed models, including optimal Bayesian learning and risk minimization, e-greedy and win-stay-lose-shift. It has the added benefit of being closest in performance to the optimal Bayesian model than all the other heuristic models that have the same computational complexity (all are significantly less complex than the optimal model). These results constitute an advancement in the theoretical understanding of how humans negotiate the tension between exploration and exploitation in a noisy, imperfectly known environment.},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UZ6CM3IK/Zhang and Yu - Forgetful Bayes and myopic planning Human learnin.pdf;/Users/alexten/Zotero/storage/W5AX2UZN/Zhang and Yu - Forgetful Bayes and myopic planning Human learnin.pdf}
}

@article{zuurProtocolConductingPresenting2016,
  title = {A Protocol for Conducting and Presenting Results of Regression‐type Analyses},
  author = {Zuur, Alain F and Ieno, Elena N},
  date = {2016},
  journaltitle = {Methods in Ecology and Evolution},
  pages = {10},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/UDACIG22/Zuur and Ieno - 2016 - A protocol for conducting and presenting results o.pdf}
}

@article{zuurProtocolConductingPresenting2016a,
  title = {A Protocol for Conducting and Presenting Results of Regression-Type Analyses},
  author = {Zuur, Alain F. and Ieno, Elena N.},
  editor = {Freckleton, Robert},
  date = {2016-06},
  journaltitle = {Methods in Ecology and Evolution},
  shortjournal = {Methods Ecol Evol},
  volume = {7},
  number = {6},
  pages = {636--645},
  issn = {2041210X},
  doi = {10.1111/2041-210X.12577},
  url = {http://doi.wiley.com/10.1111/2041-210X.12577},
  urldate = {2021-01-22},
  langid = {english},
  file = {/Users/alexten/Zotero/storage/R2Q2YPQM/Zuur and Ieno - 2016 - A protocol for conducting and presenting results o.pdf}
}


